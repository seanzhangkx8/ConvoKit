{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t5JqrpJWoNaB"
   },
   "source": [
    "# CRAFT demo (inference only) using ConvoKit\n",
    "\n",
    "This example notebook shows how an already-trained CRAFT model can be applied to conversational data to predict future derailment. This example uses the fully trained Wikiconv-based model as reported in the \"Trouble on the Horizon\" paper, and applies it to ConvoKit's version of the labeled Wikiconv corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "import convokit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Forecaster, Corpus, download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit.forecaster.CRAFTModel import CRAFTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing CRAFT model with options:\n",
      "{'hidden_size': 500, 'encoder_n_layers': 2, 'context_encoder_n_layers': 2, 'decoder_n_layers': 2, 'dropout': 0.1, 'batch_size': 64, 'clip': 50.0, 'learning_rate': 1e-05, 'print_every': 10, 'train_epochs': 30, 'validation_size': 0.2, 'max_length': 80, 'trained_model_output_filepath': 'finetuned_model.tar'}\n",
      "Could not find CRAFT model tar file at: finetuned_model.tar\n",
      "Loading saved parameters...\n",
      "Building encoders, decoder, and classifier...\n",
      "Models built and ready to go!\n"
     ]
    }
   ],
   "source": [
    "craft_model = CRAFTModel(device_type=\"cpu\", model_path=\"finetuned_model.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = Forecaster(forecaster_model = craft_model,\n",
    "                        forecast_mode = \"future\",\n",
    "                        convo_structure=\"linear\",\n",
    "                        text_func = lambda utt: utt.meta[\"tokens\"][:(MAX_LENGTH-1)],\n",
    "                        label_func = lambda utt: int(utt.meta['comment_has_personal_attack']),\n",
    "                        forecast_attribute_name=\"prediction\", forecast_prob_attribute_name=\"pred_score\",\n",
    "                        use_last_only = True,\n",
    "                        skip_broken_convos=False\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /kitchen/convokit-corpora-jpc/conversations-gone-awry-corpus\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(filename=download(\"conversations-gone-awry-corpus\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_ev-7g-xsGQ"
   },
   "source": [
    "## Part 2: load the data\n",
    "\n",
    "Now we load the labeled Wikiconv corpus from ConvoKit, and run some transformations to prepare it for use with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit.forecaster.CRAFT import craft_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for utt in corpus.iter_utterances():\n",
    "    utt.add_meta(\"tokens\", craft_tokenize(craft_model.voc, utt.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1; Percent complete: 2.5%\n",
      "Iteration: 2; Percent complete: 5.0%\n",
      "Iteration: 3; Percent complete: 7.5%\n",
      "Iteration: 4; Percent complete: 10.0%\n",
      "Iteration: 5; Percent complete: 12.5%\n",
      "Iteration: 6; Percent complete: 15.0%\n",
      "Iteration: 7; Percent complete: 17.5%\n",
      "Iteration: 8; Percent complete: 20.0%\n",
      "Iteration: 9; Percent complete: 22.5%\n",
      "Iteration: 10; Percent complete: 25.0%\n",
      "Iteration: 11; Percent complete: 27.5%\n",
      "Iteration: 12; Percent complete: 30.0%\n",
      "Iteration: 13; Percent complete: 32.5%\n",
      "Iteration: 14; Percent complete: 35.0%\n",
      "Iteration: 15; Percent complete: 37.5%\n",
      "Iteration: 16; Percent complete: 40.0%\n",
      "Iteration: 17; Percent complete: 42.5%\n",
      "Iteration: 18; Percent complete: 45.0%\n",
      "Iteration: 19; Percent complete: 47.5%\n",
      "Iteration: 20; Percent complete: 50.0%\n",
      "Iteration: 21; Percent complete: 52.5%\n",
      "Iteration: 22; Percent complete: 55.0%\n",
      "Iteration: 23; Percent complete: 57.5%\n",
      "Iteration: 24; Percent complete: 60.0%\n",
      "Iteration: 25; Percent complete: 62.5%\n",
      "Iteration: 26; Percent complete: 65.0%\n",
      "Iteration: 27; Percent complete: 67.5%\n",
      "Iteration: 28; Percent complete: 70.0%\n",
      "Iteration: 29; Percent complete: 72.5%\n",
      "Iteration: 30; Percent complete: 75.0%\n",
      "Iteration: 31; Percent complete: 77.5%\n",
      "Iteration: 32; Percent complete: 80.0%\n",
      "Iteration: 33; Percent complete: 82.5%\n",
      "Iteration: 34; Percent complete: 85.0%\n",
      "Iteration: 35; Percent complete: 87.5%\n",
      "Iteration: 36; Percent complete: 90.0%\n",
      "Iteration: 37; Percent complete: 92.5%\n",
      "Iteration: 38; Percent complete: 95.0%\n",
      "Iteration: 39; Percent complete: 97.5%\n",
      "Iteration: 40; Percent complete: 100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<convokit.model.corpus.Corpus at 0x7ff539d91a50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.transform(corpus, selector=lambda convo: convo.meta[\"split\"] == \"train\",\n",
    "                    ignore_utterances=lambda utt: utt.meta[\"is_section_header\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_df = forecaster.summarize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utt_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>800622928.18454.18454</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.989630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351871224.50472.50472</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409048245.4938.4938</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751475142.54124.54124</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308491753.38115.38115</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404257585.20200.20200</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159022461.6705.6705</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746296311.83642.83642</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117788418.23770.23770</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18657304.7525.7525</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200417282.167665.167665</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462029088.1785.1785</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110875381.4905.4893</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737162646.263371.263371</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379019100.144622.144622</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362070598.18873.18873</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36494082.4097.4097</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677077058.15302.15302</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170314474.34849.34849</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.985931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79340130.87335.87335</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.985910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         prediction  pred_score\n",
       "utt_id                                         \n",
       "800622928.18454.18454           1.0    0.989630\n",
       "351871224.50472.50472           1.0    0.988888\n",
       "409048245.4938.4938             1.0    0.988836\n",
       "751475142.54124.54124           1.0    0.988621\n",
       "308491753.38115.38115           1.0    0.988546\n",
       "404257585.20200.20200           1.0    0.988429\n",
       "159022461.6705.6705             1.0    0.988336\n",
       "746296311.83642.83642           1.0    0.988175\n",
       "117788418.23770.23770           1.0    0.987995\n",
       "18657304.7525.7525              1.0    0.987427\n",
       "200417282.167665.167665         1.0    0.987180\n",
       "462029088.1785.1785             1.0    0.986980\n",
       "110875381.4905.4893             1.0    0.986850\n",
       "737162646.263371.263371         1.0    0.986698\n",
       "379019100.144622.144622         1.0    0.986244\n",
       "362070598.18873.18873           1.0    0.986196\n",
       "36494082.4097.4097              1.0    0.986079\n",
       "677077058.15302.15302           1.0    0.986012\n",
       "170314474.34849.34849           1.0    0.985931\n",
       "79340130.87335.87335            1.0    0.985910"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts_df.head(20)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of CRAFT inference demo using ConvoKit",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
