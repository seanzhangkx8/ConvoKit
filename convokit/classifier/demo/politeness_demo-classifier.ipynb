{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Politeness prediction with ConvoKit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to train a simple classifier to predict the politeness level of a request by considering the politeness strategies used, as seen in the paper [A computational approach to politeness with application to social factors](https://www.cs.cornell.edu/~cristian/Politeness.html), using ConvoKit. Note that this notebook is *not* intended to reproduce the paper results: legacy code for reproducibility is available at this [repository](https://github.com/sudhof/politeness). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import convokit\n",
    "from convokit import Corpus, User, Utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from typing import List, Dict, Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1: load annotated dataset\n",
    "\n",
    "We will be using the wikipedia annotations from the [Stanford Politeness Corpus](https://www.cs.cornell.edu/~cristian/Politeness.html). \n",
    "\n",
    "Code below demonstrates how to convert the original CSV file into the corpus format expected by ConvoKit, but this resultant corpus can also be directly downloaded using the helper function `download(\"wiki-politeness-annotated\")`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2: annotate the corpus with politeness strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get politeness strategies for each utterance, we will first obtain dependency parses for the utterances, and then check for strategy use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import TextParser, PolitenessStrategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- adding dependency parses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading wiki-politeness-annotated to /Users/calebchiam/.convokit/downloads/wiki-politeness-annotated\n",
      "Downloading wiki-politeness-annotated from http://zissou.infosci.cornell.edu/convokit/datasets/wiki-politeness-annotated-corpus/wiki-politeness-annotated-corpus.zip (644.7KB)... Done\n"
     ]
    }
   ],
   "source": [
    "wiki_corpus = Corpus(convokit.download(\"wiki-politeness-annotated\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator = TextParser()\n",
    "wiki_corpus = annotator.fit_transform(wiki_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- adding strategy information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PolitenessStrategies()\n",
    "wiki_corpus = ps.transform(wiki_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of how a processed utterance now look. Dependency parses are stored in `parsed`, and politeness strategies are in `politeness_strategies`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Utterance({'obj_type': 'utterance', '_owner': <convokit.model.corpus.Corpus object at 0x13b0b9978>, 'meta': {'Normalized Score': -1.1200492637766977, 'Binary': -1, 'Annotations': {'A2UFD1I8ZO1V4G': 13, 'A2YFPO0N4GIS25': 9, 'AYG3MF094634L': 11, 'A38WUWONC7EXTO': 11, 'A15DM9BMKZZJQ6': 5}, 'parsed': [{'rt': 3, 'toks': [{'tok': 'Where', 'tag': 'WRB', 'dep': 'advmod', 'up': 3, 'dn': []}, {'tok': 'did', 'tag': 'VBD', 'dep': 'aux', 'up': 3, 'dn': []}, {'tok': 'you', 'tag': 'PRP', 'dep': 'nsubj', 'up': 3, 'dn': []}, {'tok': 'learn', 'tag': 'VB', 'dep': 'ROOT', 'dn': [0, 1, 2, 4, 5]}, {'tok': 'English', 'tag': 'NNP', 'dep': 'dobj', 'up': 3, 'dn': []}, {'tok': '?', 'tag': '.', 'dep': 'punct', 'up': 3, 'dn': []}]}, {'rt': 4, 'toks': [{'tok': 'How', 'tag': 'WRB', 'dep': 'advmod', 'up': 4, 'dn': []}, {'tok': 'come', 'tag': 'VB', 'dep': 'aux', 'up': 4, 'dn': []}, {'tok': 'you', 'tag': 'PRP', 'dep': 'nsubj', 'up': 4, 'dn': []}, {'tok': \"'re\", 'tag': 'VBP', 'dep': 'aux', 'up': 4, 'dn': []}, {'tok': 'taking', 'tag': 'VBG', 'dep': 'ROOT', 'dn': [0, 1, 2, 3, 5, 8, 9]}, {'tok': 'on', 'tag': 'RP', 'dep': 'prt', 'up': 4, 'dn': []}, {'tok': 'a', 'tag': 'DT', 'dep': 'det', 'up': 8, 'dn': []}, {'tok': 'third', 'tag': 'JJ', 'dep': 'amod', 'up': 8, 'dn': []}, {'tok': 'language', 'tag': 'NN', 'dep': 'dobj', 'up': 4, 'dn': [6, 7]}, {'tok': '?', 'tag': '.', 'dep': 'punct', 'up': 4, 'dn': []}]}], 'politeness_strategies': {'feature_politeness_==Please==': 0, 'feature_politeness_==Please_start==': 0, 'feature_politeness_==Indirect_(btw)==': 0, 'feature_politeness_==Hedges==': 0, 'feature_politeness_==Factuality==': 0, 'feature_politeness_==Deference==': 0, 'feature_politeness_==Gratitude==': 0, 'feature_politeness_==Apologizing==': 0, 'feature_politeness_==1st_person_pl.==': 0, 'feature_politeness_==1st_person==': 0, 'feature_politeness_==1st_person_start==': 0, 'feature_politeness_==2nd_person==': 1, 'feature_politeness_==2nd_person_start==': 0, 'feature_politeness_==Indirect_(greeting)==': 0, 'feature_politeness_==Direct_question==': 1, 'feature_politeness_==Direct_start==': 0, 'feature_politeness_==SUBJUNCTIVE==': 0, 'feature_politeness_==INDICATIVE==': 0, 'feature_politeness_==HASHEDGE==': 0, 'feature_politeness_==HASPOSITIVE==': 0, 'feature_politeness_==HASNEGATIVE==': 0}}, '_id': '629705', 'user': User({'obj_type': 'user', '_owner': <convokit.model.corpus.Corpus object at 0x13b0b9978>, 'meta': {}, '_id': 'wiki_user', '_name': 'wiki_user'}), 'root': '629705', 'reply_to': None, 'timestamp': 'NOT_RECORDED', 'text': \"Where did you learn English? How come you're taking on a third language?\"})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_corpus.get_utterance(\"629705\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to save the corpus by doing `wiki_corpus.dump(\"wiki-politeness-annotated\")` for further exploration. Note that if you do not specify a base path, data will be saved to `.convokit/saved-corpora` in your home directory by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. predict politeness \n",
    "\n",
    "We will see how a simple classifier considering the use of politeness strategies perform. Note that this is only for demonstration, and not geared towards achieving best performance. \n",
    "\n",
    "(Most of the code below are adapted from [here](https://github.com/sudhof/politeness/blob/master/scripts/train_model.py))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn import svm\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this prediction task, we will only consider the polite vs. impolite group (i.e., those with \"Binary\" field being either +1 or -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_corpus = Corpus(utterances=[utt for utt in wiki_corpus.iter_utterances() if utt.meta[\"Binary\"] != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier(obj_type=\"utterance\", \n",
    "                        pred_feats=[\"politeness_strategies\"], \n",
    "                        labeller=lambda utt: utt.meta['Binary'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<convokit.classifier.classifier.Classifier at 0x14dfe3128>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(binary_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use this classifier to predict politeness labels for Utterances. As an example, we will use some test utterances, but you can also consider use this classifier to predict on new utterances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = ['485293', '252109', '623560', '328144', '627508']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- predicting for test utterances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- to check predicted politeness label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_utts = [binary_corpus.get_utterance(oid) for oid in test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "objs = classifier.transform_objs(objs=test_utts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>485293</th>\n",
       "      <td>0</td>\n",
       "      <td>0.190408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252109</th>\n",
       "      <td>0</td>\n",
       "      <td>0.219440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328144</th>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623560</th>\n",
       "      <td>1</td>\n",
       "      <td>0.626807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627508</th>\n",
       "      <td>1</td>\n",
       "      <td>0.728420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        prediction  pred_score\n",
       "id                            \n",
       "485293           0    0.190408\n",
       "252109           0    0.219440\n",
       "328144           0    0.500000\n",
       "623560           1    0.626807\n",
       "627508           1    0.728420"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.summarize(objs=objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<convokit.model.corpus.Corpus at 0x14d40d128>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.transform(binary_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = classifier.summarize(binary_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>618958</th>\n",
       "      <td>0</td>\n",
       "      <td>0.018899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389055</th>\n",
       "      <td>0</td>\n",
       "      <td>0.018899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620697</th>\n",
       "      <td>0</td>\n",
       "      <td>0.019789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215577</th>\n",
       "      <td>0</td>\n",
       "      <td>0.022574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9038</th>\n",
       "      <td>0</td>\n",
       "      <td>0.022911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204288</th>\n",
       "      <td>0</td>\n",
       "      <td>0.022911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28387</th>\n",
       "      <td>0</td>\n",
       "      <td>0.022912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619691</th>\n",
       "      <td>0</td>\n",
       "      <td>0.027646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622098</th>\n",
       "      <td>0</td>\n",
       "      <td>0.027646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281102</th>\n",
       "      <td>0</td>\n",
       "      <td>0.030126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493465</th>\n",
       "      <td>0</td>\n",
       "      <td>0.031550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417649</th>\n",
       "      <td>0</td>\n",
       "      <td>0.031554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278041</th>\n",
       "      <td>0</td>\n",
       "      <td>0.036495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624081</th>\n",
       "      <td>0</td>\n",
       "      <td>0.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628216</th>\n",
       "      <td>0</td>\n",
       "      <td>0.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542059</th>\n",
       "      <td>0</td>\n",
       "      <td>0.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40765</th>\n",
       "      <td>0</td>\n",
       "      <td>0.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624848</th>\n",
       "      <td>0</td>\n",
       "      <td>0.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494773</th>\n",
       "      <td>0</td>\n",
       "      <td>0.038199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76371</th>\n",
       "      <td>0</td>\n",
       "      <td>0.042035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621563</th>\n",
       "      <td>0</td>\n",
       "      <td>0.042056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132700</th>\n",
       "      <td>0</td>\n",
       "      <td>0.042056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81992</th>\n",
       "      <td>0</td>\n",
       "      <td>0.042056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51606</th>\n",
       "      <td>0</td>\n",
       "      <td>0.042056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577368</th>\n",
       "      <td>0</td>\n",
       "      <td>0.042056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251922</th>\n",
       "      <td>0</td>\n",
       "      <td>0.047866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34876</th>\n",
       "      <td>0</td>\n",
       "      <td>0.048570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133623</th>\n",
       "      <td>0</td>\n",
       "      <td>0.048570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247684</th>\n",
       "      <td>0</td>\n",
       "      <td>0.048571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599609</th>\n",
       "      <td>0</td>\n",
       "      <td>0.048571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530060</th>\n",
       "      <td>1</td>\n",
       "      <td>0.983843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413628</th>\n",
       "      <td>1</td>\n",
       "      <td>0.984830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464868</th>\n",
       "      <td>1</td>\n",
       "      <td>0.986278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73769</th>\n",
       "      <td>1</td>\n",
       "      <td>0.986843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608548</th>\n",
       "      <td>1</td>\n",
       "      <td>0.986843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494487</th>\n",
       "      <td>1</td>\n",
       "      <td>0.986881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533882</th>\n",
       "      <td>1</td>\n",
       "      <td>0.987501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214946</th>\n",
       "      <td>1</td>\n",
       "      <td>0.987572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349495</th>\n",
       "      <td>1</td>\n",
       "      <td>0.988070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591512</th>\n",
       "      <td>1</td>\n",
       "      <td>0.988373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29829</th>\n",
       "      <td>1</td>\n",
       "      <td>0.988428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222405</th>\n",
       "      <td>1</td>\n",
       "      <td>0.988449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378320</th>\n",
       "      <td>1</td>\n",
       "      <td>0.988665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213945</th>\n",
       "      <td>1</td>\n",
       "      <td>0.988731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625248</th>\n",
       "      <td>1</td>\n",
       "      <td>0.988731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9522</th>\n",
       "      <td>1</td>\n",
       "      <td>0.991495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163627</th>\n",
       "      <td>1</td>\n",
       "      <td>0.991754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95018</th>\n",
       "      <td>1</td>\n",
       "      <td>0.992153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186097</th>\n",
       "      <td>1</td>\n",
       "      <td>0.992757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19520</th>\n",
       "      <td>1</td>\n",
       "      <td>0.993945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325606</th>\n",
       "      <td>1</td>\n",
       "      <td>0.993946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19538</th>\n",
       "      <td>1</td>\n",
       "      <td>0.994529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358525</th>\n",
       "      <td>1</td>\n",
       "      <td>0.996001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559038</th>\n",
       "      <td>1</td>\n",
       "      <td>0.996003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528412</th>\n",
       "      <td>1</td>\n",
       "      <td>0.996309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167072</th>\n",
       "      <td>1</td>\n",
       "      <td>0.996310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454903</th>\n",
       "      <td>1</td>\n",
       "      <td>0.997158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513734</th>\n",
       "      <td>1</td>\n",
       "      <td>0.997433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601165</th>\n",
       "      <td>1</td>\n",
       "      <td>0.997433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235786</th>\n",
       "      <td>1</td>\n",
       "      <td>0.997433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2178 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        prediction  pred_score\n",
       "id                            \n",
       "618958           0    0.018899\n",
       "389055           0    0.018899\n",
       "620697           0    0.019789\n",
       "215577           0    0.022574\n",
       "9038             0    0.022911\n",
       "204288           0    0.022911\n",
       "28387            0    0.022912\n",
       "619691           0    0.027646\n",
       "622098           0    0.027646\n",
       "281102           0    0.030126\n",
       "493465           0    0.031550\n",
       "417649           0    0.031554\n",
       "278041           0    0.036495\n",
       "624081           0    0.036500\n",
       "628216           0    0.036500\n",
       "542059           0    0.036500\n",
       "40765            0    0.036500\n",
       "624848           0    0.036500\n",
       "494773           0    0.038199\n",
       "76371            0    0.042035\n",
       "621563           0    0.042056\n",
       "132700           0    0.042056\n",
       "81992            0    0.042056\n",
       "51606            0    0.042056\n",
       "577368           0    0.042056\n",
       "251922           0    0.047866\n",
       "34876            0    0.048570\n",
       "133623           0    0.048570\n",
       "247684           0    0.048571\n",
       "599609           0    0.048571\n",
       "...            ...         ...\n",
       "530060           1    0.983843\n",
       "413628           1    0.984830\n",
       "464868           1    0.986278\n",
       "73769            1    0.986843\n",
       "608548           1    0.986843\n",
       "494487           1    0.986881\n",
       "533882           1    0.987501\n",
       "214946           1    0.987572\n",
       "349495           1    0.988070\n",
       "591512           1    0.988373\n",
       "29829            1    0.988428\n",
       "222405           1    0.988449\n",
       "378320           1    0.988665\n",
       "213945           1    0.988731\n",
       "625248           1    0.988731\n",
       "9522             1    0.991495\n",
       "163627           1    0.991754\n",
       "95018            1    0.992153\n",
       "186097           1    0.992757\n",
       "19520            1    0.993945\n",
       "325606           1    0.993946\n",
       "19538            1    0.994529\n",
       "358525           1    0.996001\n",
       "559038           1    0.996003\n",
       "528412           1    0.996309\n",
       "167072           1    0.996310\n",
       "454903           1    0.997158\n",
       "513734           1    0.997433\n",
       "601165           1    0.997433\n",
       "235786           1    0.997433\n",
       "\n",
       "[2178 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['prediction'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "test utterance:\n",
      "Blocked, templated.  Next?\n",
      "------------------------\n",
      "Result: impolite, score = 0.19040800463767432\n",
      "\n",
      "1\n",
      "test utterance:\n",
      "Stephan, what did you mean by ''\"Is English your native language? You seem to fill in a lot of things not said with your assumptions.\"'' on my talk?\n",
      "------------------------\n",
      "Result: impolite, score = 0.2194400627715542\n",
      "\n",
      "2\n",
      "test utterance:\n",
      "I see you created a nonsense article yesterday because you were bored. If I unblock you will you disrupt more?\n",
      "------------------------\n",
      "Result: polite, score = 0.6268071385370304\n",
      "\n",
      "3\n",
      "test utterance:\n",
      "I have no need to search the interwebs, all that matters is it offends people and is a violation of NPOV and MoS. \"All Wikipedia articles and other encyclopedic content must be written from a neutral point of view (NPOV), representing fairly and without bias all significant views (that have been published by reliable sources)\" - ess-eff is a bias term for a minority group of fans, put it this way: is there an SF-channel, or how often is the clichxe9 ess-eff used outside fan-groups?\n",
      "------------------------\n",
      "Result: impolite, score = 0.5\n",
      "\n",
      "4\n",
      "test utterance:\n",
      "I responded to your talk page comment, encouraging you to try your hand at reworking it.  Good analysis of a potential problem, so why not take a whack at it?\n",
      "------------------------\n",
      "Result: polite, score = 0.7284201545195865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred2label = {1: \"polite\", 0: \"impolite\"}\n",
    "\n",
    "for i, idx in enumerate(test_ids):\n",
    "    print(i)\n",
    "    test_utt = binary_corpus.get_utterance(idx)\n",
    "    \n",
    "    print(\"test utterance:\\n{}\".format(test_utt.text))\n",
    "    print(\"------------------------\")\n",
    "    results = classifier.transform_objs(objs=[test_utt])[0]\n",
    "    \n",
    "    print(\"Result: {}, score = {}\\n\".format(pred2label[results.meta['prediction']], results.meta['pred_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that this is an implementation of a politeness classifier is trained on a specific dataset (wikipedia) and on a specific binarization of politeness classes. Depending on your scenario, you might find it is preferable to directly use the politeness strategies, as exemplified in the [conversations gone awry example](https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/conversations-gone-awry/Conversations_Gone_Awry_Prediction.ipynb), rather than a politeness label/score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using corpus objects...\n",
      "Running a train-test-split evaluation...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "accuracy, confusion_matrix = classifier.evaluate_with_train_test_split(binary_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7706422018348624"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[176,  53],\n",
       "       [ 47, 160]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.base_accuracy(binary_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7529843893480257"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.accuracy(binary_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[876, 213],\n",
       "       [325, 764]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.confusion_matrix(binary_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.73      0.80      0.77      1089\n",
      "        True       0.78      0.70      0.74      1089\n",
      "\n",
      "    accuracy                           0.75      2178\n",
      "   macro avg       0.76      0.75      0.75      2178\n",
      "weighted avg       0.76      0.75      0.75      2178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classifier.classification_report(binary_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
