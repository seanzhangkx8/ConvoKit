{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing Surprise With ConvoKit\n",
    "=====================\n",
    "This notebook provides a demo of how to use the Surprise transformer to compute surprise across a corpus. In this demo, we will use the Surprise transformer to compute Speaker Convo Diversity, a measure of how surprising a speaker's participation in one conversation is compared to their participation in all other conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import convokit\n",
    "import itertools\n",
    "import numpy as np\n",
    "import spacy\n",
    "from convokit import Corpus, download, Surprise\n",
    "from convokit.text_processing import TextProcessor, TextParser\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Load a corpus\n",
    "--------\n",
    "We will use data from the subreddit r/Cornell to demonstrate the functionality of this transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /home/axl4/.convokit/downloads/subreddit-Cornell\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(filename=download(\"subreddit-Cornell\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 7568\n",
      "Number of Utterances: 74467\n",
      "Number of Conversations: 10744\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to speed up the demo, we will take just the top 100 most active speakers (based on the number of conversations they participate in)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEAKER_BLACKLIST = [\"[deleted]\", \"DeltaBot\", \"AutoModerator\"]\n",
    "\n",
    "\n",
    "def utterance_is_valid(utterance):\n",
    "    return utterance.speaker.id not in SPEAKER_BLACKLIST and utterance.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/axl4/ConvoKit/convokit/model/corpus.py:1213: FutureWarning: set_info() is deprecated and will be removed in a future release. Use add_meta() instead.\n",
      "/home/axl4/ConvoKit/convokit/model/corpus.py:1219: FutureWarning: set_info() is deprecated and will be removed in a future release. Use add_meta() instead.\n"
     ]
    }
   ],
   "source": [
    "corpus.organize_speaker_convo_history(utterance_filter=utterance_is_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_activities = corpus.get_attribute_table(\"speaker\", [\"n_convos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_convos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>laveritecestla</th>\n",
       "      <td>781.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EQUASHNZRKUL</th>\n",
       "      <td>726.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CornHellUniversity</th>\n",
       "      <td>696.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t3hasiangod</th>\n",
       "      <td>647.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ilovemymemesboo</th>\n",
       "      <td>430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omgdonerkebab</th>\n",
       "      <td>425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cartesiancategory</th>\n",
       "      <td>341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cornell256</th>\n",
       "      <td>330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mushiettake</th>\n",
       "      <td>321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fencerman2</th>\n",
       "      <td>298.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    n_convos\n",
       "id                          \n",
       "laveritecestla         781.0\n",
       "EQUASHNZRKUL           726.0\n",
       "CornHellUniversity     696.0\n",
       "t3hasiangod            647.0\n",
       "ilovemymemesboo        430.0\n",
       "omgdonerkebab          425.0\n",
       "cartesiancategory      341.0\n",
       "cornell256             330.0\n",
       "mushiettake            321.0\n",
       "Fencerman2             298.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_activities.sort_values(\"n_convos\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_speakers = speaker_activities.sort_values(\"n_convos\", ascending=False).head(100).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "subset_utts = [\n",
    "    list(corpus.get_speaker(speaker).iter_utterances(selector=utterance_is_valid))\n",
    "    for speaker in top_speakers\n",
    "]\n",
    "subset_corpus = Corpus(utterances=list(itertools.chain(*subset_utts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 100\n",
      "Number of Utterances: 20550\n",
      "Number of Conversations: 6866\n"
     ]
    }
   ],
   "source": [
    "subset_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Create instance of Surprise transformer\n",
    "---------------\n",
    "`target_sample_size` and `context_sample_size` specify the minimum number of tokens that should be in the target and context respectively. If we sent these to simply be 1, the most surprising statements tend to just be the very short statements. If a target or context is shorter than the specified sample size, the transformer will set the surprise to be `nan`. The transformer takes `n_samples` samples from the target and context transformer (where samples are of size corresponding to `target_sample_size` and `context_sample_size`). It calculates cross entropy for each pair of samples and takes the average to get the final surprise score. This is done to minimize effect of length on scores.\n",
    "\n",
    "`model_key_selector` defines how utterances in a corpus should be mapped to a model. It takes in an utterance and returns the key for the corresponding model. For this demo we want to map utterances to models based on their speaker and conversation ids.\n",
    "\n",
    "The transformer also has an optional `tokenizer` parameter to customize tokenization. Here we will tokenize the text outside of the surprise transformer, so our tokenizer will be an identity function.\n",
    "\n",
    "The `smooth` parameter determines whether the transformer uses +1 laplace smoothing (`smooth = True`) or naively replaces 0 counts with 1's as the SpeakerConvoDiversity transformer does (`smooth = False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "spacy_nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\", \"tagger\", \"lemmatizer\"])\n",
    "for utt in subset_corpus.iter_utterances():\n",
    "    utt.meta[\"joined_tokens\"] = [t.text.lower() for t in spacy_nlp(utt.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "surp = Surprise(\n",
    "    tokenizer=lambda x: x,\n",
    "    model_key_selector=lambda utt: \"_\".join([utt.speaker.id, utt.conversation_id]),\n",
    "    target_sample_size=100,\n",
    "    context_sample_size=1000,\n",
    "    n_samples=50,\n",
    "    smooth=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fit1: 20550it [00:16, 1283.44it/s]\n",
      "fit2: 100%|██████████| 15394/15394 [00:00<00:00, 1032033.56it/s]\n"
     ]
    }
   ],
   "source": [
    "surp = surp.fit(\n",
    "    subset_corpus,\n",
    "    text_func=lambda utt: [\n",
    "        list(\n",
    "            itertools.chain(\n",
    "                *[\n",
    "                    u.meta[\"joined_tokens\"]\n",
    "                    for u in utt.speaker.iter_utterances()\n",
    "                    if u.conversation_id != utt.conversation_id\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Transform corpus\n",
    "--------\n",
    "The object type input to `transform` determines what objects the transformer adds metadata to. Valid inputs are `'utterance'`, `'speaker'`, `'conversation'`, and `'corpus'`. Here we'll call `transform` with object type `'speaker'` so that surprise scores will be added as a metadata field for each speaker. See the tennis demo for an example where object type is utterance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "transform: 100it [15:57,  9.57s/it]\n"
     ]
    }
   ],
   "source": [
    "transformed_corpus = surp.transform(subset_corpus, obj_type=\"speaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "def combine_dicts(x, y):\n",
    "    x.update(y)\n",
    "    return x\n",
    "\n",
    "\n",
    "surprise_scores = reduce(\n",
    "    combine_dicts, transformed_corpus.get_speakers_dataframe()[\"meta.surprise\"].values\n",
    ")\n",
    "suprise_series = pd.Series(surprise_scores).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the resulting pandas series, the keys are of the format {speaker}_{conversation id}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some of the most surprising speaker conversation involvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EQUASHNZRKUL_815y6t        7.233156\n",
       "SwissWatchesOnly_8g5q88    7.216094\n",
       "SwissWatchesOnly_67cljd    7.129933\n",
       "EQUASHNZRKUL_73xuw6        7.114335\n",
       "Straight_Derpin_5kst5l     7.067594\n",
       "laveritecestla_6v4ysm      7.066840\n",
       "ClawofBeta_52u1nu          7.059744\n",
       "Udontlikecake_7rj6a0       7.053087\n",
       "syntheticity_97zg9z        7.041747\n",
       "DEEP_THORAX_8drwet         7.038059\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_surprising = suprise_series.sort_values(ascending=False).head(10)\n",
    "most_surprising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at some of the least surprising entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unga_Bunga_30ac0l         5.841967\n",
       "Bisphosphate_7r8nu1       5.941750\n",
       "crash_over-ride_6bjxnm    5.945221\n",
       "crash_over-ride_8f7b0y    5.962945\n",
       "crash_over-ride_7owfvv    5.963205\n",
       "crash_over-ride_30zba1    5.970271\n",
       "crash_over-ride_2vhtzx    5.970866\n",
       "crash_over-ride_t6w01     5.981621\n",
       "omgdonerkebab_v4a3p       5.981898\n",
       "crash_over-ride_9b132c    5.983570\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least_surprising = suprise_series.sort_values(ascending=True).head(10)\n",
    "least_surprising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that some speakers appear multiple times in the most or least surprising speaker, convo pairs. This is particularly true of the least surprising where speaker 'crash_over-ride' appears many times. A possible explanation for this could be that this particular speaker talks about very similar things in their conversations, so much of their conversation participation is not very surprising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
