{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Conversations Gone Awry With Convokit\n",
    "\n",
    "This interactive tutorial demonstrates how to predict whether a conversation will eventually lead to a personal attack, as seen in the paper [Conversations Gone Awry: Detecting Early Signs of Conversational Failure](http://www.cs.cornell.edu/~cristian/Conversations_gone_awry.html), using the tools provided by convokit. It also serves as an illustration of how to use two of convokit's main features: question typology and politeness strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pkg_resources\n",
    "import json\n",
    "import itertools\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut\n",
    "from sklearn.feature_selection import f_classif, SelectPercentile\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from itertools import combinations\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "from convokit import Corpus, QuestionTypology, download, MotifsExtractor, QuestionTypologyUtils, PolitenessStrategies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset from the Conversations Gone Awry paper is provided through Convokit as \"conversations-gone-awry-corpus\". We will download this corpus, which includes precomputed SpaCy dependency parses, and use it for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading conversations-gone-awry-corpus to /home/jonathan/.convokit/downloads/conversations-gone-awry-corpus\n",
      "Downloading conversations-gone-awry-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/conversations-gone-awry-corpus/full.corpus (36.4MB)... Done\n"
     ]
    }
   ],
   "source": [
    "# download corpus and construct a convokit Corpus object from it. The Corpus class provides functionality for\n",
    "# convenient manipulation of text corpora.\n",
    "awry_corpus = Corpus(filename=download(\"conversations-gone-awry-corpus\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original Awry paper and dataset was released at ACL 2018. In the time since initial release, the dataset has been expanded with additional labeled samples, with the later annotation rounds focusing on longer conversations. Since this example notebook is based on the original Awry paper, we will now filter the corpus to keep only the conversations from the original dataset. This can be achieved by checking the \"annotation_year\" metadata entry; original data will have the value \"2018\". However, if you may also skip this filtering stage (skip directly to \"Step 2: Extract prompt types features\") if you wish to run the model on the complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168\n",
      "6363\n"
     ]
    }
   ],
   "source": [
    "# first, construct a table of conversations that meet the filter criteria (annotation_year = '2018')\n",
    "kept_conversations = {c.id: c for c in awry_corpus.iter_conversations() if c.meta['annotation_year'] == \"2018\"}\n",
    "# next, construct a filtered utterance table containing only the utterances in the filtered conversations\n",
    "kept_utterances = {}\n",
    "for convo_id in kept_conversations:\n",
    "    for utterance in kept_conversations[convo_id].iter_utterances():\n",
    "        kept_utterances[utterance.id] = utterance\n",
    "# finally, we overwrite the `conversations` and `utterances` fields of the Corpus object to turn it into a filtered Corpus.\n",
    "awry_corpus.conversations = kept_conversations\n",
    "awry_corpus.utterances = kept_utterances\n",
    "# make sure the size is what we expect\n",
    "print(len(awry_corpus.conversations))\n",
    "print(len(awry_corpus.utterances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract prompt types features\n",
    "\n",
    "In this step, we will extract the first of the two types of pragmatic features seen in the paper: prompt types. We can learn prompt types and compute types for each utterance in the corpus using convokit's QuestionTypology class. Note that in keeping with proper machine learning practices, we need a different dataset to use for training the QuestionTypology object. For this, we will use Convokit's Wikipedia talk corpus (\"wiki-corpus\"), which is comprised of Wikipedia talk page conversations different from those found in the Awry corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading wiki-corpus to /home/jonathan/.convokit/downloads/wiki-corpus\n",
      "Downloading wiki-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/wiki-corpus/full.corpus (324.4MB)... Done\n"
     ]
    }
   ],
   "source": [
    "# load the wiki corpus into a convokit Corpus object\n",
    "corpus = Corpus(filename=download(\"wiki-corpus\"))\n",
    "\n",
    "questionTypology = QuestionTypology(num_dims=50, num_clusters=6, question_threshold=100, answer_threshold=100, \n",
    "                                    verbose=1000000, random_seed=2018, min_support=20,\n",
    "                                    questions_only=False, enforce_formatting=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train a QuestionTypology object on the downloaded wiki corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running motif extraction pipeline\n",
      "loading spacy vocab\n",
      "loading spacy vocab\n",
      "getting question arcs\n",
      "making motif tree\n",
      "\tcounting itemsets\n",
      "\tfirst pass\n",
      "\tand then the rest\n",
      "\t 6 18623\n",
      "\t 7 4867\n",
      "\t 8 2724\n",
      "\t 9 1295\n",
      "\t 10 867\n",
      "\t 11 534\n",
      "\t 12 188\n",
      "\t 13 116\n",
      "\t 14 20\n",
      "\t 15 20\n",
      "\twriting itemsets\n",
      "\tbuilding tree\n",
      "fitting motifs to questions\n",
      "\tfitting arcsets\n",
      "handling redundant motifs\n",
      "\treading raw fits\n",
      "\tcounting cooccs\n",
      "\tdeduplicating\n",
      "\t1000000\n",
      "\t2000000\n",
      "\t3000000\n",
      "\t4000000\n",
      "\t5000000\n",
      "\t6000000\n",
      "\tmaking new entries\n",
      "done motif extraction\n",
      "running answer arc pipeline\n",
      "loading spacy vocab\n",
      "loading spacy vocab\n",
      "getting answer arcs\n",
      "done answer arc extraction\n",
      "building q-a matrices\n",
      "\treading arcs and motifs\n",
      "\t1000000\n",
      "\t2000000\n",
      "\t3000000\n",
      "\t4000000\n",
      "\t5000000\n",
      "\t6000000\n",
      "\tbuilding matrices\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<convokit.questionTypology.questionTypology.QuestionTypology at 0x7f3a447d0518>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionTypology.fit(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the QuestionTypology object has been trained, we can use it to compute prompt types for our awry corpus (notice that this is a different corpus from what the QuestionTypology object was trained on!). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforming corpus!\n",
      "fitting extracted motifs to new data...\n",
      "getting question arcs\n",
      "fitting motifs to questions\n",
      "building new q-a matrices\n",
      "\tbuilding matrices\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "awry_corpus = questionTypology.transform(awry_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to gather the computed prompt types into a tabular format to use as features for an sklearn estimator. For our purposes, we want the distances from the centers of the KMeans clusters corresponding to each prompt type. We can get these using the `qtype_dists` field that gets written to each Utterance's metadata table by the `transform` method. Note that in most other situations, where we want just the prompt type, we can instead use the `qtype` field which records an integer prompt type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterance_ids = awry_corpus.get_utterance_ids()\n",
    "rows = []\n",
    "# to build our table of features, we will iterate over the utterances in the corpus and look up the qtype_dists\n",
    "# metadata entry for each one. The resulting table will be indexed by utterance ID.\n",
    "for uid in utterance_ids:\n",
    "    rows.append(awry_corpus.get_utterance(uid).meta.get(\"qtype_dists\", np.zeros(6)))\n",
    "prompt_types = pd.DataFrame(np.vstack(rows), index=utterance_ids, columns=[\"km_%d_dist\" % i for i in range(6)])\n",
    "# in the paper, we assigned a max distance cutoff such that distances were capped at 1.\n",
    "prompt_types[prompt_types > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>km_0_dist</th>\n",
       "      <th>km_1_dist</th>\n",
       "      <th>km_2_dist</th>\n",
       "      <th>km_3_dist</th>\n",
       "      <th>km_4_dist</th>\n",
       "      <th>km_5_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146743638.12652.12652</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146743638.12667.12652</th>\n",
       "      <td>0.923923</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987788</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146842219.12874.12874</th>\n",
       "      <td>0.904788</td>\n",
       "      <td>0.933091</td>\n",
       "      <td>0.962390</td>\n",
       "      <td>0.904334</td>\n",
       "      <td>0.933777</td>\n",
       "      <td>0.967004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146860774.13072.13072</th>\n",
       "      <td>0.881840</td>\n",
       "      <td>0.985436</td>\n",
       "      <td>0.753976</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.814262</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11926.11926</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11944.11926</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893586</td>\n",
       "      <td>0.932266</td>\n",
       "      <td>0.967356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143902946.11991.11991</th>\n",
       "      <td>0.985922</td>\n",
       "      <td>0.840804</td>\n",
       "      <td>0.919971</td>\n",
       "      <td>0.916651</td>\n",
       "      <td>0.967571</td>\n",
       "      <td>0.714346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143945536.12065.12065</th>\n",
       "      <td>0.980050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144052463.12169.12169</th>\n",
       "      <td>0.929560</td>\n",
       "      <td>0.963447</td>\n",
       "      <td>0.959526</td>\n",
       "      <td>0.994848</td>\n",
       "      <td>0.922012</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144065917.12226.12226</th>\n",
       "      <td>0.991078</td>\n",
       "      <td>0.845476</td>\n",
       "      <td>0.996844</td>\n",
       "      <td>0.886332</td>\n",
       "      <td>0.950649</td>\n",
       "      <td>0.691565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       km_0_dist  km_1_dist  km_2_dist  km_3_dist  km_4_dist  \\\n",
       "146743638.12652.12652   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "146743638.12667.12652   0.923923   1.000000   1.000000   1.000000   0.987788   \n",
       "146842219.12874.12874   0.904788   0.933091   0.962390   0.904334   0.933777   \n",
       "146860774.13072.13072   0.881840   0.985436   0.753976   1.000000   0.814262   \n",
       "143890867.11926.11926   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "143890867.11944.11926   1.000000   1.000000   1.000000   0.893586   0.932266   \n",
       "143902946.11991.11991   0.985922   0.840804   0.919971   0.916651   0.967571   \n",
       "143945536.12065.12065   0.980050   1.000000   1.000000   0.937123   1.000000   \n",
       "144052463.12169.12169   0.929560   0.963447   0.959526   0.994848   0.922012   \n",
       "144065917.12226.12226   0.991078   0.845476   0.996844   0.886332   0.950649   \n",
       "\n",
       "                       km_5_dist  \n",
       "146743638.12652.12652   0.000000  \n",
       "146743638.12667.12652   1.000000  \n",
       "146842219.12874.12874   0.967004  \n",
       "146860774.13072.13072   1.000000  \n",
       "143890867.11926.11926   0.000000  \n",
       "143890867.11944.11926   0.967356  \n",
       "143902946.11991.11991   0.714346  \n",
       "143945536.12065.12065   0.971439  \n",
       "144052463.12169.12169   1.000000  \n",
       "144065917.12226.12226   0.691565  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ipython().config.get('IPKernelApp', {})['parent_appname'] = \"\" \n",
    "# fixing html display error when spacy / pandas are used (https://github.com/jupyter/notebook/issues/4369)\n",
    "\n",
    "# let's take a look at what the output looks like\n",
    "prompt_types.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Extract politeness strategies features\n",
    "\n",
    "Now we will extract the second type of pragmatic features described in the paper: politeness strategies. We can do this using convokit's PolitenessStrategies class. This class does not require any training, so we can just apply it directly to the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PolitenessStrategies()\n",
    "awry_corpus = ps.transform(awry_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to before, we will construct a feature matrix from the computed per-utterance features. In this case, the results can be found in the `politeness_strategies` metadata field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_politeness_==1st_person==</th>\n",
       "      <th>feature_politeness_==1st_person_pl.==</th>\n",
       "      <th>feature_politeness_==1st_person_start==</th>\n",
       "      <th>feature_politeness_==2nd_person==</th>\n",
       "      <th>feature_politeness_==2nd_person_start==</th>\n",
       "      <th>feature_politeness_==Apologizing==</th>\n",
       "      <th>feature_politeness_==Deference==</th>\n",
       "      <th>feature_politeness_==Direct_question==</th>\n",
       "      <th>feature_politeness_==Direct_start==</th>\n",
       "      <th>feature_politeness_==Factuality==</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_politeness_==HASHEDGE==</th>\n",
       "      <th>feature_politeness_==HASNEGATIVE==</th>\n",
       "      <th>feature_politeness_==HASPOSITIVE==</th>\n",
       "      <th>feature_politeness_==Hedges==</th>\n",
       "      <th>feature_politeness_==INDICATIVE==</th>\n",
       "      <th>feature_politeness_==Indirect_(btw)==</th>\n",
       "      <th>feature_politeness_==Indirect_(greeting)==</th>\n",
       "      <th>feature_politeness_==Please==</th>\n",
       "      <th>feature_politeness_==Please_start==</th>\n",
       "      <th>feature_politeness_==SUBJUNCTIVE==</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146743638.12652.12652</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146743638.12667.12652</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146842219.12874.12874</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146860774.13072.13072</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11926.11926</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11944.11926</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143902946.11991.11991</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143945536.12065.12065</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144052463.12169.12169</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144065917.12226.12226</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature_politeness_==1st_person==  \\\n",
       "146743638.12652.12652                                  0   \n",
       "146743638.12667.12652                                  1   \n",
       "146842219.12874.12874                                  1   \n",
       "146860774.13072.13072                                  1   \n",
       "143890867.11926.11926                                  0   \n",
       "143890867.11944.11926                                  0   \n",
       "143902946.11991.11991                                  0   \n",
       "143945536.12065.12065                                  0   \n",
       "144052463.12169.12169                                  1   \n",
       "144065917.12226.12226                                  0   \n",
       "\n",
       "                       feature_politeness_==1st_person_pl.==  \\\n",
       "146743638.12652.12652                                      0   \n",
       "146743638.12667.12652                                      0   \n",
       "146842219.12874.12874                                      0   \n",
       "146860774.13072.13072                                      0   \n",
       "143890867.11926.11926                                      0   \n",
       "143890867.11944.11926                                      0   \n",
       "143902946.11991.11991                                      0   \n",
       "143945536.12065.12065                                      0   \n",
       "144052463.12169.12169                                      0   \n",
       "144065917.12226.12226                                      0   \n",
       "\n",
       "                       feature_politeness_==1st_person_start==  \\\n",
       "146743638.12652.12652                                        0   \n",
       "146743638.12667.12652                                        1   \n",
       "146842219.12874.12874                                        1   \n",
       "146860774.13072.13072                                        1   \n",
       "143890867.11926.11926                                        0   \n",
       "143890867.11944.11926                                        0   \n",
       "143902946.11991.11991                                        0   \n",
       "143945536.12065.12065                                        0   \n",
       "144052463.12169.12169                                        0   \n",
       "144065917.12226.12226                                        1   \n",
       "\n",
       "                       feature_politeness_==2nd_person==  \\\n",
       "146743638.12652.12652                                  0   \n",
       "146743638.12667.12652                                  1   \n",
       "146842219.12874.12874                                  0   \n",
       "146860774.13072.13072                                  1   \n",
       "143890867.11926.11926                                  0   \n",
       "143890867.11944.11926                                  0   \n",
       "143902946.11991.11991                                  1   \n",
       "143945536.12065.12065                                  1   \n",
       "144052463.12169.12169                                  1   \n",
       "144065917.12226.12226                                  1   \n",
       "\n",
       "                       feature_politeness_==2nd_person_start==  \\\n",
       "146743638.12652.12652                                        0   \n",
       "146743638.12667.12652                                        0   \n",
       "146842219.12874.12874                                        0   \n",
       "146860774.13072.13072                                        0   \n",
       "143890867.11926.11926                                        0   \n",
       "143890867.11944.11926                                        0   \n",
       "143902946.11991.11991                                        0   \n",
       "143945536.12065.12065                                        0   \n",
       "144052463.12169.12169                                        0   \n",
       "144065917.12226.12226                                        0   \n",
       "\n",
       "                       feature_politeness_==Apologizing==  \\\n",
       "146743638.12652.12652                                   0   \n",
       "146743638.12667.12652                                   0   \n",
       "146842219.12874.12874                                   0   \n",
       "146860774.13072.13072                                   0   \n",
       "143890867.11926.11926                                   0   \n",
       "143890867.11944.11926                                   0   \n",
       "143902946.11991.11991                                   0   \n",
       "143945536.12065.12065                                   0   \n",
       "144052463.12169.12169                                   0   \n",
       "144065917.12226.12226                                   0   \n",
       "\n",
       "                       feature_politeness_==Deference==  \\\n",
       "146743638.12652.12652                                 0   \n",
       "146743638.12667.12652                                 0   \n",
       "146842219.12874.12874                                 0   \n",
       "146860774.13072.13072                                 0   \n",
       "143890867.11926.11926                                 0   \n",
       "143890867.11944.11926                                 0   \n",
       "143902946.11991.11991                                 0   \n",
       "143945536.12065.12065                                 0   \n",
       "144052463.12169.12169                                 0   \n",
       "144065917.12226.12226                                 0   \n",
       "\n",
       "                       feature_politeness_==Direct_question==  \\\n",
       "146743638.12652.12652                                       0   \n",
       "146743638.12667.12652                                       1   \n",
       "146842219.12874.12874                                       0   \n",
       "146860774.13072.13072                                       0   \n",
       "143890867.11926.11926                                       0   \n",
       "143890867.11944.11926                                       0   \n",
       "143902946.11991.11991                                       0   \n",
       "143945536.12065.12065                                       0   \n",
       "144052463.12169.12169                                       0   \n",
       "144065917.12226.12226                                       0   \n",
       "\n",
       "                       feature_politeness_==Direct_start==  \\\n",
       "146743638.12652.12652                                    0   \n",
       "146743638.12667.12652                                    0   \n",
       "146842219.12874.12874                                    0   \n",
       "146860774.13072.13072                                    1   \n",
       "143890867.11926.11926                                    0   \n",
       "143890867.11944.11926                                    0   \n",
       "143902946.11991.11991                                    0   \n",
       "143945536.12065.12065                                    0   \n",
       "144052463.12169.12169                                    0   \n",
       "144065917.12226.12226                                    0   \n",
       "\n",
       "                       feature_politeness_==Factuality==  \\\n",
       "146743638.12652.12652                                  0   \n",
       "146743638.12667.12652                                  0   \n",
       "146842219.12874.12874                                  0   \n",
       "146860774.13072.13072                                  0   \n",
       "143890867.11926.11926                                  0   \n",
       "143890867.11944.11926                                  0   \n",
       "143902946.11991.11991                                  0   \n",
       "143945536.12065.12065                                  1   \n",
       "144052463.12169.12169                                  0   \n",
       "144065917.12226.12226                                  0   \n",
       "\n",
       "                                      ...                  \\\n",
       "146743638.12652.12652                 ...                   \n",
       "146743638.12667.12652                 ...                   \n",
       "146842219.12874.12874                 ...                   \n",
       "146860774.13072.13072                 ...                   \n",
       "143890867.11926.11926                 ...                   \n",
       "143890867.11944.11926                 ...                   \n",
       "143902946.11991.11991                 ...                   \n",
       "143945536.12065.12065                 ...                   \n",
       "144052463.12169.12169                 ...                   \n",
       "144065917.12226.12226                 ...                   \n",
       "\n",
       "                       feature_politeness_==HASHEDGE==  \\\n",
       "146743638.12652.12652                                0   \n",
       "146743638.12667.12652                                1   \n",
       "146842219.12874.12874                                1   \n",
       "146860774.13072.13072                                1   \n",
       "143890867.11926.11926                                0   \n",
       "143890867.11944.11926                                1   \n",
       "143902946.11991.11991                                0   \n",
       "143945536.12065.12065                                0   \n",
       "144052463.12169.12169                                1   \n",
       "144065917.12226.12226                                1   \n",
       "\n",
       "                       feature_politeness_==HASNEGATIVE==  \\\n",
       "146743638.12652.12652                                   0   \n",
       "146743638.12667.12652                                   1   \n",
       "146842219.12874.12874                                   0   \n",
       "146860774.13072.13072                                   1   \n",
       "143890867.11926.11926                                   0   \n",
       "143890867.11944.11926                                   0   \n",
       "143902946.11991.11991                                   1   \n",
       "143945536.12065.12065                                   1   \n",
       "144052463.12169.12169                                   1   \n",
       "144065917.12226.12226                                   1   \n",
       "\n",
       "                       feature_politeness_==HASPOSITIVE==  \\\n",
       "146743638.12652.12652                                   0   \n",
       "146743638.12667.12652                                   1   \n",
       "146842219.12874.12874                                   1   \n",
       "146860774.13072.13072                                   1   \n",
       "143890867.11926.11926                                   0   \n",
       "143890867.11944.11926                                   1   \n",
       "143902946.11991.11991                                   1   \n",
       "143945536.12065.12065                                   1   \n",
       "144052463.12169.12169                                   0   \n",
       "144065917.12226.12226                                   0   \n",
       "\n",
       "                       feature_politeness_==Hedges==  \\\n",
       "146743638.12652.12652                              0   \n",
       "146743638.12667.12652                              1   \n",
       "146842219.12874.12874                              1   \n",
       "146860774.13072.13072                              1   \n",
       "143890867.11926.11926                              0   \n",
       "143890867.11944.11926                              0   \n",
       "143902946.11991.11991                              0   \n",
       "143945536.12065.12065                              0   \n",
       "144052463.12169.12169                              1   \n",
       "144065917.12226.12226                              1   \n",
       "\n",
       "                       feature_politeness_==INDICATIVE==  \\\n",
       "146743638.12652.12652                                  0   \n",
       "146743638.12667.12652                                  0   \n",
       "146842219.12874.12874                                  0   \n",
       "146860774.13072.13072                                  0   \n",
       "143890867.11926.11926                                  0   \n",
       "143890867.11944.11926                                  0   \n",
       "143902946.11991.11991                                  0   \n",
       "143945536.12065.12065                                  0   \n",
       "144052463.12169.12169                                  0   \n",
       "144065917.12226.12226                                  0   \n",
       "\n",
       "                       feature_politeness_==Indirect_(btw)==  \\\n",
       "146743638.12652.12652                                      0   \n",
       "146743638.12667.12652                                      0   \n",
       "146842219.12874.12874                                      0   \n",
       "146860774.13072.13072                                      0   \n",
       "143890867.11926.11926                                      0   \n",
       "143890867.11944.11926                                      0   \n",
       "143902946.11991.11991                                      0   \n",
       "143945536.12065.12065                                      0   \n",
       "144052463.12169.12169                                      0   \n",
       "144065917.12226.12226                                      0   \n",
       "\n",
       "                       feature_politeness_==Indirect_(greeting)==  \\\n",
       "146743638.12652.12652                                           0   \n",
       "146743638.12667.12652                                           0   \n",
       "146842219.12874.12874                                           0   \n",
       "146860774.13072.13072                                           0   \n",
       "143890867.11926.11926                                           0   \n",
       "143890867.11944.11926                                           0   \n",
       "143902946.11991.11991                                           0   \n",
       "143945536.12065.12065                                           0   \n",
       "144052463.12169.12169                                           0   \n",
       "144065917.12226.12226                                           0   \n",
       "\n",
       "                       feature_politeness_==Please==  \\\n",
       "146743638.12652.12652                              0   \n",
       "146743638.12667.12652                              0   \n",
       "146842219.12874.12874                              0   \n",
       "146860774.13072.13072                              0   \n",
       "143890867.11926.11926                              0   \n",
       "143890867.11944.11926                              0   \n",
       "143902946.11991.11991                              1   \n",
       "143945536.12065.12065                              0   \n",
       "144052463.12169.12169                              0   \n",
       "144065917.12226.12226                              0   \n",
       "\n",
       "                       feature_politeness_==Please_start==  \\\n",
       "146743638.12652.12652                                    0   \n",
       "146743638.12667.12652                                    0   \n",
       "146842219.12874.12874                                    0   \n",
       "146860774.13072.13072                                    0   \n",
       "143890867.11926.11926                                    0   \n",
       "143890867.11944.11926                                    0   \n",
       "143902946.11991.11991                                    1   \n",
       "143945536.12065.12065                                    0   \n",
       "144052463.12169.12169                                    0   \n",
       "144065917.12226.12226                                    1   \n",
       "\n",
       "                       feature_politeness_==SUBJUNCTIVE==  \n",
       "146743638.12652.12652                                   0  \n",
       "146743638.12667.12652                                   0  \n",
       "146842219.12874.12874                                   0  \n",
       "146860774.13072.13072                                   0  \n",
       "143890867.11926.11926                                   0  \n",
       "143890867.11944.11926                                   0  \n",
       "143902946.11991.11991                                   0  \n",
       "143945536.12065.12065                                   0  \n",
       "144052463.12169.12169                                   0  \n",
       "144065917.12226.12226                                   0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterance_ids = awry_corpus.get_utterance_ids()\n",
    "rows = []\n",
    "for uid in utterance_ids:\n",
    "    rows.append(awry_corpus.get_utterance(uid).meta[\"politeness_strategies\"])\n",
    "politeness_strategies = pd.DataFrame(rows, index=utterance_ids)\n",
    "politeness_strategies.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create pair data\n",
    "\n",
    "The prediction task defined in the paper is a paired task. The corpus downloaded from convokit already includes metadata about how conversations were paired for the paper, so we don't need to do any of the hard work here. Instead, we'll format the pair information into a table for use in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we need to directly map comment IDs to their conversations. We'll build a DataFrame to do this\n",
    "comment_ids = []\n",
    "convo_ids = []\n",
    "timestamps = []\n",
    "page_ids = []\n",
    "for conversation in awry_corpus.iter_conversations():\n",
    "    for comment in conversation.iter_utterances():\n",
    "        # section headers are included in the dataset for completeness, but for prediction we need to ignore\n",
    "        # them as they are not utterances\n",
    "        if not comment.meta[\"is_section_header\"]:\n",
    "            comment_ids.append(comment.id)\n",
    "            convo_ids.append(comment.root)\n",
    "            timestamps.append(comment.timestamp)\n",
    "            page_ids.append(conversation.meta[\"page_id\"])\n",
    "comment_df = pd.DataFrame({\"conversation_id\": convo_ids, \"timestamp\": timestamps, \"page_id\": page_ids}, index=comment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll do our construction using awry conversation ID's as the reference key\n",
    "awry_convo_ids = set()\n",
    "# these dicts will then all be keyed by awry ID\n",
    "good_convo_map = {}\n",
    "page_id_map = {}\n",
    "for conversation in awry_corpus.iter_conversations():\n",
    "    if conversation.meta[\"conversation_has_personal_attack\"] and conversation.id not in awry_convo_ids:\n",
    "        awry_convo_ids.add(conversation.id)\n",
    "        good_convo_map[conversation.id] = conversation.meta[\"pair_id\"]\n",
    "        page_id_map[conversation.id] = conversation.meta[\"page_id\"]\n",
    "awry_convo_ids = list(awry_convo_ids)\n",
    "pairs_df = pd.DataFrame({\"bad_conversation_id\": awry_convo_ids,\n",
    "                         \"conversation_id\": [good_convo_map[cid] for cid in awry_convo_ids],\n",
    "                         \"page_id\": [page_id_map[cid] for cid in awry_convo_ids]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, we will augment the pairs dataframe with the IDs of the first and second comment for both\n",
    "# the bad and good conversation. This will come in handy for constructing the feature matrix.\n",
    "first_ids = []\n",
    "second_ids = []\n",
    "first_ids_bad = []\n",
    "second_ids_bad = []\n",
    "for row in pairs_df.itertuples():\n",
    "    # \"first two\" is defined in terms of time of posting\n",
    "    comments_sorted = comment_df[comment_df.conversation_id==row.conversation_id].sort_values(by=\"timestamp\")\n",
    "    first_ids.append(comments_sorted.iloc[0].name)\n",
    "    second_ids.append(comments_sorted.iloc[1].name)\n",
    "    comments_sorted_bad = comment_df[comment_df.conversation_id==row.bad_conversation_id].sort_values(by=\"timestamp\")\n",
    "    first_ids_bad.append(comments_sorted_bad.iloc[0].name)\n",
    "    second_ids_bad.append(comments_sorted_bad.iloc[1].name)\n",
    "pairs_df = pairs_df.assign(first_id=first_ids, second_id=second_ids, \n",
    "                           bad_first_id=first_ids_bad, bad_second_id=second_ids_bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Construct feature matrix\n",
    "\n",
    "Now that we have the pair data, we can construct a table of pragmatic features for each pair, to use in prediction. This table will consist of the prompt types and politeness strategies for the first and second comment of each conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_for_convo(convo_id, first_comment_id, second_comment_id):\n",
    "\n",
    "    # get prompt type features\n",
    "    try:\n",
    "        first_prompts = prompt_types.loc[first_comment_id]\n",
    "    except:\n",
    "        first_prompts = pd.Series(data=np.ones(len(prompt_types.columns)), index=prompt_types.columns)\n",
    "    try:\n",
    "        second_prompts = prompt_types.loc[second_comment_id].rename({c: c + \"_second\" for c in prompt_types.columns})\n",
    "    except:\n",
    "        second_prompts = pd.Series(data=np.ones(len(prompt_types.columns)), index=[c + \"_second\" for c in prompt_types.columns])\n",
    "    prompts = first_prompts.append(second_prompts)\n",
    "    # get politeness strategies features\n",
    "    first_politeness = politeness_strategies.loc[first_comment_id]\n",
    "    second_politeness = politeness_strategies.loc[second_comment_id].rename({c: c + \"_second\" for c in politeness_strategies.columns})\n",
    "    politeness = first_politeness.append(second_politeness)\n",
    "    return politeness.append(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_ids = np.concatenate((pairs_df.conversation_id.values, pairs_df.bad_conversation_id.values))\n",
    "feats = [features_for_convo(row.conversation_id, row.first_id, row.second_id) for row in pairs_df.itertuples()] + \\\n",
    "        [features_for_convo(row.bad_conversation_id, row.bad_first_id, row.bad_second_id) for row in pairs_df.itertuples()]\n",
    "feature_table = pd.DataFrame(data=np.vstack([f.values for f in feats]), columns=feats[0].index, index=convo_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the paper, we dropped the sentiment lexicon based features (HASPOSITIVE and HASNEGATIVE), opting\n",
    "# to instead use them as a baseline. We do this here as well to be consistent with the paper.\n",
    "feature_table = feature_table.drop(columns=[\"feature_politeness_==HASPOSITIVE==\",\n",
    "                                            \"feature_politeness_==HASNEGATIVE==\",\n",
    "                                            \"feature_politeness_==HASPOSITIVE==_second\",\n",
    "                                            \"feature_politeness_==HASNEGATIVE==_second\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_politeness_==1st_person==</th>\n",
       "      <th>feature_politeness_==1st_person_pl.==</th>\n",
       "      <th>feature_politeness_==1st_person_start==</th>\n",
       "      <th>feature_politeness_==2nd_person==</th>\n",
       "      <th>feature_politeness_==2nd_person_start==</th>\n",
       "      <th>feature_politeness_==Apologizing==</th>\n",
       "      <th>feature_politeness_==Deference==</th>\n",
       "      <th>feature_politeness_==Direct_question==</th>\n",
       "      <th>feature_politeness_==Direct_start==</th>\n",
       "      <th>feature_politeness_==Factuality==</th>\n",
       "      <th>...</th>\n",
       "      <th>km_2_dist</th>\n",
       "      <th>km_3_dist</th>\n",
       "      <th>km_4_dist</th>\n",
       "      <th>km_5_dist</th>\n",
       "      <th>km_0_dist_second</th>\n",
       "      <th>km_1_dist_second</th>\n",
       "      <th>km_2_dist_second</th>\n",
       "      <th>km_3_dist_second</th>\n",
       "      <th>km_4_dist_second</th>\n",
       "      <th>km_5_dist_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>351432768.1226.1226</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977957</td>\n",
       "      <td>0.930525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.728473</td>\n",
       "      <td>0.981666</td>\n",
       "      <td>0.979661</td>\n",
       "      <td>0.975603</td>\n",
       "      <td>0.880087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70475487.1262.1239</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964696</td>\n",
       "      <td>0.927741</td>\n",
       "      <td>0.865463</td>\n",
       "      <td>0.929096</td>\n",
       "      <td>0.927851</td>\n",
       "      <td>0.959724</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.862154</td>\n",
       "      <td>0.940759</td>\n",
       "      <td>0.930614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200468806.12461.12461</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.854175</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972612</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104887604.5394.5394</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889971</td>\n",
       "      <td>0.936902</td>\n",
       "      <td>0.942025</td>\n",
       "      <td>0.966720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930947</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65058998.2939.2939</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963229</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.920382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988798</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature_politeness_==1st_person==  \\\n",
       "351432768.1226.1226                                  1.0   \n",
       "70475487.1262.1239                                   0.0   \n",
       "200468806.12461.12461                                1.0   \n",
       "104887604.5394.5394                                  1.0   \n",
       "65058998.2939.2939                                   1.0   \n",
       "\n",
       "                       feature_politeness_==1st_person_pl.==  \\\n",
       "351432768.1226.1226                                      0.0   \n",
       "70475487.1262.1239                                       0.0   \n",
       "200468806.12461.12461                                    0.0   \n",
       "104887604.5394.5394                                      0.0   \n",
       "65058998.2939.2939                                       0.0   \n",
       "\n",
       "                       feature_politeness_==1st_person_start==  \\\n",
       "351432768.1226.1226                                        0.0   \n",
       "70475487.1262.1239                                         0.0   \n",
       "200468806.12461.12461                                      1.0   \n",
       "104887604.5394.5394                                        0.0   \n",
       "65058998.2939.2939                                         1.0   \n",
       "\n",
       "                       feature_politeness_==2nd_person==  \\\n",
       "351432768.1226.1226                                  1.0   \n",
       "70475487.1262.1239                                   1.0   \n",
       "200468806.12461.12461                                1.0   \n",
       "104887604.5394.5394                                  0.0   \n",
       "65058998.2939.2939                                   1.0   \n",
       "\n",
       "                       feature_politeness_==2nd_person_start==  \\\n",
       "351432768.1226.1226                                        0.0   \n",
       "70475487.1262.1239                                         0.0   \n",
       "200468806.12461.12461                                      0.0   \n",
       "104887604.5394.5394                                        0.0   \n",
       "65058998.2939.2939                                         0.0   \n",
       "\n",
       "                       feature_politeness_==Apologizing==  \\\n",
       "351432768.1226.1226                                   0.0   \n",
       "70475487.1262.1239                                    0.0   \n",
       "200468806.12461.12461                                 0.0   \n",
       "104887604.5394.5394                                   0.0   \n",
       "65058998.2939.2939                                    0.0   \n",
       "\n",
       "                       feature_politeness_==Deference==  \\\n",
       "351432768.1226.1226                                 0.0   \n",
       "70475487.1262.1239                                  0.0   \n",
       "200468806.12461.12461                               0.0   \n",
       "104887604.5394.5394                                 0.0   \n",
       "65058998.2939.2939                                  0.0   \n",
       "\n",
       "                       feature_politeness_==Direct_question==  \\\n",
       "351432768.1226.1226                                       0.0   \n",
       "70475487.1262.1239                                        0.0   \n",
       "200468806.12461.12461                                     0.0   \n",
       "104887604.5394.5394                                       0.0   \n",
       "65058998.2939.2939                                        0.0   \n",
       "\n",
       "                       feature_politeness_==Direct_start==  \\\n",
       "351432768.1226.1226                                    0.0   \n",
       "70475487.1262.1239                                     0.0   \n",
       "200468806.12461.12461                                  0.0   \n",
       "104887604.5394.5394                                    0.0   \n",
       "65058998.2939.2939                                     0.0   \n",
       "\n",
       "                       feature_politeness_==Factuality==        ...         \\\n",
       "351432768.1226.1226                                  0.0        ...          \n",
       "70475487.1262.1239                                   0.0        ...          \n",
       "200468806.12461.12461                                0.0        ...          \n",
       "104887604.5394.5394                                  0.0        ...          \n",
       "65058998.2939.2939                                   0.0        ...          \n",
       "\n",
       "                       km_2_dist  km_3_dist  km_4_dist  km_5_dist  \\\n",
       "351432768.1226.1226     0.977957   0.930525   1.000000   0.728473   \n",
       "70475487.1262.1239      0.964696   0.927741   0.865463   0.929096   \n",
       "200468806.12461.12461   0.651960   1.000000   0.854175   1.000000   \n",
       "104887604.5394.5394     0.889971   0.936902   0.942025   0.966720   \n",
       "65058998.2939.2939      0.744375   1.000000   0.963229   0.849057   \n",
       "\n",
       "                       km_0_dist_second  km_1_dist_second  km_2_dist_second  \\\n",
       "351432768.1226.1226            0.981666          0.979661          0.975603   \n",
       "70475487.1262.1239             0.927851          0.959724          1.000000   \n",
       "200468806.12461.12461          1.000000          1.000000          1.000000   \n",
       "104887604.5394.5394            1.000000          1.000000          1.000000   \n",
       "65058998.2939.2939             0.920382          1.000000          1.000000   \n",
       "\n",
       "                       km_3_dist_second  km_4_dist_second  km_5_dist_second  \n",
       "351432768.1226.1226            0.880087          1.000000          0.891322  \n",
       "70475487.1262.1239             0.862154          0.940759          0.930614  \n",
       "200468806.12461.12461          0.972612          1.000000          1.000000  \n",
       "104887604.5394.5394            0.930947          1.000000          1.000000  \n",
       "65058998.2939.2939             0.988798          1.000000          1.000000  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how it looks\n",
    "feature_table.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Prediction Utils\n",
    "\n",
    "We're almost ready to do the prediction! First we need to define a few helper functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(seq):\n",
    "    vals, counts = np.unique(seq, return_counts=True)\n",
    "    return vals[np.argmax(counts)]\n",
    "\n",
    "def run_pred_single(inputs, X, y):\n",
    "    f_idx, (train_idx, test_idx) = inputs\n",
    "    \n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    base_clf = Pipeline([(\"scaler\", StandardScaler()), (\"featselect\", SelectPercentile(f_classif, 10)), (\"logreg\", LogisticRegression(solver='liblinear'))])\n",
    "    clf = GridSearchCV(base_clf, {\"logreg__C\": [10**i for i in range(-4,4)], \"featselect__percentile\": list(range(10, 110, 10))}, cv=3)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_scores = clf.predict_proba(X_test)[:,1]\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    feature_weights = clf.best_estimator_.named_steps[\"logreg\"].coef_.flatten()\n",
    "    feature_mask = clf.best_estimator_.named_steps[\"featselect\"].get_support()\n",
    "    \n",
    "    hyperparams = clf.best_params_\n",
    "    \n",
    "    return (y_pred, y_scores, feature_weights, hyperparams, feature_mask)\n",
    "\n",
    "def run_pred(X, y, fnames, groups):\n",
    "    feature_weights = {}\n",
    "    scores = np.asarray([np.nan for i in range(len(y))])\n",
    "    y_pred = np.zeros(len(y))\n",
    "    hyperparameters = defaultdict(list)\n",
    "    splits = list(enumerate(LeaveOneGroupOut().split(X, y, groups)))\n",
    "    accs = []\n",
    "        \n",
    "    with Pool(os.cpu_count()) as p:\n",
    "        prediction_results = p.map(partial(run_pred_single, X=X, y=y), splits)\n",
    "        \n",
    "    fselect_pvals_all = []\n",
    "    for i in range(len(splits)):\n",
    "        f_idx, (train_idx, test_idx) = splits[i]\n",
    "        y_pred_i, y_scores_i, weights_i, hyperparams_i, mask_i = prediction_results[i]\n",
    "        y_pred[test_idx] = y_pred_i\n",
    "        scores[test_idx] = y_scores_i\n",
    "        feature_weights[f_idx] = np.asarray([np.nan for _ in range(len(fnames))])\n",
    "        feature_weights[f_idx][mask_i] = weights_i\n",
    "        for param in hyperparams_i:\n",
    "            hyperparameters[param].append(hyperparams_i[param])   \n",
    "    \n",
    "    acc = np.mean(y_pred == y)\n",
    "    pvalue = stats.binom_test(sum(y_pred == y), n=len(y), alternative=\"greater\")\n",
    "                \n",
    "    coef_df = pd.DataFrame(feature_weights, index=fnames)\n",
    "    coef_df['mean_coef'] = coef_df.apply(np.nanmean, axis=1)\n",
    "    coef_df['std_coef'] = coef_df.apply(np.nanstd, axis=1)\n",
    "    return acc, coef_df[['mean_coef', 'std_coef']], scores, pd.DataFrame(hyperparameters), pvalue\n",
    "\n",
    "def get_labeled_pairs(pairs_df):\n",
    "    paired_labels = []\n",
    "    c0s = []\n",
    "    c1s = []\n",
    "    page_ids = []\n",
    "    for i, row in enumerate(pairs_df.itertuples()):\n",
    "        if i % 2 == 0:\n",
    "            c0s.append(row.conversation_id)\n",
    "            c1s.append(row.bad_conversation_id)\n",
    "        else:\n",
    "            c0s.append(row.bad_conversation_id)\n",
    "            c1s.append(row.conversation_id)\n",
    "        paired_labels.append(i%2)\n",
    "        page_ids.append(row.page_id)\n",
    "    return pd.DataFrame({\"c0\": c0s, \"c1\": c1s,\"first_convo_toxic\": paired_labels, \"page_id\": page_ids})\n",
    "\n",
    "def get_feature_subset(labeled_pairs_df, feature_list):\n",
    "    prompt_type_names = [\"km_%d_dist\" % i for i in range(6)] + [\"km_%d_dist_second\" % i for i in range(6)]\n",
    "    politeness_names = [f for f in feature_table.columns if f not in prompt_type_names]\n",
    "    \n",
    "    features_to_use = []\n",
    "    if \"prompt_types\" in feature_list:\n",
    "        features_to_use += prompt_type_names\n",
    "    if \"politeness_strategies\" in feature_list:\n",
    "        features_to_use += politeness_names\n",
    "        \n",
    "    feature_subset = feature_table[features_to_use]\n",
    "    \n",
    "    c0_feats = feature_subset.loc[labeled_pairs_df.c0].values\n",
    "    c1_feats = feature_subset.loc[labeled_pairs_df.c1].values\n",
    "    \n",
    "    return c0_feats, c1_feats, features_to_use\n",
    "\n",
    "def run_pipeline(feature_set):\n",
    "    print(\"Running prediction task for feature set\", \"+\".join(feature_set))\n",
    "    print(\"Generating labels...\")\n",
    "    labeled_pairs_df = get_labeled_pairs(pairs_df)\n",
    "    print(\"Computing paired features...\")\n",
    "    X_c0, X_c1, feature_names = get_feature_subset(labeled_pairs_df, feature_set)\n",
    "    X = X_c1 - X_c0\n",
    "    print(\"Using\", X.shape[1], \"features\")\n",
    "    y = labeled_pairs_df.first_convo_toxic.values\n",
    "    print(\"Running leave-one-page-out prediction...\")\n",
    "    accuracy, coefs, scores, hyperparams, pvalue = run_pred(X, y, feature_names, labeled_pairs_df.page_id)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"p-value: %.4e\" % pvalue)\n",
    "    print(\"C (mode):\", mode(hyperparams.logreg__C))\n",
    "    print(\"Percent of features (mode):\", mode(hyperparams.featselect__percentile))\n",
    "    print(\"Coefficents:\")\n",
    "    print(coefs.sort_values(by=\"mean_coef\"))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Prediction\n",
    "\n",
    "Finally, we run the prediction task on each possible combination of pragmatic features: prompt types, politeness strategies, and both combined. We generate a table like Table 3 from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running prediction task for feature set politeness_strategies\n",
      "Generating labels...\n",
      "Computing paired features...\n",
      "Using 38 features\n",
      "Running leave-one-page-out prediction...\n",
      "Accuracy: 0.583904109589041\n",
      "p-value: 2.8776e-05\n",
      "C (mode): 0.01\n",
      "Percent of features (mode): 70\n",
      "Coefficents:\n",
      "                                                   mean_coef  std_coef\n",
      "feature_politeness_==2nd_person==_second           -0.143045  0.101528\n",
      "feature_politeness_==2nd_person_start==            -0.119936  0.083688\n",
      "feature_politeness_==Direct_question==             -0.093094  0.059778\n",
      "feature_politeness_==2nd_person_start==_second     -0.089930  0.060446\n",
      "feature_politeness_==Direct_question==_second      -0.069404  0.045657\n",
      "feature_politeness_==Please_start==_second         -0.053513  0.034739\n",
      "feature_politeness_==Please==                      -0.037547  0.023493\n",
      "feature_politeness_==Factuality==                  -0.031830  0.023429\n",
      "feature_politeness_==Indirect_(btw)==              -0.017527  0.022944\n",
      "feature_politeness_==Please==_second               -0.017169  0.010292\n",
      "feature_politeness_==Direct_start==_second         -0.015260  0.014589\n",
      "feature_politeness_==2nd_person==                  -0.015115  0.011816\n",
      "feature_politeness_==INDICATIVE==                  -0.013437  0.007647\n",
      "feature_politeness_==Direct_start==                -0.010501  0.006353\n",
      "feature_politeness_==Please_start==                -0.003896  0.003130\n",
      "feature_politeness_==SUBJUNCTIVE==                 -0.000382  0.001617\n",
      "feature_politeness_==1st_person_pl.==               0.000966  0.000486\n",
      "feature_politeness_==1st_person_pl.==_second        0.005524  0.006805\n",
      "feature_politeness_==1st_person==                   0.007936  0.004891\n",
      "feature_politeness_==Indirect_(greeting)==_second   0.009856  0.005769\n",
      "feature_politeness_==1st_person_start==             0.010947  0.008216\n",
      "feature_politeness_==Apologizing==                  0.010967  0.008334\n",
      "feature_politeness_==Indirect_(btw)==_second        0.011051  0.010484\n",
      "feature_politeness_==Factuality==_second            0.012365  0.006573\n",
      "feature_politeness_==Deference==                    0.016130  0.014772\n",
      "feature_politeness_==Hedges==_second                0.019722  0.016006\n",
      "feature_politeness_==Deference==_second             0.030635  0.020662\n",
      "feature_politeness_==Hedges==                       0.040562  0.024514\n",
      "feature_politeness_==1st_person_start==_second      0.044660  0.026133\n",
      "feature_politeness_==INDICATIVE==_second            0.047160  0.037757\n",
      "feature_politeness_==Apologizing==_second           0.049119  0.034166\n",
      "feature_politeness_==HASHEDGE==                     0.061399  0.040193\n",
      "feature_politeness_==1st_person==_second            0.064122  0.040089\n",
      "feature_politeness_==Gratitude==                    0.065774  0.046961\n",
      "feature_politeness_==Indirect_(greeting)==          0.066267  0.047380\n",
      "feature_politeness_==Gratitude==_second             0.076366  0.052291\n",
      "feature_politeness_==HASHEDGE==_second              0.102313  0.073541\n",
      "feature_politeness_==SUBJUNCTIVE==_second           0.115053  0.093719\n",
      "Running prediction task for feature set prompt_types\n",
      "Generating labels...\n",
      "Computing paired features...\n",
      "Using 12 features\n",
      "Running leave-one-page-out prediction...\n",
      "Accuracy: 0.565068493150685\n",
      "p-value: 9.4381e-04\n",
      "C (mode): 0.01\n",
      "Percent of features (mode): 30\n",
      "Coefficents:\n",
      "                  mean_coef  std_coef\n",
      "km_0_dist         -0.473318  0.329004\n",
      "km_0_dist_second  -0.149193  0.198305\n",
      "km_2_dist         -0.113339  0.105536\n",
      "km_2_dist_second  -0.093957  0.098238\n",
      "km_1_dist         -0.038165  0.015230\n",
      "km_4_dist_second   0.001674  0.039190\n",
      "km_1_dist_second   0.050015  0.015963\n",
      "km_3_dist_second   0.134347  0.012698\n",
      "km_5_dist          0.241463  0.026124\n",
      "km_4_dist          0.318390  0.095596\n",
      "km_5_dist_second   0.423363  0.057945\n",
      "km_3_dist          0.427423  0.050105\n",
      "Running prediction task for feature set politeness_strategies+prompt_types\n",
      "Generating labels...\n",
      "Computing paired features...\n",
      "Using 50 features\n",
      "Running leave-one-page-out prediction...\n",
      "Accuracy: 0.583904109589041\n",
      "p-value: 2.8776e-05\n",
      "C (mode): 10.0\n",
      "Percent of features (mode): 50\n",
      "Coefficents:\n",
      "                                                   mean_coef  std_coef\n",
      "km_2_dist                                          -0.397692  0.168294\n",
      "feature_politeness_==2nd_person==_second           -0.290938  0.053299\n",
      "feature_politeness_==2nd_person_start==            -0.241659  0.045560\n",
      "km_2_dist_second                                   -0.238315  0.080545\n",
      "feature_politeness_==2nd_person_start==_second     -0.180419  0.034882\n",
      "feature_politeness_==Direct_question==             -0.148852  0.019532\n",
      "feature_politeness_==Direct_question==_second      -0.128156  0.021431\n",
      "feature_politeness_==Please_start==_second         -0.088989  0.022762\n",
      "km_0_dist                                          -0.083836  0.054699\n",
      "feature_politeness_==Indirect_(btw)==              -0.081917  0.040583\n",
      "feature_politeness_==Factuality==                  -0.066499  0.018085\n",
      "feature_politeness_==Direct_start==_second         -0.065291  0.011108\n",
      "feature_politeness_==Please==                      -0.062838  0.026935\n",
      "km_4_dist_second                                   -0.042905  0.018085\n",
      "feature_politeness_==1st_person==                  -0.032860  0.026256\n",
      "feature_politeness_==INDICATIVE==                  -0.030337  0.009000\n",
      "feature_politeness_==2nd_person==                  -0.029039  0.006908\n",
      "feature_politeness_==Direct_start==                -0.025003  0.010509\n",
      "feature_politeness_==Please==_second               -0.011010  0.016755\n",
      "feature_politeness_==1st_person_pl.==               0.000837  0.000000\n",
      "feature_politeness_==SUBJUNCTIVE==                  0.001373  0.000000\n",
      "km_3_dist_second                                    0.002403  0.000000\n",
      "feature_politeness_==1st_person_start==             0.002735  0.006628\n",
      "km_3_dist                                           0.005634  0.000000\n",
      "feature_politeness_==Indirect_(greeting)==_second   0.013314  0.004654\n",
      "feature_politeness_==Deference==                    0.014468  0.008871\n",
      "feature_politeness_==Hedges==_second                0.019559  0.010522\n",
      "feature_politeness_==Apologizing==                  0.027912  0.005110\n",
      "feature_politeness_==Factuality==_second            0.032016  0.016131\n",
      "km_1_dist                                           0.032984  0.017754\n",
      "feature_politeness_==Indirect_(btw)==_second        0.036670  0.006999\n",
      "feature_politeness_==1st_person_pl.==_second        0.054443  0.010983\n",
      "feature_politeness_==Please_start==                 0.058439  0.017536\n",
      "feature_politeness_==Hedges==                       0.059257  0.008288\n",
      "feature_politeness_==1st_person_start==_second      0.059637  0.006672\n",
      "feature_politeness_==Deference==_second             0.063810  0.014029\n",
      "feature_politeness_==Apologizing==_second           0.098300  0.018138\n",
      "feature_politeness_==Indirect_(greeting)==          0.104859  0.015676\n",
      "feature_politeness_==INDICATIVE==_second            0.111074  0.033104\n",
      "feature_politeness_==Gratitude==                    0.118279  0.019274\n",
      "feature_politeness_==1st_person==_second            0.120423  0.017044\n",
      "km_1_dist_second                                    0.121026  0.090851\n",
      "feature_politeness_==Gratitude==_second             0.134666  0.021460\n",
      "km_0_dist_second                                    0.137362  0.124380\n",
      "feature_politeness_==HASHEDGE==                     0.143323  0.025640\n",
      "feature_politeness_==HASHEDGE==_second              0.219188  0.044249\n",
      "km_5_dist_second                                    0.225580  0.054816\n",
      "feature_politeness_==SUBJUNCTIVE==_second           0.260572  0.058179\n",
      "km_5_dist                                           0.325240  0.095802\n",
      "km_4_dist                                           0.345938  0.219024\n"
     ]
    }
   ],
   "source": [
    "# silence warnings since otherwise feature selection may throw a lot of warnings regarding constant features (some politeness strategies) during cross validation\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "feature_combos = [[\"politeness_strategies\"], [\"prompt_types\"], [\"politeness_strategies\", \"prompt_types\"]]\n",
    "combo_names = []\n",
    "accs = []\n",
    "for combo in feature_combos:\n",
    "    combo_names.append(\"+\".join(combo).replace(\"_\", \" \"))\n",
    "    accuracy = run_pipeline(combo)\n",
    "    accs.append(accuracy)\n",
    "results_df = pd.DataFrame({\"Accuracy\": accs}, index=combo_names)\n",
    "results_df.index.name = \"Feature set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature set</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>politeness strategies</th>\n",
       "      <td>0.583904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt types</th>\n",
       "      <td>0.565068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politeness strategies+prompt types</th>\n",
       "      <td>0.583904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Accuracy\n",
       "Feature set                                 \n",
       "politeness strategies               0.583904\n",
       "prompt types                        0.565068\n",
       "politeness strategies+prompt types  0.583904"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see the table\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Comparing features exhibited\n",
    "\n",
    "We can also compare how often the pragmatic devices we extracted occur in the initial exchanges of conversations that turn awry, vs. conversations that stay on track. We will compute log-odds ratios of each device, comparing the awry and on-track conversations; we will also compute significance values from binomal tests comparing the proportion of awry-turning conversations exhibiting a particular device to the proportion of on-track conversations.\n",
    "\n",
    "Since we've already got the pragmatic features precomputed, and our dataset of pairs compiled, it remains to compute the effect sizes and statistical significances, and plot these values, producing a plot like Figure 2 from the paper.\n",
    "\n",
    "Note: due to changes in SpaCy's dependency parsing that took place between the original time of publication and the updated release of this code, the extracted features may differ slightly from the ones used in the paper, so the resulting figure may differ slightly from the one in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up the politeness features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_feature_name(feat):\n",
    "    new_feat = feat.replace('feature_politeness','').replace('==','').replace('_', ' ')\n",
    "    split = new_feat.split()\n",
    "    first, rest = split[0], ' '.join(split[1:]).lower()\n",
    "    if first[0].isalpha():\n",
    "        first = first.title()\n",
    "    if 'Hashedge' in first:\n",
    "        return 'Hedge (lexicon)'\n",
    "    if 'Hedges' in first:\n",
    "        return 'Hedge (dep. tree)'\n",
    "    if 'greeting' in feat:\n",
    "        return 'Greetings'\n",
    "    cleaner_str = first + ' ' + rest\n",
    "    cleaner_str = cleaner_str.replace('2nd', '2$\\mathregular{^{nd}}$').replace('1st', '1$\\mathregular{^{st}}$')\n",
    "    return cleaner_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "politeness_strategies = politeness_strategies[[col for col in politeness_strategies.columns \n",
    "                              if col not in ['feature_politeness_==HASNEGATIVE==', 'feature_politeness_==HASPOSITIVE==']]]\n",
    "politeness_strategies.columns = [clean_feature_name(col) for col in politeness_strategies.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up prompt types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_type_names = ['Prompt: Opinion', 'Prompt: Action statement', 'Prompt: Coordination',\n",
    "                     'Prompt: Factual check', 'Prompt: Casual remark', 'Prompt: Moderation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we are now counting the number of times comments were assigned to *particular* prompt types, \n",
    "# we will use cluster assignments rather than distances\n",
    "prompt_type_assignments = np.zeros_like(prompt_types)\n",
    "prompt_type_assignments[np.arange(len(prompt_types)),prompt_types.values.argmin(axis=1)] = 1\n",
    "prompt_type_assignment_df = pd.DataFrame(columns=prompt_type_names, index=prompt_types.index, \n",
    "                                        data=prompt_type_assignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a table of combined features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.concat([prompt_type_assignment_df, politeness_strategies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group features by clean versus toxic conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox_first_comment_features =pairs_df[['bad_first_id']].join(all_features, how='left', on='bad_first_id')[all_features.columns]\n",
    "ntox_first_comment_features =pairs_df[['first_id']].join(all_features, how='left', on='first_id')[all_features.columns]\n",
    "\n",
    "tox_second_comment_features =pairs_df[['bad_second_id']].join(all_features, how='left', on='bad_second_id')[all_features.columns]\n",
    "ntox_second_comment_features =pairs_df[['second_id']].join(all_features, how='left', on='second_id')[all_features.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_stars(x):\n",
    "    if x < .001: return '***'\n",
    "    elif x < .01: return '**'\n",
    "    elif x < .05: return '*'\n",
    "    else: return ''\n",
    "def compare_tox(df_ntox, df_tox,  min_n=0):\n",
    "    cols = df_ntox.columns\n",
    "    num_feats_in_tox = df_tox[cols].sum().astype(int).rename('num_feat_tox')\n",
    "    num_nfeats_in_tox = (1 - df_tox[cols]).sum().astype(int).rename('num_nfeat_tox')\n",
    "    num_feats_in_ntox = df_ntox[cols].sum().astype(int).rename('num_feat_ntox')\n",
    "    num_nfeats_in_ntox = (1 - df_ntox[cols]).sum().astype(int).rename('num_nfeat_ntox')\n",
    "    prop_tox = df_tox[cols].mean().rename('prop_tox')\n",
    "    ref_prop_ntox = df_ntox[cols].mean().rename('prop_ntox')\n",
    "    n_tox = len(df_tox)\n",
    "    df = pd.concat([\n",
    "        num_feats_in_tox, \n",
    "        num_nfeats_in_tox,\n",
    "        num_feats_in_ntox,\n",
    "        num_nfeats_in_ntox,\n",
    "        prop_tox,\n",
    "        ref_prop_ntox,\n",
    "    ], axis=1)\n",
    "    df['num_total'] = df.num_feat_tox + df.num_feat_ntox\n",
    "    df['log_odds'] = np.log(df.num_feat_tox) - np.log(df.num_nfeat_tox) \\\n",
    "        + np.log(df.num_nfeat_ntox) - np.log(df.num_feat_ntox)\n",
    "    df['abs_log_odds'] = np.abs(df.log_odds)\n",
    "    df['binom_p'] = df.apply(lambda x: stats.binom_test(x.num_feat_tox, n_tox, x.prop_ntox), axis=1)\n",
    "    df = df[df.num_total >= min_n]\n",
    "    df['p'] = df['binom_p'].apply(lambda x: '%.3f' % x)\n",
    "    df['pstars'] = df['binom_p'].apply(get_p_stars)\n",
    "    return df.sort_values('log_odds', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_comparisons = compare_tox(ntox_first_comment_features, tox_first_comment_features)\n",
    "second_comparisons = compare_tox(ntox_second_comment_features, tox_second_comment_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are now ready to plot these comparisons. the following (rather intimidating) helper function \n",
    "# produces a nicely-formatted plot:\n",
    "def draw_figure(ax, first_cmp, second_cmp, title='', prompt_types=6, min_log_odds=.2, min_freq=50,xlim=.85):\n",
    "\n",
    "    # selecting and sorting the features to plot, given minimum effect sizes and statistical significance\n",
    "    frequent_feats = first_cmp[first_cmp.num_total >= min_freq].index.union(second_cmp[second_cmp.num_total >= min_freq].index)\n",
    "    lrg_effect_feats = first_cmp[(first_cmp.abs_log_odds >= .2)\n",
    "                                & (first_cmp.binom_p < .05)].index.union(second_cmp[(second_cmp.abs_log_odds >= .2)\n",
    "                                                                                  & (second_cmp.binom_p < .05)].index)\n",
    "    feats_to_include = frequent_feats.intersection(lrg_effect_feats)\n",
    "    feat_order = sorted(feats_to_include, key=lambda x: first_cmp.loc[x].log_odds, reverse=True)\n",
    "\n",
    "    # parameters determining the look of the figure\n",
    "    colors = ['darkorchid', 'seagreen']\n",
    "    shapes = ['d', 's']    \n",
    "    eps = .02\n",
    "    star_eps = .035\n",
    "    xlim = xlim\n",
    "    min_log = .2\n",
    "    gap_prop = 2\n",
    "    label_size = 14\n",
    "    title_size=18\n",
    "    radius = 144\n",
    "    features = feat_order\n",
    "    ax.invert_yaxis()\n",
    "    ax.plot([0,0], [0, len(features)/gap_prop], color='black')\n",
    "    \n",
    "    # for each figure we plot the point according to effect size in the first and second comment, \n",
    "    # and add axis labels denoting statistical significance\n",
    "    yticks = []\n",
    "    yticklabels = []\n",
    "    for f_idx, feat in enumerate(features):\n",
    "        curr_y = (f_idx + .5)/gap_prop\n",
    "        yticks.append(curr_y)\n",
    "        try:\n",
    "            \n",
    "            first_p = first_cmp.loc[feat].binom_p\n",
    "            second_p = second_cmp.loc[feat].binom_p            \n",
    "            if first_cmp.loc[feat].abs_log_odds < min_log:\n",
    "                first_face = \"white\"\n",
    "            elif first_p >= 0.05:\n",
    "                first_face = 'white'\n",
    "            else:\n",
    "                first_face = colors[0]\n",
    "            if second_cmp.loc[feat].abs_log_odds < min_log:\n",
    "                second_face = \"white\"\n",
    "            elif second_p >= 0.05:\n",
    "                second_face = 'white'\n",
    "            else:\n",
    "                second_face = colors[1]\n",
    "            ax.plot([-1 * xlim, xlim], [curr_y, curr_y], '--', color='grey', zorder=0, linewidth=.5)\n",
    "            \n",
    "            ax.scatter([first_cmp.loc[feat].log_odds], [curr_y + eps], s=radius, edgecolor=colors[0], marker=shapes[0],\n",
    "                        zorder=20, facecolors=first_face)\n",
    "            ax.scatter([second_cmp.loc[feat].log_odds], [curr_y + eps], s=radius, edgecolor=colors[1], marker=shapes[1], \n",
    "                       zorder=10, facecolors=second_face)\n",
    "            \n",
    "            first_pstr_len = len(get_p_stars(first_p))\n",
    "            second_pstr_len = len(get_p_stars(second_p))\n",
    "            p_str = np.array([' '] * 8)\n",
    "            if first_pstr_len > 0:\n",
    "                p_str[:first_pstr_len] = '*'\n",
    "            if second_pstr_len > 0:\n",
    "                p_str[-second_pstr_len:] = 'âº'\n",
    "            \n",
    "            feat_str = feat + '\\n' + ''.join(p_str)\n",
    "            yticklabels.append(feat_str)\n",
    "        except Exception as e:\n",
    "            yticklabels.append('')\n",
    "    \n",
    "    # add the axis labels\n",
    "    ax.set_xlabel('log-odds ratio', fontsize=14, family='serif')\n",
    "    ax.set_xticks([-xlim-.05, -.5, 0, .5, xlim])\n",
    "    ax.set_xticklabels(['on-track', -.5, 0, .5, 'awry'], fontsize=14, family='serif')\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels(yticklabels, fontsize=16, family='serif')\n",
    "    ax.tick_params(axis='both',  which='both', bottom='off',  top='off',left='off')\n",
    "    if title != '':\n",
    "        ax.text(0, (len(features) + 2.25)/ gap_prop, title, fontsize=title_size, family='serif',horizontalalignment='center',)\n",
    "    return feat_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1,1, figsize=(5,10))\n",
    "_ = draw_figure(ax, first_comparisons, second_comparisons, 'First & second comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
