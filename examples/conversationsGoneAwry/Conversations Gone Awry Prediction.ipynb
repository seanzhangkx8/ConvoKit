{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Conversations Gone Awry With Convokit\n",
    "\n",
    "This interactive tutorial demonstrates how to predict whether a conversation will eventually lead to a personal attack, as seen in the paper [Conversations Gone Awry: Detecting Early Signs of Conversational Failure](http://www.cs.cornell.edu/~cristian/Conversations_gone_awry.html), using the tools provided by convokit. It also serves as an illustration of how to use two of convokit's main features: question typology and politeness strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pkg_resources\n",
    "import json\n",
    "import itertools\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut\n",
    "from sklearn.feature_selection import f_classif, SelectPercentile\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from itertools import combinations\n",
    "\n",
    "from convokit import Corpus, QuestionTypology, download, MotifsExtractor, QuestionTypologyUtils, PolitenessStrategies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Conversations Gone Awry corpus, provided as part of convokit\n",
    "if not os.path.exists(os.path.join(pkg_resources.resource_filename(\"convokit\", \"\"), \"downloads\", \"conversations-gone-awry-corpus\")):\n",
    "    download(\"conversations-gone-awry-corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a convokit Corpus object from the downloaded data. The Corpus class provides functionality for\n",
    "# convenient manipulation of text corpora.\n",
    "awry_corpus = Corpus(filename=os.path.join(pkg_resources.resource_filename(\"convokit\", \"\"), \"downloads\", \"conversations-gone-awry-corpus\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract prompt types features\n",
    "\n",
    "In this step, we will extract the first of the two types of pragmatic features seen in the paper: prompt types. We can learn prompt types and compute types for each utterance in the corpus using convokit's QuestionTypology class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will train the QuestionTypology object on convokit's wiki corpus. Let's first download the corpus...\n",
    "if not os.path.exists(os.path.join(pkg_resources.resource_filename(\"convokit\", \"\"), \"downloads\", \"wiki-corpus\")):\n",
    "    download(\"wiki-corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now train a QuestionTypology object on the downloaded wiki corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building q-a matrices\n",
      "matrix dir /home/jonathan/research/Cornell-Conversational-Analysis-Toolkit/convokit/downloads/wiki-corpus-awry-matrix exists!\n",
      "\treading arcs and motifs\n",
      "\t1000000\n",
      "\t2000000\n",
      "\t3000000\n",
      "\t4000000\n",
      "\t5000000\n",
      "\t6000000\n",
      "\tbuilding matrices\n",
      "\twriting stuff\n",
      "reading question tidxes\n",
      "reading question leaves\n",
      "reading answer tidxes\n",
      "reading question didxes\n",
      "reading answer didxes\n",
      "reading question terms\n",
      "reading answer terms\n",
      "reading docs\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# some parameters to get us started. Note that \"dataset name\" refers not to the name of the *source* dataset,\n",
    "# but the name we want to give to trained output files of the QuestionTypology object. We could have given\n",
    "# any name we liked - we chose \"wiki-corpus-awry\" to keep things clear.\n",
    "dataset_name = \"wiki-corpus-awry\"\n",
    "num_clusters = 6\n",
    "\n",
    "# load the wiki corpus into a convokit Corpus object\n",
    "data_dir = os.path.join(pkg_resources.resource_filename(\"convokit\", \"\"), 'downloads')\n",
    "corpus = Corpus(filename=os.path.join(data_dir, 'wiki-corpus'))\n",
    "\n",
    "# if this is our first time running this example, we need to fit motifs on the\n",
    "# dataset. If we have run it before, just load the previously computed motifs\n",
    "motifs_dir = os.path.join(data_dir, dataset_name + \"-motifs\")\n",
    "if not os.path.exists(motifs_dir):\n",
    "    motifs_dir = None\n",
    "\n",
    "questionTypology = QuestionTypology(corpus, data_dir, dataset_name=dataset_name, motifs_dir=motifs_dir,\n",
    "                                    num_dims=50, num_clusters=6, question_threshold=100, answer_threshold=100, \n",
    "                                    verbose=1000000, random_seed=2018, min_support=20,\n",
    "                                    questions_only=False, enforce_formatting=False,\n",
    "                                    spacy_dir=\"/scratch/convokit_spacy_dump\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the QuestionTypology object has been trained, we can use it to compute prompt types for our awry corpus (notice that this is a different corpus from what the QuestionTypology object was trained on!). For our purposes, we want the raw features, which are distances from the centers of the KMeans clusters corresponding to each prompt type. We can get these using the `get_qtype_dists` method. Note that in most other situations, where we want just the prompt type, we can use the QuestionTypology object as a Callable, which will return an integer prompt type for each utterance in the corpus. We could also use the `compute_type` function, which is aliased to do the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_types = questionTypology.get_qtype_dists(awry_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>km_0_dist</th>\n",
       "      <th>km_1_dist</th>\n",
       "      <th>km_2_dist</th>\n",
       "      <th>km_3_dist</th>\n",
       "      <th>km_4_dist</th>\n",
       "      <th>km_5_dist</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146743638.12667.12652</th>\n",
       "      <td>0.988895</td>\n",
       "      <td>1.100313</td>\n",
       "      <td>0.925354</td>\n",
       "      <td>1.052824</td>\n",
       "      <td>0.998516</td>\n",
       "      <td>1.063603</td>\n",
       "      <td>I notice that earier that  moved wiki_link to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146842219.12874.12874</th>\n",
       "      <td>0.934950</td>\n",
       "      <td>0.959767</td>\n",
       "      <td>0.906565</td>\n",
       "      <td>0.963544</td>\n",
       "      <td>0.903838</td>\n",
       "      <td>0.931161</td>\n",
       "      <td>Chen was known in the poker world as \"William\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146860774.13072.13072</th>\n",
       "      <td>0.825559</td>\n",
       "      <td>1.048260</td>\n",
       "      <td>0.885811</td>\n",
       "      <td>0.764113</td>\n",
       "      <td>1.021051</td>\n",
       "      <td>0.985920</td>\n",
       "      <td>I see what you saying I just read his pokersta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11944.11926</th>\n",
       "      <td>0.934407</td>\n",
       "      <td>0.973923</td>\n",
       "      <td>1.018610</td>\n",
       "      <td>1.163208</td>\n",
       "      <td>0.889388</td>\n",
       "      <td>1.110955</td>\n",
       "      <td>No more than two editors advocated deletion.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143902946.11991.11991</th>\n",
       "      <td>0.971398</td>\n",
       "      <td>0.712804</td>\n",
       "      <td>0.983160</td>\n",
       "      <td>0.916819</td>\n",
       "      <td>0.911771</td>\n",
       "      <td>0.839036</td>\n",
       "      <td>In the future please don't close Afds when you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143945536.12065.12065</th>\n",
       "      <td>1.044573</td>\n",
       "      <td>0.976042</td>\n",
       "      <td>0.979892</td>\n",
       "      <td>1.099157</td>\n",
       "      <td>0.934318</td>\n",
       "      <td>1.022813</td>\n",
       "      <td>That simply isn't true.  If you read the comme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144052463.12169.12169</th>\n",
       "      <td>0.924036</td>\n",
       "      <td>1.102745</td>\n",
       "      <td>0.929785</td>\n",
       "      <td>0.959193</td>\n",
       "      <td>0.996333</td>\n",
       "      <td>0.963547</td>\n",
       "      <td>Somehow, I suspect you may wish to participate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144065917.12226.12226</th>\n",
       "      <td>0.957274</td>\n",
       "      <td>0.687598</td>\n",
       "      <td>0.990034</td>\n",
       "      <td>0.996022</td>\n",
       "      <td>0.880861</td>\n",
       "      <td>0.844266</td>\n",
       "      <td>I assume your deliberate lying has a point, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127296808.516.516</th>\n",
       "      <td>1.121714</td>\n",
       "      <td>0.692300</td>\n",
       "      <td>1.117303</td>\n",
       "      <td>1.166274</td>\n",
       "      <td>0.929166</td>\n",
       "      <td>1.001746</td>\n",
       "      <td>== Could you stop reverting my corrections ==\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127296808.534.516</th>\n",
       "      <td>0.923464</td>\n",
       "      <td>0.784017</td>\n",
       "      <td>0.955954</td>\n",
       "      <td>0.741971</td>\n",
       "      <td>0.962447</td>\n",
       "      <td>0.760987</td>\n",
       "      <td>If you have problems with my edits to the 4WD ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       km_0_dist  km_1_dist  km_2_dist  km_3_dist  km_4_dist  \\\n",
       "146743638.12667.12652   0.988895   1.100313   0.925354   1.052824   0.998516   \n",
       "146842219.12874.12874   0.934950   0.959767   0.906565   0.963544   0.903838   \n",
       "146860774.13072.13072   0.825559   1.048260   0.885811   0.764113   1.021051   \n",
       "143890867.11944.11926   0.934407   0.973923   1.018610   1.163208   0.889388   \n",
       "143902946.11991.11991   0.971398   0.712804   0.983160   0.916819   0.911771   \n",
       "143945536.12065.12065   1.044573   0.976042   0.979892   1.099157   0.934318   \n",
       "144052463.12169.12169   0.924036   1.102745   0.929785   0.959193   0.996333   \n",
       "144065917.12226.12226   0.957274   0.687598   0.990034   0.996022   0.880861   \n",
       "127296808.516.516       1.121714   0.692300   1.117303   1.166274   0.929166   \n",
       "127296808.534.516       0.923464   0.784017   0.955954   0.741971   0.962447   \n",
       "\n",
       "                       km_5_dist  \\\n",
       "146743638.12667.12652   1.063603   \n",
       "146842219.12874.12874   0.931161   \n",
       "146860774.13072.13072   0.985920   \n",
       "143890867.11944.11926   1.110955   \n",
       "143902946.11991.11991   0.839036   \n",
       "143945536.12065.12065   1.022813   \n",
       "144052463.12169.12169   0.963547   \n",
       "144065917.12226.12226   0.844266   \n",
       "127296808.516.516       1.001746   \n",
       "127296808.534.516       0.760987   \n",
       "\n",
       "                                                                 content  \n",
       "146743638.12667.12652  I notice that earier that  moved wiki_link to ...  \n",
       "146842219.12874.12874  Chen was known in the poker world as \"William\"...  \n",
       "146860774.13072.13072  I see what you saying I just read his pokersta...  \n",
       "143890867.11944.11926  No more than two editors advocated deletion.  ...  \n",
       "143902946.11991.11991  In the future please don't close Afds when you...  \n",
       "143945536.12065.12065  That simply isn't true.  If you read the comme...  \n",
       "144052463.12169.12169  Somehow, I suspect you may wish to participate...  \n",
       "144065917.12226.12226  I assume your deliberate lying has a point, bu...  \n",
       "127296808.516.516        == Could you stop reverting my corrections ==\\n  \n",
       "127296808.534.516      If you have problems with my edits to the 4WD ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's take a look at what the output looks like\n",
    "prompt_types.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to do a little bit of cleaning up of the prompt types table. First off, we don't need the content column, as we are just interested in using the prompt type features themselves. Second, in the paper we assigned a max distance cutoff, such that distances were capped at 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_types = prompt_types.drop(columns=\"content\")\n",
    "prompt_types[prompt_types > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>km_0_dist</th>\n",
       "      <th>km_1_dist</th>\n",
       "      <th>km_2_dist</th>\n",
       "      <th>km_3_dist</th>\n",
       "      <th>km_4_dist</th>\n",
       "      <th>km_5_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146743638.12667.12652</th>\n",
       "      <td>0.988895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998516</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146842219.12874.12874</th>\n",
       "      <td>0.934950</td>\n",
       "      <td>0.959767</td>\n",
       "      <td>0.906565</td>\n",
       "      <td>0.963544</td>\n",
       "      <td>0.903838</td>\n",
       "      <td>0.931161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146860774.13072.13072</th>\n",
       "      <td>0.825559</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885811</td>\n",
       "      <td>0.764113</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.985920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11944.11926</th>\n",
       "      <td>0.934407</td>\n",
       "      <td>0.973923</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889388</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143902946.11991.11991</th>\n",
       "      <td>0.971398</td>\n",
       "      <td>0.712804</td>\n",
       "      <td>0.983160</td>\n",
       "      <td>0.916819</td>\n",
       "      <td>0.911771</td>\n",
       "      <td>0.839036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143945536.12065.12065</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976042</td>\n",
       "      <td>0.979892</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.934318</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144052463.12169.12169</th>\n",
       "      <td>0.924036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929785</td>\n",
       "      <td>0.959193</td>\n",
       "      <td>0.996333</td>\n",
       "      <td>0.963547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144065917.12226.12226</th>\n",
       "      <td>0.957274</td>\n",
       "      <td>0.687598</td>\n",
       "      <td>0.990034</td>\n",
       "      <td>0.996022</td>\n",
       "      <td>0.880861</td>\n",
       "      <td>0.844266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127296808.516.516</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.692300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929166</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127296808.534.516</th>\n",
       "      <td>0.923464</td>\n",
       "      <td>0.784017</td>\n",
       "      <td>0.955954</td>\n",
       "      <td>0.741971</td>\n",
       "      <td>0.962447</td>\n",
       "      <td>0.760987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       km_0_dist  km_1_dist  km_2_dist  km_3_dist  km_4_dist  \\\n",
       "146743638.12667.12652   0.988895   1.000000   0.925354   1.000000   0.998516   \n",
       "146842219.12874.12874   0.934950   0.959767   0.906565   0.963544   0.903838   \n",
       "146860774.13072.13072   0.825559   1.000000   0.885811   0.764113   1.000000   \n",
       "143890867.11944.11926   0.934407   0.973923   1.000000   1.000000   0.889388   \n",
       "143902946.11991.11991   0.971398   0.712804   0.983160   0.916819   0.911771   \n",
       "143945536.12065.12065   1.000000   0.976042   0.979892   1.000000   0.934318   \n",
       "144052463.12169.12169   0.924036   1.000000   0.929785   0.959193   0.996333   \n",
       "144065917.12226.12226   0.957274   0.687598   0.990034   0.996022   0.880861   \n",
       "127296808.516.516       1.000000   0.692300   1.000000   1.000000   0.929166   \n",
       "127296808.534.516       0.923464   0.784017   0.955954   0.741971   0.962447   \n",
       "\n",
       "                       km_5_dist  \n",
       "146743638.12667.12652   1.000000  \n",
       "146842219.12874.12874   0.931161  \n",
       "146860774.13072.13072   0.985920  \n",
       "143890867.11944.11926   1.000000  \n",
       "143902946.11991.11991   0.839036  \n",
       "143945536.12065.12065   1.000000  \n",
       "144052463.12169.12169   0.963547  \n",
       "144065917.12226.12226   0.844266  \n",
       "127296808.516.516       1.000000  \n",
       "127296808.534.516       0.760987  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_types.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Extract politeness strategies features\n",
    "\n",
    "Now we will extract the second type of pragmatic features described in the paper: politeness strategies. We can do this using convokit's PolitenessStrategies class. This class does not require any training, so we can just apply it directly to the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PolitenessStrategies(awry_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The politeness strategy features themselves can be accessed via the `feature_df` field of the PolitenessStrategies object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_politeness_==Hedges==</th>\n",
       "      <th>feature_politeness_==HASPOSITIVE==</th>\n",
       "      <th>feature_politeness_==Apologizing==</th>\n",
       "      <th>feature_politeness_==1st_person_pl.==</th>\n",
       "      <th>feature_politeness_==2nd_person==</th>\n",
       "      <th>feature_politeness_==Indirect_(btw)==</th>\n",
       "      <th>feature_politeness_==Indirect_(greeting)==</th>\n",
       "      <th>feature_politeness_==SUBJUNCTIVE==</th>\n",
       "      <th>feature_politeness_==HASHEDGE==</th>\n",
       "      <th>feature_politeness_==Please==</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_politeness_==2nd_person_start==</th>\n",
       "      <th>feature_politeness_==Gratitude==</th>\n",
       "      <th>feature_politeness_==Direct_start==</th>\n",
       "      <th>feature_politeness_==Direct_question==</th>\n",
       "      <th>feature_politeness_==1st_person==</th>\n",
       "      <th>feature_politeness_==HASNEGATIVE==</th>\n",
       "      <th>feature_politeness_==1st_person_start==</th>\n",
       "      <th>feature_politeness_==INDICATIVE==</th>\n",
       "      <th>feature_politeness_==Deference==</th>\n",
       "      <th>feature_politeness_==Factuality==</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146743638.12652.12652</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146743638.12667.12652</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146842219.12874.12874</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146860774.13072.13072</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11926.11926</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143890867.11944.11926</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143902946.11991.11991</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143945536.12065.12065</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144052463.12169.12169</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144065917.12226.12226</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature_politeness_==Hedges==  \\\n",
       "146743638.12652.12652                              0   \n",
       "146743638.12667.12652                              1   \n",
       "146842219.12874.12874                              1   \n",
       "146860774.13072.13072                              1   \n",
       "143890867.11926.11926                              0   \n",
       "143890867.11944.11926                              0   \n",
       "143902946.11991.11991                              0   \n",
       "143945536.12065.12065                              0   \n",
       "144052463.12169.12169                              1   \n",
       "144065917.12226.12226                              1   \n",
       "\n",
       "                       feature_politeness_==HASPOSITIVE==  \\\n",
       "146743638.12652.12652                                   0   \n",
       "146743638.12667.12652                                   1   \n",
       "146842219.12874.12874                                   1   \n",
       "146860774.13072.13072                                   1   \n",
       "143890867.11926.11926                                   0   \n",
       "143890867.11944.11926                                   1   \n",
       "143902946.11991.11991                                   1   \n",
       "143945536.12065.12065                                   1   \n",
       "144052463.12169.12169                                   0   \n",
       "144065917.12226.12226                                   0   \n",
       "\n",
       "                       feature_politeness_==Apologizing==  \\\n",
       "146743638.12652.12652                                   0   \n",
       "146743638.12667.12652                                   0   \n",
       "146842219.12874.12874                                   0   \n",
       "146860774.13072.13072                                   0   \n",
       "143890867.11926.11926                                   0   \n",
       "143890867.11944.11926                                   0   \n",
       "143902946.11991.11991                                   0   \n",
       "143945536.12065.12065                                   0   \n",
       "144052463.12169.12169                                   0   \n",
       "144065917.12226.12226                                   0   \n",
       "\n",
       "                       feature_politeness_==1st_person_pl.==  \\\n",
       "146743638.12652.12652                                      0   \n",
       "146743638.12667.12652                                      0   \n",
       "146842219.12874.12874                                      0   \n",
       "146860774.13072.13072                                      0   \n",
       "143890867.11926.11926                                      0   \n",
       "143890867.11944.11926                                      0   \n",
       "143902946.11991.11991                                      0   \n",
       "143945536.12065.12065                                      0   \n",
       "144052463.12169.12169                                      0   \n",
       "144065917.12226.12226                                      0   \n",
       "\n",
       "                       feature_politeness_==2nd_person==  \\\n",
       "146743638.12652.12652                                  0   \n",
       "146743638.12667.12652                                  1   \n",
       "146842219.12874.12874                                  0   \n",
       "146860774.13072.13072                                  1   \n",
       "143890867.11926.11926                                  0   \n",
       "143890867.11944.11926                                  0   \n",
       "143902946.11991.11991                                  1   \n",
       "143945536.12065.12065                                  1   \n",
       "144052463.12169.12169                                  1   \n",
       "144065917.12226.12226                                  1   \n",
       "\n",
       "                       feature_politeness_==Indirect_(btw)==  \\\n",
       "146743638.12652.12652                                      0   \n",
       "146743638.12667.12652                                      0   \n",
       "146842219.12874.12874                                      0   \n",
       "146860774.13072.13072                                      0   \n",
       "143890867.11926.11926                                      0   \n",
       "143890867.11944.11926                                      0   \n",
       "143902946.11991.11991                                      0   \n",
       "143945536.12065.12065                                      0   \n",
       "144052463.12169.12169                                      0   \n",
       "144065917.12226.12226                                      0   \n",
       "\n",
       "                       feature_politeness_==Indirect_(greeting)==  \\\n",
       "146743638.12652.12652                                           0   \n",
       "146743638.12667.12652                                           0   \n",
       "146842219.12874.12874                                           0   \n",
       "146860774.13072.13072                                           0   \n",
       "143890867.11926.11926                                           0   \n",
       "143890867.11944.11926                                           0   \n",
       "143902946.11991.11991                                           0   \n",
       "143945536.12065.12065                                           0   \n",
       "144052463.12169.12169                                           0   \n",
       "144065917.12226.12226                                           0   \n",
       "\n",
       "                       feature_politeness_==SUBJUNCTIVE==  \\\n",
       "146743638.12652.12652                                   0   \n",
       "146743638.12667.12652                                   0   \n",
       "146842219.12874.12874                                   0   \n",
       "146860774.13072.13072                                   0   \n",
       "143890867.11926.11926                                   0   \n",
       "143890867.11944.11926                                   0   \n",
       "143902946.11991.11991                                   0   \n",
       "143945536.12065.12065                                   0   \n",
       "144052463.12169.12169                                   0   \n",
       "144065917.12226.12226                                   0   \n",
       "\n",
       "                       feature_politeness_==HASHEDGE==  \\\n",
       "146743638.12652.12652                                0   \n",
       "146743638.12667.12652                                1   \n",
       "146842219.12874.12874                                1   \n",
       "146860774.13072.13072                                1   \n",
       "143890867.11926.11926                                0   \n",
       "143890867.11944.11926                                1   \n",
       "143902946.11991.11991                                0   \n",
       "143945536.12065.12065                                0   \n",
       "144052463.12169.12169                                1   \n",
       "144065917.12226.12226                                1   \n",
       "\n",
       "                       feature_politeness_==Please==  \\\n",
       "146743638.12652.12652                              0   \n",
       "146743638.12667.12652                              0   \n",
       "146842219.12874.12874                              0   \n",
       "146860774.13072.13072                              0   \n",
       "143890867.11926.11926                              0   \n",
       "143890867.11944.11926                              0   \n",
       "143902946.11991.11991                              1   \n",
       "143945536.12065.12065                              0   \n",
       "144052463.12169.12169                              0   \n",
       "144065917.12226.12226                              0   \n",
       "\n",
       "                                     ...                  \\\n",
       "146743638.12652.12652                ...                   \n",
       "146743638.12667.12652                ...                   \n",
       "146842219.12874.12874                ...                   \n",
       "146860774.13072.13072                ...                   \n",
       "143890867.11926.11926                ...                   \n",
       "143890867.11944.11926                ...                   \n",
       "143902946.11991.11991                ...                   \n",
       "143945536.12065.12065                ...                   \n",
       "144052463.12169.12169                ...                   \n",
       "144065917.12226.12226                ...                   \n",
       "\n",
       "                       feature_politeness_==2nd_person_start==  \\\n",
       "146743638.12652.12652                                        0   \n",
       "146743638.12667.12652                                        0   \n",
       "146842219.12874.12874                                        0   \n",
       "146860774.13072.13072                                        0   \n",
       "143890867.11926.11926                                        0   \n",
       "143890867.11944.11926                                        0   \n",
       "143902946.11991.11991                                        0   \n",
       "143945536.12065.12065                                        0   \n",
       "144052463.12169.12169                                        0   \n",
       "144065917.12226.12226                                        0   \n",
       "\n",
       "                       feature_politeness_==Gratitude==  \\\n",
       "146743638.12652.12652                                 0   \n",
       "146743638.12667.12652                                 0   \n",
       "146842219.12874.12874                                 0   \n",
       "146860774.13072.13072                                 1   \n",
       "143890867.11926.11926                                 0   \n",
       "143890867.11944.11926                                 0   \n",
       "143902946.11991.11991                                 0   \n",
       "143945536.12065.12065                                 0   \n",
       "144052463.12169.12169                                 0   \n",
       "144065917.12226.12226                                 0   \n",
       "\n",
       "                       feature_politeness_==Direct_start==  \\\n",
       "146743638.12652.12652                                    0   \n",
       "146743638.12667.12652                                    0   \n",
       "146842219.12874.12874                                    0   \n",
       "146860774.13072.13072                                    1   \n",
       "143890867.11926.11926                                    0   \n",
       "143890867.11944.11926                                    0   \n",
       "143902946.11991.11991                                    0   \n",
       "143945536.12065.12065                                    0   \n",
       "144052463.12169.12169                                    0   \n",
       "144065917.12226.12226                                    0   \n",
       "\n",
       "                       feature_politeness_==Direct_question==  \\\n",
       "146743638.12652.12652                                       0   \n",
       "146743638.12667.12652                                       1   \n",
       "146842219.12874.12874                                       0   \n",
       "146860774.13072.13072                                       0   \n",
       "143890867.11926.11926                                       0   \n",
       "143890867.11944.11926                                       0   \n",
       "143902946.11991.11991                                       0   \n",
       "143945536.12065.12065                                       0   \n",
       "144052463.12169.12169                                       0   \n",
       "144065917.12226.12226                                       0   \n",
       "\n",
       "                       feature_politeness_==1st_person==  \\\n",
       "146743638.12652.12652                                  0   \n",
       "146743638.12667.12652                                  1   \n",
       "146842219.12874.12874                                  1   \n",
       "146860774.13072.13072                                  1   \n",
       "143890867.11926.11926                                  0   \n",
       "143890867.11944.11926                                  0   \n",
       "143902946.11991.11991                                  0   \n",
       "143945536.12065.12065                                  0   \n",
       "144052463.12169.12169                                  1   \n",
       "144065917.12226.12226                                  0   \n",
       "\n",
       "                       feature_politeness_==HASNEGATIVE==  \\\n",
       "146743638.12652.12652                                   0   \n",
       "146743638.12667.12652                                   1   \n",
       "146842219.12874.12874                                   0   \n",
       "146860774.13072.13072                                   1   \n",
       "143890867.11926.11926                                   0   \n",
       "143890867.11944.11926                                   0   \n",
       "143902946.11991.11991                                   1   \n",
       "143945536.12065.12065                                   1   \n",
       "144052463.12169.12169                                   1   \n",
       "144065917.12226.12226                                   1   \n",
       "\n",
       "                       feature_politeness_==1st_person_start==  \\\n",
       "146743638.12652.12652                                        0   \n",
       "146743638.12667.12652                                        1   \n",
       "146842219.12874.12874                                        1   \n",
       "146860774.13072.13072                                        1   \n",
       "143890867.11926.11926                                        0   \n",
       "143890867.11944.11926                                        0   \n",
       "143902946.11991.11991                                        0   \n",
       "143945536.12065.12065                                        0   \n",
       "144052463.12169.12169                                        0   \n",
       "144065917.12226.12226                                        1   \n",
       "\n",
       "                       feature_politeness_==INDICATIVE==  \\\n",
       "146743638.12652.12652                                  0   \n",
       "146743638.12667.12652                                  0   \n",
       "146842219.12874.12874                                  0   \n",
       "146860774.13072.13072                                  0   \n",
       "143890867.11926.11926                                  0   \n",
       "143890867.11944.11926                                  0   \n",
       "143902946.11991.11991                                  0   \n",
       "143945536.12065.12065                                  0   \n",
       "144052463.12169.12169                                  0   \n",
       "144065917.12226.12226                                  0   \n",
       "\n",
       "                       feature_politeness_==Deference==  \\\n",
       "146743638.12652.12652                                 0   \n",
       "146743638.12667.12652                                 0   \n",
       "146842219.12874.12874                                 0   \n",
       "146860774.13072.13072                                 0   \n",
       "143890867.11926.11926                                 0   \n",
       "143890867.11944.11926                                 0   \n",
       "143902946.11991.11991                                 0   \n",
       "143945536.12065.12065                                 0   \n",
       "144052463.12169.12169                                 0   \n",
       "144065917.12226.12226                                 0   \n",
       "\n",
       "                       feature_politeness_==Factuality==  \n",
       "146743638.12652.12652                                  0  \n",
       "146743638.12667.12652                                  0  \n",
       "146842219.12874.12874                                  0  \n",
       "146860774.13072.13072                                  0  \n",
       "143890867.11926.11926                                  0  \n",
       "143890867.11944.11926                                  0  \n",
       "143902946.11991.11991                                  0  \n",
       "143945536.12065.12065                                  1  \n",
       "144052463.12169.12169                                  0  \n",
       "144065917.12226.12226                                  0  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politeness_strategies = ps.feature_df\n",
    "politeness_strategies.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create pair data\n",
    "\n",
    "The prediction task defined in the paper is a paired task. The corpus downloaded from convokit already includes metadata about how conversations were paired for the paper, so we don't need to do any of the hard work here. Instead, we'll format the pair information into a table for use in prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we need to directly map comment IDs to their conversations. We'll build a DataFrame to do this\n",
    "comment_ids = []\n",
    "convo_ids = []\n",
    "timestamps = []\n",
    "page_ids = []\n",
    "for comment_id in awry_corpus.utterances:\n",
    "    comment = awry_corpus.utterances[comment_id]\n",
    "    # section headers are included in the dataset for completeness, but for prediction we need to ignore\n",
    "    # them as they are not utterances\n",
    "    if not comment.other[\"is_section_header\"]:\n",
    "        comment_ids.append(comment_id)\n",
    "        convo_ids.append(comment.root)\n",
    "        timestamps.append(comment.timestamp)\n",
    "        page_ids.append(comment.other[\"awry_info\"][\"page_id\"])\n",
    "comment_df = pd.DataFrame({\"conversation_id\": convo_ids, \"timestamp\": timestamps, \"page_id\": page_ids}, index=comment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll do our construction using awry conversation ID's as the reference key\n",
    "awry_convo_ids = set()\n",
    "# these dicts will then all be keyed by awry ID\n",
    "good_convo_map = {}\n",
    "page_id_map = {}\n",
    "for comment in awry_corpus.utterances.values():\n",
    "    if comment.other[\"awry_info\"][\"conversation_has_personal_attack\"] and comment.root not in awry_convo_ids:\n",
    "        awry_convo_ids.add(comment.root)\n",
    "        good_convo_map[comment.root] = comment.other[\"awry_info\"][\"pair_id\"]\n",
    "        page_id_map[comment.root] = comment.other[\"awry_info\"][\"page_id\"]\n",
    "awry_convo_ids = list(awry_convo_ids)\n",
    "pairs_df = pd.DataFrame({\"bad_conversation_id\": awry_convo_ids,\n",
    "                         \"conversation_id\": [good_convo_map[cid] for cid in awry_convo_ids],\n",
    "                         \"page_id\": [page_id_map[cid] for cid in awry_convo_ids]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, we will augment the pairs dataframe with the IDs of the first and second comment for both\n",
    "# the bad and good conversation. This will come in handy for constructing the feature matrix.\n",
    "first_ids = []\n",
    "second_ids = []\n",
    "first_ids_bad = []\n",
    "second_ids_bad = []\n",
    "for row in pairs_df.itertuples():\n",
    "    # \"first two\" is defined in terms of time of posting\n",
    "    comments_sorted = comment_df[comment_df.conversation_id==row.conversation_id].sort_values(by=\"timestamp\")\n",
    "    first_ids.append(comments_sorted.iloc[0].name)\n",
    "    second_ids.append(comments_sorted.iloc[1].name)\n",
    "    comments_sorted_bad = comment_df[comment_df.conversation_id==row.bad_conversation_id].sort_values(by=\"timestamp\")\n",
    "    first_ids_bad.append(comments_sorted_bad.iloc[0].name)\n",
    "    second_ids_bad.append(comments_sorted_bad.iloc[1].name)\n",
    "pairs_df = pairs_df.assign(first_id=first_ids, second_id=second_ids, \n",
    "                           bad_first_id=first_ids_bad, bad_second_id=second_ids_bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Construct feature matrix\n",
    "\n",
    "Now that we have the pair data, we can construct a table of pragmatic features for each pair, to use in prediction. This table will consist of the prompt types and politeness strategies for the first and second comment of each conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_for_convo(convo_id, first_comment_id, second_comment_id):\n",
    "\n",
    "    # get prompt type features\n",
    "    try:\n",
    "        first_prompts = prompt_types.loc[first_comment_id]\n",
    "    except:\n",
    "        first_prompts = pd.Series(data=np.ones(len(prompt_types.columns)), index=prompt_types.columns)\n",
    "    try:\n",
    "        second_prompts = prompt_types.loc[second_comment_id].rename({c: c + \"_second\" for c in prompt_types.columns})\n",
    "    except:\n",
    "        second_prompts = pd.Series(data=np.ones(len(prompt_types.columns)), index=[c + \"_second\" for c in prompt_types.columns])\n",
    "    prompts = first_prompts.append(second_prompts)\n",
    "    # get politeness strategies features\n",
    "    first_politeness = politeness_strategies.loc[first_comment_id]\n",
    "    second_politeness = politeness_strategies.loc[second_comment_id].rename({c: c + \"_second\" for c in politeness_strategies.columns})\n",
    "    politeness = first_politeness.append(second_politeness)\n",
    "    return politeness.append(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_ids = np.concatenate((pairs_df.conversation_id.values, pairs_df.bad_conversation_id.values))\n",
    "feats = [features_for_convo(row.conversation_id, row.first_id, row.second_id) for row in pairs_df.itertuples()] + \\\n",
    "        [features_for_convo(row.bad_conversation_id, row.bad_first_id, row.bad_second_id) for row in pairs_df.itertuples()]\n",
    "feature_table = pd.DataFrame(data=np.vstack([f.values for f in feats]), columns=feats[0].index, index=convo_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the paper, we dropped the sentiment lexicon based features (HASPOSITIVE and HASNEGATIVE), opting\n",
    "# to instead use them as a baseline. We do this here as well to be consistent with the paper.\n",
    "feature_table = feature_table.drop(columns=[\"feature_politeness_==HASPOSITIVE==\",\n",
    "                                            \"feature_politeness_==HASNEGATIVE==\",\n",
    "                                            \"feature_politeness_==HASPOSITIVE==_second\",\n",
    "                                            \"feature_politeness_==HASNEGATIVE==_second\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_politeness_==Hedges==</th>\n",
       "      <th>feature_politeness_==Apologizing==</th>\n",
       "      <th>feature_politeness_==1st_person_pl.==</th>\n",
       "      <th>feature_politeness_==2nd_person==</th>\n",
       "      <th>feature_politeness_==Indirect_(btw)==</th>\n",
       "      <th>feature_politeness_==Indirect_(greeting)==</th>\n",
       "      <th>feature_politeness_==SUBJUNCTIVE==</th>\n",
       "      <th>feature_politeness_==HASHEDGE==</th>\n",
       "      <th>feature_politeness_==Please==</th>\n",
       "      <th>feature_politeness_==Please_start==</th>\n",
       "      <th>...</th>\n",
       "      <th>km_2_dist</th>\n",
       "      <th>km_3_dist</th>\n",
       "      <th>km_4_dist</th>\n",
       "      <th>km_5_dist</th>\n",
       "      <th>km_0_dist_second</th>\n",
       "      <th>km_1_dist_second</th>\n",
       "      <th>km_2_dist_second</th>\n",
       "      <th>km_3_dist_second</th>\n",
       "      <th>km_4_dist_second</th>\n",
       "      <th>km_5_dist_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>339153648.13082.13082</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836569</td>\n",
       "      <td>0.799070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983598</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.822115</td>\n",
       "      <td>0.973038</td>\n",
       "      <td>0.997192</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273320587.1690.1690</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830685</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884913</td>\n",
       "      <td>0.804456</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295446996.20932.20932</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931499</td>\n",
       "      <td>0.770019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.897080</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975853</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114831022.4571.4571</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809935</td>\n",
       "      <td>0.830955</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.844493</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889421</td>\n",
       "      <td>0.816545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46490327.5727.5727</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950241</td>\n",
       "      <td>0.722807</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902583</td>\n",
       "      <td>0.883167</td>\n",
       "      <td>0.950272</td>\n",
       "      <td>0.931917</td>\n",
       "      <td>0.923855</td>\n",
       "      <td>0.910283</td>\n",
       "      <td>0.849097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature_politeness_==Hedges==  \\\n",
       "339153648.13082.13082                            1.0   \n",
       "273320587.1690.1690                              0.0   \n",
       "295446996.20932.20932                            0.0   \n",
       "114831022.4571.4571                              1.0   \n",
       "46490327.5727.5727                               0.0   \n",
       "\n",
       "                       feature_politeness_==Apologizing==  \\\n",
       "339153648.13082.13082                                 0.0   \n",
       "273320587.1690.1690                                   0.0   \n",
       "295446996.20932.20932                                 0.0   \n",
       "114831022.4571.4571                                   0.0   \n",
       "46490327.5727.5727                                    0.0   \n",
       "\n",
       "                       feature_politeness_==1st_person_pl.==  \\\n",
       "339153648.13082.13082                                    0.0   \n",
       "273320587.1690.1690                                      0.0   \n",
       "295446996.20932.20932                                    0.0   \n",
       "114831022.4571.4571                                      1.0   \n",
       "46490327.5727.5727                                       0.0   \n",
       "\n",
       "                       feature_politeness_==2nd_person==  \\\n",
       "339153648.13082.13082                                1.0   \n",
       "273320587.1690.1690                                  1.0   \n",
       "295446996.20932.20932                                1.0   \n",
       "114831022.4571.4571                                  1.0   \n",
       "46490327.5727.5727                                   1.0   \n",
       "\n",
       "                       feature_politeness_==Indirect_(btw)==  \\\n",
       "339153648.13082.13082                                    0.0   \n",
       "273320587.1690.1690                                      0.0   \n",
       "295446996.20932.20932                                    0.0   \n",
       "114831022.4571.4571                                      0.0   \n",
       "46490327.5727.5727                                       0.0   \n",
       "\n",
       "                       feature_politeness_==Indirect_(greeting)==  \\\n",
       "339153648.13082.13082                                         0.0   \n",
       "273320587.1690.1690                                           0.0   \n",
       "295446996.20932.20932                                         0.0   \n",
       "114831022.4571.4571                                           0.0   \n",
       "46490327.5727.5727                                            1.0   \n",
       "\n",
       "                       feature_politeness_==SUBJUNCTIVE==  \\\n",
       "339153648.13082.13082                                 1.0   \n",
       "273320587.1690.1690                                   0.0   \n",
       "295446996.20932.20932                                 0.0   \n",
       "114831022.4571.4571                                   0.0   \n",
       "46490327.5727.5727                                    0.0   \n",
       "\n",
       "                       feature_politeness_==HASHEDGE==  \\\n",
       "339153648.13082.13082                              1.0   \n",
       "273320587.1690.1690                                0.0   \n",
       "295446996.20932.20932                              0.0   \n",
       "114831022.4571.4571                                1.0   \n",
       "46490327.5727.5727                                 0.0   \n",
       "\n",
       "                       feature_politeness_==Please==  \\\n",
       "339153648.13082.13082                            0.0   \n",
       "273320587.1690.1690                              0.0   \n",
       "295446996.20932.20932                            0.0   \n",
       "114831022.4571.4571                              0.0   \n",
       "46490327.5727.5727                               0.0   \n",
       "\n",
       "                       feature_politeness_==Please_start==        ...         \\\n",
       "339153648.13082.13082                                  0.0        ...          \n",
       "273320587.1690.1690                                    0.0        ...          \n",
       "295446996.20932.20932                                  0.0        ...          \n",
       "114831022.4571.4571                                    0.0        ...          \n",
       "46490327.5727.5727                                     0.0        ...          \n",
       "\n",
       "                       km_2_dist  km_3_dist  km_4_dist  km_5_dist  \\\n",
       "339153648.13082.13082   0.836569   0.799070        1.0   1.000000   \n",
       "273320587.1690.1690     1.000000   1.000000        1.0   1.000000   \n",
       "295446996.20932.20932   0.931499   0.770019        1.0   0.897080   \n",
       "114831022.4571.4571     0.809935   0.830955        1.0   1.000000   \n",
       "46490327.5727.5727      0.950241   0.722807        1.0   0.902583   \n",
       "\n",
       "                       km_0_dist_second  km_1_dist_second  km_2_dist_second  \\\n",
       "339153648.13082.13082          0.983598          1.000000          0.822115   \n",
       "273320587.1690.1690            0.830685          1.000000          0.884913   \n",
       "295446996.20932.20932          1.000000          1.000000          1.000000   \n",
       "114831022.4571.4571            0.844493          1.000000          0.889421   \n",
       "46490327.5727.5727             0.883167          0.950272          0.931917   \n",
       "\n",
       "                       km_3_dist_second  km_4_dist_second  km_5_dist_second  \n",
       "339153648.13082.13082          0.973038          0.997192          1.000000  \n",
       "273320587.1690.1690            0.804456          1.000000          1.000000  \n",
       "295446996.20932.20932          1.000000          0.975853          1.000000  \n",
       "114831022.4571.4571            0.816545          1.000000          0.989362  \n",
       "46490327.5727.5727             0.923855          0.910283          0.849097  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how it looks\n",
    "feature_table.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Prediction Utils\n",
    "\n",
    "We're almost ready to do the prediction! First we need to define a few helper functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(seq):\n",
    "    vals, counts = np.unique(seq, return_counts=True)\n",
    "    return vals[np.argmax(counts)]\n",
    "\n",
    "def run_pred_single(inputs, X, y):\n",
    "    f_idx, (train_idx, test_idx) = inputs\n",
    "    \n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    base_clf = Pipeline([(\"scaler\", StandardScaler()), (\"featselect\", SelectPercentile(f_classif, 10)), (\"logreg\", LogisticRegression())])\n",
    "    clf = GridSearchCV(base_clf, {\"logreg__C\": [10**i for i in range(-4,4)], \"featselect__percentile\": list(range(10, 110, 10))})\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_scores = clf.predict_proba(X_test)[:,1]\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    feature_weights = clf.best_estimator_.named_steps[\"logreg\"].coef_.flatten()\n",
    "    feature_mask = clf.best_estimator_.named_steps[\"featselect\"].get_support()\n",
    "    \n",
    "    hyperparams = clf.best_params_\n",
    "    \n",
    "    return (y_pred, y_scores, feature_weights, hyperparams, feature_mask)\n",
    "\n",
    "def run_pred(X, y, fnames, groups):\n",
    "    feature_weights = {}\n",
    "    scores = np.asarray([np.nan for i in range(len(y))])\n",
    "    y_pred = np.zeros(len(y))\n",
    "    hyperparameters = defaultdict(list)\n",
    "    splits = list(enumerate(LeaveOneGroupOut().split(X, y, groups)))\n",
    "    accs = []\n",
    "        \n",
    "    with Pool(os.cpu_count()) as p:\n",
    "        prediction_results = p.map(partial(run_pred_single, X=X, y=y), splits)\n",
    "        \n",
    "    fselect_pvals_all = []\n",
    "    for i in range(len(splits)):\n",
    "        f_idx, (train_idx, test_idx) = splits[i]\n",
    "        y_pred_i, y_scores_i, weights_i, hyperparams_i, mask_i = prediction_results[i]\n",
    "        y_pred[test_idx] = y_pred_i\n",
    "        scores[test_idx] = y_scores_i\n",
    "        feature_weights[f_idx] = np.asarray([np.nan for _ in range(len(fnames))])\n",
    "        feature_weights[f_idx][mask_i] = weights_i\n",
    "        for param in hyperparams_i:\n",
    "            hyperparameters[param].append(hyperparams_i[param])   \n",
    "    \n",
    "    acc = np.mean(y_pred == y)\n",
    "    pvalue = stats.binom_test(sum(y_pred == y), n=len(y), alternative=\"greater\")\n",
    "                \n",
    "    coef_df = pd.DataFrame(feature_weights, index=fnames)\n",
    "    coef_df['mean_coef'] = coef_df.apply(np.nanmean, axis=1)\n",
    "    coef_df['std_coef'] = coef_df.apply(np.nanstd, axis=1)\n",
    "    return acc, coef_df[['mean_coef', 'std_coef']], scores, pd.DataFrame(hyperparameters), pvalue\n",
    "\n",
    "def get_labeled_pairs(pairs_df):\n",
    "    paired_labels = []\n",
    "    c0s = []\n",
    "    c1s = []\n",
    "    page_ids = []\n",
    "    for i, row in enumerate(pairs_df.itertuples()):\n",
    "        if i % 2 == 0:\n",
    "            c0s.append(row.conversation_id)\n",
    "            c1s.append(row.bad_conversation_id)\n",
    "        else:\n",
    "            c0s.append(row.bad_conversation_id)\n",
    "            c1s.append(row.conversation_id)\n",
    "        paired_labels.append(i%2)\n",
    "        page_ids.append(row.page_id)\n",
    "    return pd.DataFrame({\"c0\": c0s, \"c1\": c1s,\"first_convo_toxic\": paired_labels, \"page_id\": page_ids})\n",
    "\n",
    "def get_feature_subset(labeled_pairs_df, feature_list):\n",
    "    prompt_type_names = [\"km_%d_dist\" % i for i in range(6)] + [\"km_%d_dist_second\" % i for i in range(6)]\n",
    "    politeness_names = [f for f in feature_table.columns if f not in prompt_type_names]\n",
    "    \n",
    "    features_to_use = []\n",
    "    if \"prompt_types\" in feature_list:\n",
    "        features_to_use += prompt_type_names\n",
    "    if \"politeness_strategies\" in feature_list:\n",
    "        features_to_use += politeness_names\n",
    "        \n",
    "    feature_subset = feature_table[features_to_use]\n",
    "    \n",
    "    c0_feats = feature_subset.loc[labeled_pairs_df.c0].values\n",
    "    c1_feats = feature_subset.loc[labeled_pairs_df.c1].values\n",
    "    \n",
    "    return c0_feats, c1_feats, features_to_use\n",
    "\n",
    "def run_pipeline(feature_set):\n",
    "    print(\"Running prediction task for feature set\", \"+\".join(feature_set))\n",
    "    print(\"Generating labels...\")\n",
    "    labeled_pairs_df = get_labeled_pairs(pairs_df)\n",
    "    print(\"Computing paired features...\")\n",
    "    X_c0, X_c1, feature_names = get_feature_subset(labeled_pairs_df, feature_set)\n",
    "    X = X_c1 - X_c0\n",
    "    print(\"Using\", X.shape[1], \"features\")\n",
    "    y = labeled_pairs_df.first_convo_toxic.values\n",
    "    print(\"Running leave-one-page-out prediction...\")\n",
    "    accuracy, coefs, scores, hyperparams, pvalue = run_pred(X, y, feature_names, labeled_pairs_df.page_id)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"p-value: %.4e\" % pvalue)\n",
    "    print(\"C (mode):\", mode(hyperparams.logreg__C))\n",
    "    print(\"Percent of features (mode):\", mode(hyperparams.featselect__percentile))\n",
    "    print(\"Coefficents:\")\n",
    "    print(coefs.sort_values(by=\"mean_coef\"))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Prediction\n",
    "\n",
    "Finally, we run the prediction task on each possible combination of pragmatic features: prompt types, politeness strategies, and both combined. We generate a table like Table 3 from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running prediction task for feature set politeness_strategies\n",
      "Generating labels...\n",
      "Computing paired features...\n",
      "Using 38 features\n",
      "Running leave-one-page-out prediction...\n",
      "Accuracy: 0.6078740157480315\n",
      "p-value: 3.0260e-08\n",
      "C (mode): 0.01\n",
      "Percent of features (mode): 50\n",
      "Coefficents:\n",
      "                                                   mean_coef  std_coef\n",
      "feature_politeness_==2nd_person==_second           -0.176311  0.043429\n",
      "feature_politeness_==2nd_person_start==_second     -0.134761  0.031002\n",
      "feature_politeness_==2nd_person_start==            -0.119161  0.029131\n",
      "feature_politeness_==Direct_question==_second      -0.117183  0.028071\n",
      "feature_politeness_==Direct_question==             -0.097743  0.020645\n",
      "feature_politeness_==Please_start==_second         -0.090237  0.021035\n",
      "feature_politeness_==Indirect_(btw)==              -0.086099  0.029164\n",
      "feature_politeness_==Indirect_(btw)==_second       -0.040407  0.004392\n",
      "feature_politeness_==Factuality==                  -0.036247  0.003115\n",
      "feature_politeness_==Direct_start==                -0.033004  0.000000\n",
      "feature_politeness_==Please==                      -0.026897  0.004232\n",
      "feature_politeness_==Please_start==                -0.022178  0.001864\n",
      "feature_politeness_==Direct_start==_second         -0.018846  0.000362\n",
      "feature_politeness_==1st_person_pl.==              -0.012946  0.000278\n",
      "feature_politeness_==2nd_person==                  -0.011392  0.000000\n",
      "feature_politeness_==INDICATIVE==                  -0.005650  0.000069\n",
      "feature_politeness_==Factuality==_second           -0.003694  0.000000\n",
      "feature_politeness_==1st_person_start==             0.002380  0.004847\n",
      "feature_politeness_==SUBJUNCTIVE==                  0.006146  0.002280\n",
      "feature_politeness_==Please==_second                0.006509  0.000000\n",
      "feature_politeness_==1st_person==                   0.011009  0.002394\n",
      "feature_politeness_==Apologizing==                  0.014362  0.000650\n",
      "feature_politeness_==Deference==_second             0.014785  0.004309\n",
      "feature_politeness_==1st_person_pl.==_second        0.024359  0.006064\n",
      "feature_politeness_==Hedges==_second                0.028173  0.005424\n",
      "feature_politeness_==Deference==                    0.032393  0.006930\n",
      "feature_politeness_==Indirect_(greeting)==_second   0.046286  0.008821\n",
      "feature_politeness_==INDICATIVE==_second            0.053820  0.007692\n",
      "feature_politeness_==Hedges==                       0.061655  0.013062\n",
      "feature_politeness_==Apologizing==_second           0.069494  0.012669\n",
      "feature_politeness_==1st_person==_second            0.069518  0.017262\n",
      "feature_politeness_==HASHEDGE==                     0.072754  0.015911\n",
      "feature_politeness_==Gratitude==                    0.076284  0.016501\n",
      "feature_politeness_==Gratitude==_second             0.088343  0.018614\n",
      "feature_politeness_==1st_person_start==_second      0.090341  0.018230\n",
      "feature_politeness_==HASHEDGE==_second              0.107210  0.026516\n",
      "feature_politeness_==Indirect_(greeting)==          0.145036  0.037300\n",
      "feature_politeness_==SUBJUNCTIVE==_second           0.148842  0.050134\n",
      "Running prediction task for feature set prompt_types\n",
      "Generating labels...\n",
      "Computing paired features...\n",
      "Using 12 features\n",
      "Running leave-one-page-out prediction...\n",
      "Accuracy: 0.5952755905511811\n",
      "p-value: 8.9506e-07\n",
      "C (mode): 0.0001\n",
      "Percent of features (mode): 80\n",
      "Coefficents:\n",
      "                  mean_coef  std_coef\n",
      "km_2_dist         -0.006889  0.008314\n",
      "km_2_dist_second  -0.005878  0.006968\n",
      "km_3_dist         -0.005519  0.006392\n",
      "km_0_dist         -0.005281  0.003681\n",
      "km_3_dist_second  -0.004781  0.005495\n",
      "km_0_dist_second  -0.003485  0.003586\n",
      "km_5_dist_second   0.005230  0.005196\n",
      "km_4_dist_second   0.005339  0.006279\n",
      "km_1_dist          0.005529  0.006507\n",
      "km_1_dist_second   0.006866  0.008387\n",
      "km_4_dist          0.007303  0.008962\n",
      "km_5_dist               NaN       NaN\n",
      "Running prediction task for feature set politeness_strategies+prompt_types\n",
      "Generating labels...\n",
      "Computing paired features...\n",
      "Using 50 features\n",
      "Running leave-one-page-out prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/miniconda3/envs/convokit/lib/python3.6/site-packages/pandas/core/apply.py:242: RuntimeWarning: Mean of empty slice\n",
      "  labels=labels)\n",
      "/home/jonathan/miniconda3/envs/convokit/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1434: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6251968503937008\n",
      "p-value: 1.4664e-10\n",
      "C (mode): 0.0001\n",
      "Percent of features (mode): 50\n",
      "Coefficents:\n",
      "                                                   mean_coef      std_coef\n",
      "feature_politeness_==2nd_person==_second           -0.021106  2.081326e-02\n",
      "feature_politeness_==2nd_person_start==_second     -0.017606  1.707194e-02\n",
      "feature_politeness_==Direct_question==_second      -0.015014  1.436886e-02\n",
      "feature_politeness_==2nd_person_start==            -0.014947  1.401025e-02\n",
      "km_2_dist                                          -0.014106  1.256456e-02\n",
      "feature_politeness_==Direct_question==             -0.012878  1.135110e-02\n",
      "feature_politeness_==Please_start==_second         -0.011870  1.067424e-02\n",
      "km_2_dist_second                                   -0.011268  8.737590e-03\n",
      "km_3_dist                                          -0.010420  8.864930e-03\n",
      "km_3_dist_second                                   -0.009586  7.886899e-03\n",
      "feature_politeness_==Indirect_(btw)==              -0.008070  1.027129e-02\n",
      "km_0_dist_second                                   -0.005979  4.609524e-03\n",
      "km_0_dist                                          -0.003459  4.293276e-03\n",
      "feature_politeness_==Indirect_(btw)==_second       -0.002580  3.096132e-03\n",
      "feature_politeness_==Factuality==                  -0.001805  2.383631e-03\n",
      "feature_politeness_==Please_start==                -0.001643  1.568465e-03\n",
      "feature_politeness_==Please==                      -0.000712  1.296706e-06\n",
      "feature_politeness_==SUBJUNCTIVE==                  0.000694  4.356248e-05\n",
      "feature_politeness_==Deference==                    0.000704  1.597452e-07\n",
      "feature_politeness_==Deference==_second             0.000708  3.892187e-07\n",
      "feature_politeness_==INDICATIVE==_second            0.000756  9.545805e-05\n",
      "feature_politeness_==1st_person==                   0.001315  9.094438e-04\n",
      "feature_politeness_==1st_person_start==             0.001656  1.394961e-03\n",
      "feature_politeness_==1st_person_pl.==_second        0.001796  2.042767e-03\n",
      "feature_politeness_==Indirect_(greeting)==_second   0.005497  5.621171e-03\n",
      "km_5_dist_second                                    0.006191  5.865100e-03\n",
      "feature_politeness_==Hedges==_second                0.007860  6.209167e-03\n",
      "feature_politeness_==Hedges==                       0.008340  6.783785e-03\n",
      "feature_politeness_==Apologizing==_second           0.008500  9.262617e-03\n",
      "feature_politeness_==1st_person==_second            0.009297  8.935267e-03\n",
      "feature_politeness_==Gratitude==                    0.009752  8.997903e-03\n",
      "km_4_dist_second                                    0.010902  8.651502e-03\n",
      "feature_politeness_==HASHEDGE==                     0.011132  1.008679e-02\n",
      "km_1_dist                                           0.011680  9.360779e-03\n",
      "feature_politeness_==Gratitude==_second             0.012348  1.111283e-02\n",
      "feature_politeness_==1st_person_start==_second      0.013073  1.129528e-02\n",
      "km_1_dist_second                                    0.013996  1.122803e-02\n",
      "feature_politeness_==HASHEDGE==_second              0.014876  1.363237e-02\n",
      "km_4_dist                                           0.016116  1.531903e-02\n",
      "feature_politeness_==SUBJUNCTIVE==_second           0.016170  1.797228e-02\n",
      "feature_politeness_==Indirect_(greeting)==          0.016544  1.572078e-02\n",
      "km_5_dist                                                NaN           NaN\n",
      "feature_politeness_==Apologizing==                       NaN           NaN\n",
      "feature_politeness_==1st_person_pl.==                    NaN           NaN\n",
      "feature_politeness_==2nd_person==                        NaN           NaN\n",
      "feature_politeness_==Direct_start==                      NaN           NaN\n",
      "feature_politeness_==INDICATIVE==                        NaN           NaN\n",
      "feature_politeness_==Please==_second                     NaN           NaN\n",
      "feature_politeness_==Direct_start==_second               NaN           NaN\n",
      "feature_politeness_==Factuality==_second                 NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "feature_combos = [[\"politeness_strategies\"], [\"prompt_types\"], [\"politeness_strategies\", \"prompt_types\"]]\n",
    "combo_names = []\n",
    "accs = []\n",
    "for combo in feature_combos:\n",
    "    combo_names.append(\"+\".join(combo).replace(\"_\", \" \"))\n",
    "    accuracy = run_pipeline(combo)\n",
    "    accs.append(accuracy)\n",
    "results_df = pd.DataFrame({\"Accuracy\": accs}, index=combo_names)\n",
    "results_df.index.name = \"Feature set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature set</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>politeness strategies</th>\n",
       "      <td>0.607874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt types</th>\n",
       "      <td>0.595276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politeness strategies+prompt types</th>\n",
       "      <td>0.625197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Accuracy\n",
       "Feature set                                 \n",
       "politeness strategies               0.607874\n",
       "prompt types                        0.595276\n",
       "politeness strategies+prompt types  0.625197"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see the table\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
