{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo, we demonstrate how to:\n",
    "\n",
    "1. Annotate a Corpus's utterances with their bag-of-words vector representations\n",
    "2. Use these bag-of-words vectors in predictive tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an introduction to vectors in ConvoKit, check out this [demo](https://github.com/CornellNLP/ConvoKit/blob/master/examples/vectors/vector_demo.ipynb) first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import convokit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import Corpus, download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /Users/calebchiam/.convokit/downloads/subreddit-Cornell\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(filename=download('subreddit-Cornell'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 7568\n",
      "Number of Utterances: 74467\n",
      "Number of Conversations: 10744\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotating the Corpus with bag-of-words vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, we use ConvoKit's [Bag-of-words Transformer](https://convokit.cornell.edu/documentation/bow.html) and set it to vectorize the Corpus's utterances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import BoWTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing default unigram CountVectorizer...Done.\n"
     ]
    }
   ],
   "source": [
    "bow_transformer = BoWTransformer(obj_type=\"utterance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a custom text vectorizer can be sent by configuring the vectorizer parameter:\n",
    "\n",
    "e.g. BoWTransformer(obj_type=\"utterance\", *vectorizer*=...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect one of the Corpus utterances to see the changes that get made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before transformation\n",
    "corpus.get_utterance('dsbgljl').vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<convokit.model.corpus.Corpus at 0x7f8e991c5f90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_transformer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bow_vector']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after transformation\n",
    "corpus.get_utterance('dsbgljl').vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Corpus now has a new vector matrix associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bow_vector'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvoKitMatrix('name': bow_vector, 'matrix': <74467x9340 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2108383 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.get_vector_matrix('bow_vector')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive task: will an utterance (i.e. Reddit comment) have a positive score?\n",
    "\n",
    "We want to predict whether an utterance will have a positive score (i.e. more upvotes than downvotes) based on its bag-of-words vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting a random utterance, we see that it has a 'score' metadata attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 2,\n",
       " 'top_level_comment': 'c3d45vg',\n",
       " 'retrieved_on': 1428110290,\n",
       " 'gilded': 0,\n",
       " 'gildings': None,\n",
       " 'subreddit': 'Cornell',\n",
       " 'stickied': False,\n",
       " 'permalink': '',\n",
       " 'author_flair_text': ''}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.random_utterance().meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use ConvoKit's VectorClassifier to train a classifier model predicting for whether the utterance's score is positive. Notice that the labeller is how we indicate the binary y value that we want the internal model to predict for, while vector_name specifies the vector feature set (i.e. the X data) to use in training the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import VectorClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized default classification model (standard scaled logistic regression).\n"
     ]
    }
   ],
   "source": [
    "bow_classifier = VectorClassifier(obj_type=\"utterance\", \n",
    "                                  vector_name='bow_vector',\n",
    "                                  labeller=lambda utt: utt.meta['score'] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<convokit.model.corpus.Corpus at 0x7f8e991c5f90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This fit_transform() step fits the classifier and then uses it to compute predictions for all the \n",
    "# utterances in the Corpus\n",
    "bow_classifier.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dhhm9sa</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dw553ml</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dvzmhdx</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dvzpp79</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dw0imao</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c3bsi2g</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dw0mm3b</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d5pddzi</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dw25pga</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5om61s</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prediction  pred_score\n",
       "id                             \n",
       "dhhm9sa        True         1.0\n",
       "dw553ml        True         1.0\n",
       "dvzmhdx        True         1.0\n",
       "dvzpp79        True         1.0\n",
       "dw0imao        True         1.0\n",
       "c3bsi2g        True         1.0\n",
       "dw0mm3b        True         1.0\n",
       "d5pddzi        True         1.0\n",
       "dw25pga        True         1.0\n",
       "5om61s         True         1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A DataFrame summary of the computed predictions\n",
    "bow_classifier.summarize(corpus).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then inspect the coefficient weights assigned to the bag-of-words n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hotels</th>\n",
       "      <td>1.270001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hbhs</th>\n",
       "      <td>1.115690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engine</th>\n",
       "      <td>1.109702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>involves</th>\n",
       "      <td>1.081836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lincoln</th>\n",
       "      <td>1.071464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               coef\n",
       "feat_name          \n",
       "hotels     1.270001\n",
       "hbhs       1.115690\n",
       "engine     1.109702\n",
       "involves   1.081836\n",
       "lincoln    1.071464"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The ngrams weighted most positively (i.e. utterances with these ngrams are more likely to have positive scores)\n",
    "bow_classifier.get_coefs(feature_names=corpus.get_vector_matrix('bow_vector').columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mahogany</th>\n",
       "      <td>-0.667785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ignoreme</th>\n",
       "      <td>-0.722992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hilton</th>\n",
       "      <td>-0.742234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>binary</th>\n",
       "      <td>-0.764383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creation</th>\n",
       "      <td>-0.784593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               coef\n",
       "feat_name          \n",
       "mahogany  -0.667785\n",
       "ignoreme  -0.722992\n",
       "hilton    -0.742234\n",
       "binary    -0.764383\n",
       "creation  -0.784593"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_classifier.get_coefs(feature_names=bow_transformer.get_vocabulary()).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9279546644822538"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The base accuracy by predicting all objects to have the majority label, i.e. has positive score\n",
    "bow_classifier.base_accuracy(corpus)\n",
    "\n",
    "# 92.8% of the corpus utterances already have a positive score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9491452589737737"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our classifier's accuracy on the Corpus\n",
    "bow_classifier.accuracy(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.34      0.49      5365\n",
      "        True       0.95      1.00      0.97     69102\n",
      "\n",
      "    accuracy                           0.95     74467\n",
      "   macro avg       0.91      0.67      0.73     74467\n",
      "weighted avg       0.95      0.95      0.94     74467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bow_classifier.classification_report(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-words prediction for Conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as utterances have bag-of-words vectors, we might imagine Conversations and Speakers having bag-of-words vectors as well, where:\n",
    "- The text of a Conversation is the *combined* texts of all the Utterances within it\n",
    "- The text of a Speaker is the *combined* texts of all the Utterances made by the Speaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BoWTransformer provides native support for such vectorizations. In this example, we predict for whether a Conversation will eventually double in length or stay the same based on the bag-of-words representations of the first five utterances in the Conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As r/Cornell's Conversations begin with the thread post (instead of only comments in the thread), we reindex the Conversations to begin with the top-level comments in each thread. This is a necessary step as our focus is on whether or not a **comment thread** will double in length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_level_comment_ids = [utt.id for utt in corpus.iter_utterances() if utt.id == utt.meta['top_level_comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 7568\n",
      "Number of Utterances: 74467\n",
      "Number of Conversations: 10744\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32893"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_level_comment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mWARNING: \u001b[0mConversation pcww4 reply-to chain does not form a valid tree.\n",
      "\u001b[91mWARNING: \u001b[0mConversation pegd2 reply-to chain does not form a valid tree.\n",
      "\u001b[91mWARNING: \u001b[0mFailed to find some of the specified new convo roots:\n",
      "\n",
      "['c3ocsyl', 'c3p1rn8', 'c3oyf4d', 'c3p8bze', 'c3od15i']\n"
     ]
    }
   ],
   "source": [
    "threads_corpus = corpus.reindex_conversations(corpus, new_convo_roots=top_level_comment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 6160\n",
      "Number of Utterances: 63697\n",
      "Number of Conversations: 32888\n"
     ]
    }
   ],
   "source": [
    "threads_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label annotation for whether the thread doubles in length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for thread in threads_corpus.iter_conversations():\n",
    "    thread_len = len(list(thread.iter_utterances()))\n",
    "    if thread_len == 5:\n",
    "        thread.meta['thread_doubles'] = False\n",
    "    elif thread_len >= 10:\n",
    "        thread.meta['thread_doubles'] = True\n",
    "    else:\n",
    "        thread.meta['thread_doubles'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BoW annotation of first 5 utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing default unigram CountVectorizer...Done.\n"
     ]
    }
   ],
   "source": [
    "# We set our BoWTransformer to use only the first 5 utterances in the Conversation by configuring 'text_func'\n",
    "bow_transformer2 = BoWTransformer(obj_type=\"conversation\", vector_name='bow_vector_2',\n",
    "                text_func=lambda convo: ' '.join([utt.text for utt in convo.get_chronological_utterance_list()[:5]])\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<convokit.model.corpus.Corpus at 0x7f8ea1a7e6d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_transformer2.fit_transform(threads_corpus, selector=lambda convo: convo.meta['thread_doubles'] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bow_vector_2'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threads_corpus.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized default classification model (standard scaled logistic regression).\n"
     ]
    }
   ],
   "source": [
    "bow_classifier2 = VectorClassifier(obj_type=\"conversation\", vector_name='bow_vector_2',\n",
    "                                   labeller=lambda convo: convo.meta['thread_doubles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<convokit.model.corpus.Corpus at 0x7f8ea1a7e6d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_classifier2.fit_transform(threads_corpus, selector=lambda convo: convo.meta['thread_doubles'] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = bow_classifier2.summarize(threads_corpus, selector=lambda convo: convo.meta['thread_doubles'] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dt05qyf</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dandio0</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dwa6k96</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dsldpxg</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e70wjy3</th>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prediction  pred_score\n",
       "id                             \n",
       "dt05qyf        True         1.0\n",
       "dandio0        True         1.0\n",
       "dwa6k96        True         1.0\n",
       "dsldpxg        True         1.0\n",
       "e70wjy3        True         1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>drduxx1</th>\n",
       "      <td>False</td>\n",
       "      <td>2.465871e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dl7q7n2</th>\n",
       "      <td>False</td>\n",
       "      <td>8.168132e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dxfib8r</th>\n",
       "      <td>False</td>\n",
       "      <td>2.717009e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dwqaa06</th>\n",
       "      <td>False</td>\n",
       "      <td>2.680858e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d8y9akn</th>\n",
       "      <td>False</td>\n",
       "      <td>1.600627e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prediction    pred_score\n",
       "id                               \n",
       "drduxx1       False  2.465871e-12\n",
       "dl7q7n2       False  8.168132e-14\n",
       "dxfib8r       False  2.717009e-15\n",
       "dwqaa06       False  2.680858e-16\n",
       "d8y9akn       False  1.600627e-16"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6761904761904762"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_classifier2.base_accuracy(threads_corpus, selector=lambda convo: convo.meta['thread_doubles'] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992063492063492"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_classifier2.accuracy(threads_corpus, selector=lambda convo: convo.meta['thread_doubles'] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00       852\n",
      "        True       1.00      1.00      1.00       408\n",
      "\n",
      "    accuracy                           1.00      1260\n",
      "   macro avg       1.00      1.00      1.00      1260\n",
      "weighted avg       1.00      1.00      1.00      1260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bow_classifier2.classification_report(threads_corpus, selector=lambda convo: convo.meta['thread_doubles'] is not None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this artificial setup, our Bag-of-words classifier has achieved very high accuracy because the test and train data are identical. In a proper train-test split setting, our classifier would perform much more poorly. Setting up such a train-test evaluation is straightforward as well:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider only conversations that have at least 5 utterances, i.e. from earlier,\n",
    "# this is any conversation that has thread_doubles with a value that is not None.\n",
    "valid_convos = list(threads_corpus.iter_conversations(lambda convo: convo.meta['thread_doubles'] is not None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1260"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_convos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Speakers: 6160\n",
      "Number of Utterances: 63697\n",
      "Number of Conversations: 32888\n"
     ]
    }
   ],
   "source": [
    "threads_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_convos, test_convos = train_test_split(valid_convos, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008 252\n"
     ]
    }
   ],
   "source": [
    "print(len(train_convos), len(test_convos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for convo in train_convos:\n",
    "    convo.meta['train_test_type'] = 'train'\n",
    "    \n",
    "for convo in test_convos:\n",
    "    convo.meta['train_test_type'] = 'test'\n",
    "\n",
    "# any other convo not part of the train/test split should have the metadata attribute value set to None\n",
    "for convo in threads_corpus.iter_conversations():\n",
    "    if 'train_test_type' not in convo.meta:\n",
    "        convo.meta['train_test_type'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<convokit.classifier.vectorClassifier.VectorClassifier at 0x7f8ea28c91d0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the classifier only on train data\n",
    "bow_classifier2.fit(threads_corpus, selector=lambda convo: convo.meta['train_test_type'] == 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dandio0</th>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d7247x6</th>\n",
       "      <td>True</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dn521re</th>\n",
       "      <td>True</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dkbth1f</th>\n",
       "      <td>True</td>\n",
       "      <td>9.999970e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cebb5so</th>\n",
       "      <td>True</td>\n",
       "      <td>9.999454e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d3rfzjm</th>\n",
       "      <td>False</td>\n",
       "      <td>1.442058e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c7h95bx</th>\n",
       "      <td>False</td>\n",
       "      <td>1.092930e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cx87pi5</th>\n",
       "      <td>False</td>\n",
       "      <td>3.321833e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dxfib8r</th>\n",
       "      <td>False</td>\n",
       "      <td>2.046636e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>csgknhh</th>\n",
       "      <td>False</td>\n",
       "      <td>2.755765e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         prediction    pred_score\n",
       "id                               \n",
       "dandio0        True  1.000000e+00\n",
       "d7247x6        True  1.000000e+00\n",
       "dn521re        True  9.999998e-01\n",
       "dkbth1f        True  9.999970e-01\n",
       "cebb5so        True  9.999454e-01\n",
       "...             ...           ...\n",
       "d3rfzjm       False  1.442058e-08\n",
       "c7h95bx       False  1.092930e-08\n",
       "cx87pi5       False  3.321833e-09\n",
       "dxfib8r       False  2.046636e-14\n",
       "csgknhh       False  2.755765e-16\n",
       "\n",
       "[252 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the classifier on test data\n",
    "\n",
    "# First annotate the conversation with the prediction\n",
    "bow_classifier2.transform(threads_corpus, selector=lambda convo: convo.meta['train_test_type'] == 'test')\n",
    "\n",
    "# Then evaluate the accuracy of this prediction\n",
    "bow_classifier2.summarize(threads_corpus, selector=lambda convo: convo.meta['train_test_type'] == 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.63      0.76      0.69       156\n",
      "        True       0.41      0.27      0.33        96\n",
      "\n",
      "    accuracy                           0.58       252\n",
      "   macro avg       0.52      0.52      0.51       252\n",
      "weighted avg       0.55      0.58      0.55       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bow_classifier2.classification_report(threads_corpus, \n",
    "                                            selector=lambda convo: convo.meta['train_test_type'] == 'test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running a cross-validated evaluation...Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.6031746 , 0.63095238, 0.66666667, 0.63095238, 0.67460317])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_classifier2.evaluate_with_cv(threads_corpus, selector=lambda convo: convo.meta['thread_doubles'] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running a train-test-split evaluation...\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6071428571428571,\n",
       " array([[125,  46],\n",
       "        [ 53,  28]]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_classifier2.evaluate_with_train_test_split(threads_corpus, \n",
    "                                               selector=lambda convo: convo.meta['thread_doubles'] is not None,\n",
    "                                               test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the demo. Check out [our other demo on predicting comment-growth and commenter-growth](https://github.com/CornellNLP/ConvoKit/blob/master/examples/hyperconvo/predictive_tasks.ipynb) to see how bag-of-words vectors can be used in a paired predictive setting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
