{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the paired data from \"Winning Arguments: Interaction Dynamics and Persuasion Strategies in Good-faith Online Discussions\" into ConvoKit format (the data used in section 4 of their paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: we are only converting the subset data used to measure successful vs. unsuccessful arguments. All data provided by \n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Winning Arguments: Interaction Dynamics and Persuasion Strategies in Good-faith Online Discussions\n",
    "Chenhao Tan, Vlad Niculae, Cristian Danescu-Niculescu-Mizil, Lillian Lee. \n",
    "In Proceedings of the 25th International World Wide Web Conference (WWW'2016).\n",
    "\n",
    "The paper, data, and associated materials can be found at:\n",
    "http://chenhaot.com/pages/changemyview.html\n",
    "\n",
    "If you use this data, please cite:\n",
    "@inproceedings{tan+etal:16a, \n",
    "    author = {Chenhao Tan and Vlad Niculae and Cristian Danescu-Niculescu-Mizil and Lillian Lee}, \n",
    "    title = {Winning Arguments: Interaction Dynamics and Persuasion Strategies in Good-faith Online Discussions}, \n",
    "    year = {2016}, \n",
    "    booktitle = {Proceedings of WWW} \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note at the blog in the hyperlink above, the data we used is the original data (linked with corresponding README, PDF and Slides). We did *not* use the updated data provided on 11/11/2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the data conversion, you need to download the data, linked above, and extract the data from the tar archive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here I set the working directory to where I store the convokit package \n",
    "os.chdir('C:\\\\Users\\\\Andrew\\\\Desktop\\\\Cornell-Conversational-Analysis-Toolkit')\n",
    "from convokit import Corpus, Speaker, Utterance, meta_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the original pair data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3456\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_author</th>\n",
       "      <th>op_text</th>\n",
       "      <th>op_title</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>op_name</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3451</td>\n",
       "      <td>helpful_hank</td>\n",
       "      <td>In opposing injustice, we must strive not to p...</td>\n",
       "      <td>CMV: Drawing images of Mohammed and posting th...</td>\n",
       "      <td>{'ancestor': 't1_cniw4jr', 'author': 'cold08',...</td>\n",
       "      <td>{'ancestor': 't1_cniu655', 'author': 'learhpa'...</td>\n",
       "      <td>t3_2rsgv3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3452</td>\n",
       "      <td>VIRMD</td>\n",
       "      <td>The rate at which income is taxed (at least in...</td>\n",
       "      <td>CMV: The rate at which one's income is taxed s...</td>\n",
       "      <td>{'ancestor': 't1_cnirwl5', 'author': 'scottevi...</td>\n",
       "      <td>{'ancestor': 't1_cnjrwds', 'author': 'natha105...</td>\n",
       "      <td>t3_2rs57a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3453</td>\n",
       "      <td>VIRMD</td>\n",
       "      <td>The rate at which income is taxed (at least in...</td>\n",
       "      <td>CMV: The rate at which one's income is taxed s...</td>\n",
       "      <td>{'ancestor': 't1_cnjiwww', 'author': 'AdmiralC...</td>\n",
       "      <td>{'ancestor': 't1_cnjrwds', 'author': 'natha105...</td>\n",
       "      <td>t3_2rs57a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3454</td>\n",
       "      <td>GetCapeFly</td>\n",
       "      <td>It seems logical to me that school hours shoul...</td>\n",
       "      <td>CMV: School hours should be 9am to 5pm to matc...</td>\n",
       "      <td>{'ancestor': 't1_cnii75i', 'author': '[deleted...</td>\n",
       "      <td>{'ancestor': 't1_cnijhp3', 'author': 'funchy',...</td>\n",
       "      <td>t3_2rqvf8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3455</td>\n",
       "      <td>luxo42</td>\n",
       "      <td>My argument assumes the Christian theology tau...</td>\n",
       "      <td>CMV: In heaven, as long as an individual has f...</td>\n",
       "      <td>{'ancestor': 't1_cnj7d44', 'author': 'Field-K'...</td>\n",
       "      <td>{'ancestor': 't1_cnih5d9', 'author': '____Matt...</td>\n",
       "      <td>t3_2rq5g3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         op_author                                            op_text  \\\n",
       "3451  helpful_hank  In opposing injustice, we must strive not to p...   \n",
       "3452         VIRMD  The rate at which income is taxed (at least in...   \n",
       "3453         VIRMD  The rate at which income is taxed (at least in...   \n",
       "3454    GetCapeFly  It seems logical to me that school hours shoul...   \n",
       "3455        luxo42  My argument assumes the Christian theology tau...   \n",
       "\n",
       "                                               op_title  \\\n",
       "3451  CMV: Drawing images of Mohammed and posting th...   \n",
       "3452  CMV: The rate at which one's income is taxed s...   \n",
       "3453  CMV: The rate at which one's income is taxed s...   \n",
       "3454  CMV: School hours should be 9am to 5pm to matc...   \n",
       "3455  CMV: In heaven, as long as an individual has f...   \n",
       "\n",
       "                                               positive  \\\n",
       "3451  {'ancestor': 't1_cniw4jr', 'author': 'cold08',...   \n",
       "3452  {'ancestor': 't1_cnirwl5', 'author': 'scottevi...   \n",
       "3453  {'ancestor': 't1_cnjiwww', 'author': 'AdmiralC...   \n",
       "3454  {'ancestor': 't1_cnii75i', 'author': '[deleted...   \n",
       "3455  {'ancestor': 't1_cnj7d44', 'author': 'Field-K'...   \n",
       "\n",
       "                                               negative    op_name  train  \n",
       "3451  {'ancestor': 't1_cniu655', 'author': 'learhpa'...  t3_2rsgv3      1  \n",
       "3452  {'ancestor': 't1_cnjrwds', 'author': 'natha105...  t3_2rs57a      1  \n",
       "3453  {'ancestor': 't1_cnjrwds', 'author': 'natha105...  t3_2rs57a      1  \n",
       "3454  {'ancestor': 't1_cnijhp3', 'author': 'funchy',...  t3_2rqvf8      1  \n",
       "3455  {'ancestor': 't1_cnih5d9', 'author': '____Matt...  t3_2rq5g3      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairDFtrain=pd.read_json('C:\\\\Users\\\\Andrew\\\\Documents\\\\pair_task\\\\train_pair_data.jsonlist',lines=True)\n",
    "print(len(pairDFtrain))\n",
    "pairDFtrain['train']=1\n",
    "pairDFtrain.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "807\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_author</th>\n",
       "      <th>op_text</th>\n",
       "      <th>op_title</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>op_name</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>923iwek</td>\n",
       "      <td>I'll start off by saying I'm a vegetarian and ...</td>\n",
       "      <td>CMV: The contribution of vegans/vegetarians an...</td>\n",
       "      <td>{'ancestor': 't1_cundk5r', 'author': 'ghoooooo...</td>\n",
       "      <td>{'ancestor': 't1_cunbl8g', 'author': 'ClimateM...</td>\n",
       "      <td>t3_3j8yfq</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>923iwek</td>\n",
       "      <td>I'll start off by saying I'm a vegetarian and ...</td>\n",
       "      <td>CMV: The contribution of vegans/vegetarians an...</td>\n",
       "      <td>{'ancestor': 't1_cunbkbz', 'author': 'archagon...</td>\n",
       "      <td>{'ancestor': 't1_cuncrke', 'author': 'Diomange...</td>\n",
       "      <td>t3_3j8yfq</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Navyurf</td>\n",
       "      <td>Hello, I'm Luke and for the longest time a sma...</td>\n",
       "      <td>CMV:I want to live in Scandinavia</td>\n",
       "      <td>{'ancestor': 't1_cun0c3t', 'author': 'huadpe',...</td>\n",
       "      <td>{'ancestor': 't1_cun2oqr', 'author': 'iamambie...</td>\n",
       "      <td>t3_3j7dlx</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>trashlunch</td>\n",
       "      <td>By \"practical reason,\" I mean a reason that mo...</td>\n",
       "      <td>CMV: There is no practical reason for any indi...</td>\n",
       "      <td>{'ancestor': 't1_cumn3j4', 'author': 'ReOsIr10...</td>\n",
       "      <td>{'ancestor': 't1_cumqh8n', 'author': 'Omega037...</td>\n",
       "      <td>t3_3j64aa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>VaginalExcrement</td>\n",
       "      <td>\\n_____\\n\\nAlright, so, i was challenged by a ...</td>\n",
       "      <td>CMV: We Should execute the weak to improve the...</td>\n",
       "      <td>{'ancestor': 't1_cumhf65', 'author': 'BadKeyMa...</td>\n",
       "      <td>{'ancestor': 't1_cumi9vr', 'author': 'MCBeatho...</td>\n",
       "      <td>t3_3j5b7g</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          op_author                                            op_text  \\\n",
       "0           923iwek  I'll start off by saying I'm a vegetarian and ...   \n",
       "1           923iwek  I'll start off by saying I'm a vegetarian and ...   \n",
       "2           Navyurf  Hello, I'm Luke and for the longest time a sma...   \n",
       "3        trashlunch  By \"practical reason,\" I mean a reason that mo...   \n",
       "4  VaginalExcrement  \\n_____\\n\\nAlright, so, i was challenged by a ...   \n",
       "\n",
       "                                            op_title  \\\n",
       "0  CMV: The contribution of vegans/vegetarians an...   \n",
       "1  CMV: The contribution of vegans/vegetarians an...   \n",
       "2                  CMV:I want to live in Scandinavia   \n",
       "3  CMV: There is no practical reason for any indi...   \n",
       "4  CMV: We Should execute the weak to improve the...   \n",
       "\n",
       "                                            positive  \\\n",
       "0  {'ancestor': 't1_cundk5r', 'author': 'ghoooooo...   \n",
       "1  {'ancestor': 't1_cunbkbz', 'author': 'archagon...   \n",
       "2  {'ancestor': 't1_cun0c3t', 'author': 'huadpe',...   \n",
       "3  {'ancestor': 't1_cumn3j4', 'author': 'ReOsIr10...   \n",
       "4  {'ancestor': 't1_cumhf65', 'author': 'BadKeyMa...   \n",
       "\n",
       "                                            negative    op_name  train  \n",
       "0  {'ancestor': 't1_cunbl8g', 'author': 'ClimateM...  t3_3j8yfq      0  \n",
       "1  {'ancestor': 't1_cuncrke', 'author': 'Diomange...  t3_3j8yfq      0  \n",
       "2  {'ancestor': 't1_cun2oqr', 'author': 'iamambie...  t3_3j7dlx      0  \n",
       "3  {'ancestor': 't1_cumqh8n', 'author': 'Omega037...  t3_3j64aa      0  \n",
       "4  {'ancestor': 't1_cumi9vr', 'author': 'MCBeatho...  t3_3j5b7g      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairDFhold=pd.read_json('C:\\\\Users\\\\Andrew\\\\Documents\\\\pair_task\\\\heldout_pair_data.jsonlist',lines=True)\n",
    "print(len(pairDFhold))\n",
    "pairDFhold['train']=0\n",
    "pairDFhold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairDF=pd.concat([pairDFtrain,pairDFhold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4263"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Each observation has the reply comments in a conversation that changes the OP's (OP: original poster) mind (positive column) and a conversation that does not change the OP's mind (negative column). Unfortunately, this does not include the comments that OP made after their original post: the comments made by the OP in response to the second conversant's arguments. To find the comments made by OP (i.e. the other half of the conversation), we need to retrieve them from the 'all' dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First: collect the unique identifiers for each original post in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3051"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyms = list(set(pairDF.op_name))\n",
    "len(nyms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect each post from the full dataset (this has the full comment threads, whereas the pair data above only has the first response):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: if you have not run this notebook before, then you will need to uncomment the following seven code cells. It will load the full dataset into your working memory and save only the observations that match with the posts in the pair_data above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #note: this is over 2 GB of data, uncomment the following two lines to read in the data\n",
    "\n",
    "# dataT = pd.read_json('C:\\\\Users\\\\Andrew\\\\Documents\\\\all\\\\train_period_data.jsonlist', lines=True)\n",
    "# # len(dataT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only the posts that are identified in our original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #note: this reduces the 2 GB dataset to a similar size as our original dataset\n",
    "\n",
    "# dataT=dataT[dataT.name.isin(nyms)]\n",
    "# len(dataT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # do the same for the holdout data \n",
    "# dataH = pd.read_json('C:\\\\Users\\\\Andrew\\\\Documents\\\\all\\\\heldout_period_data.jsonlist', lines=True)\n",
    "# len(dataH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataH=dataH[dataH.name.isin(nyms)]\n",
    "# len(dataH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #combine holdout and train datasets\n",
    "# data = pd.concat([dataT,dataH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the posts from the full dataset that are the same as posts in our pair data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #note: I save the data as a pickle file so I don't have to reload the 2 GB dataset in my working memory\n",
    "\n",
    "# data.to_pickle('C:\\\\Users\\\\Andrew\\\\Downloads\\\\pairAll.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I have already run this notebook, so I can just load this dataset back into working memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle('C:\\\\Users\\\\Andrew\\\\Downloads\\\\pairAll.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approved_by</th>\n",
       "      <th>archived</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>banned_by</th>\n",
       "      <th>clicked</th>\n",
       "      <th>comments</th>\n",
       "      <th>created</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>...</th>\n",
       "      <th>stickied</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>suggested_sort</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "      <th>url</th>\n",
       "      <th>user_reports</th>\n",
       "      <th>visited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EconomistMagazine</td>\n",
       "      <td>None</td>\n",
       "      <td>2Δ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'subreddit_id': 't5_2w2s8', 'banned_by': Non...</td>\n",
       "      <td>1431231205</td>\n",
       "      <td>1431227605</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t5_2w2s8</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>CMV: There will never be another military draf...</td>\n",
       "      <td>31</td>\n",
       "      <td>http://www.reddit.com/r/changemyview/comments/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2247</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mike2800</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'subreddit_id': 't5_2w2s8', 'banned_by': Non...</td>\n",
       "      <td>1431213658</td>\n",
       "      <td>1431210058</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t5_2w2s8</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>CMV: I'm anti abortion, and I feel like an ass...</td>\n",
       "      <td>44</td>\n",
       "      <td>http://www.reddit.com/r/changemyview/comments/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EpicPiDude</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'subreddit_id': 't5_2w2s8', 'banned_by': Non...</td>\n",
       "      <td>1431210521</td>\n",
       "      <td>1431206921</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t5_2w2s8</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>CMV: You should have to pass the citizenship t...</td>\n",
       "      <td>34</td>\n",
       "      <td>http://www.reddit.com/r/changemyview/comments/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>G01denW01f11</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'subreddit_id': 't5_2w2s8', 'banned_by': Non...</td>\n",
       "      <td>1431187622</td>\n",
       "      <td>1431184022</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t5_2w2s8</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>CMV: Black and white are colors</td>\n",
       "      <td>27</td>\n",
       "      <td>http://www.reddit.com/r/changemyview/comments/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WumboWombo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[{'subreddit_id': 't5_2w2s8', 'banned_by': Non...</td>\n",
       "      <td>1431111913</td>\n",
       "      <td>1431108313</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>changemyview</td>\n",
       "      <td>t5_2w2s8</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>CMV: America's economy is destined to fail</td>\n",
       "      <td>97</td>\n",
       "      <td>http://www.reddit.com/r/changemyview/comments/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      approved_by  archived             author author_flair_css_class  \\\n",
       "2242          NaN       0.0  EconomistMagazine                   None   \n",
       "2247          NaN       0.0           Mike2800                   None   \n",
       "2249          NaN       0.0         EpicPiDude                   None   \n",
       "2254          NaN       0.0       G01denW01f11                   None   \n",
       "2262          NaN       0.0         WumboWombo                   None   \n",
       "\n",
       "     author_flair_text  banned_by  clicked  \\\n",
       "2242                2Δ        NaN    False   \n",
       "2247              None        NaN    False   \n",
       "2249              None        NaN    False   \n",
       "2254              None        NaN    False   \n",
       "2262              None        NaN    False   \n",
       "\n",
       "                                               comments     created  \\\n",
       "2242  [{'subreddit_id': 't5_2w2s8', 'banned_by': Non...  1431231205   \n",
       "2247  [{'subreddit_id': 't5_2w2s8', 'banned_by': Non...  1431213658   \n",
       "2249  [{'subreddit_id': 't5_2w2s8', 'banned_by': Non...  1431210521   \n",
       "2254  [{'subreddit_id': 't5_2w2s8', 'banned_by': Non...  1431187622   \n",
       "2262  [{'subreddit_id': 't5_2w2s8', 'banned_by': Non...  1431111913   \n",
       "\n",
       "      created_utc  ... stickied     subreddit  subreddit_id  suggested_sort  \\\n",
       "2242   1431227605  ...    False  changemyview      t5_2w2s8             NaN   \n",
       "2247   1431210058  ...    False  changemyview      t5_2w2s8             NaN   \n",
       "2249   1431206921  ...    False  changemyview      t5_2w2s8             NaN   \n",
       "2254   1431184022  ...    False  changemyview      t5_2w2s8             NaN   \n",
       "2262   1431108313  ...    False  changemyview      t5_2w2s8             NaN   \n",
       "\n",
       "      thumbnail                                              title  ups  \\\n",
       "2242             CMV: There will never be another military draf...   31   \n",
       "2247             CMV: I'm anti abortion, and I feel like an ass...   44   \n",
       "2249             CMV: You should have to pass the citizenship t...   34   \n",
       "2254                               CMV: Black and white are colors   27   \n",
       "2262                    CMV: America's economy is destined to fail   97   \n",
       "\n",
       "                                                    url  user_reports visited  \n",
       "2242  http://www.reddit.com/r/changemyview/comments/...            []   False  \n",
       "2247  http://www.reddit.com/r/changemyview/comments/...            []   False  \n",
       "2249  http://www.reddit.com/r/changemyview/comments/...            []   False  \n",
       "2254  http://www.reddit.com/r/changemyview/comments/...            []   False  \n",
       "2262  http://www.reddit.com/r/changemyview/comments/...            []   False  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3051"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4263"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['approved_by', 'archived', 'author', 'author_flair_css_class',\n",
       "       'author_flair_text', 'banned_by', 'clicked', 'comments', 'created',\n",
       "       'created_utc', 'distinguished', 'domain', 'downs', 'edited', 'from',\n",
       "       'from_id', 'from_kind', 'gilded', 'hidden', 'hide_score', 'id',\n",
       "       'is_self', 'likes', 'link_flair_css_class', 'link_flair_text', 'media',\n",
       "       'media_embed', 'mod_reports', 'name', 'num_comments', 'num_reports',\n",
       "       'over_18', 'permalink', 'quarantine', 'removal_reason',\n",
       "       'report_reasons', 'saved', 'score', 'secure_media',\n",
       "       'secure_media_embed', 'selftext', 'selftext_html', 'stickied',\n",
       "       'subreddit', 'subreddit_id', 'suggested_sort', 'thumbnail', 'title',\n",
       "       'ups', 'url', 'user_reports', 'visited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only keep the comments and the identifier for merging with the original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[['comments','name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['op_author', 'op_text', 'op_title', 'positive', 'negative', 'op_name',\n",
       "       'train'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairDF.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This joins the comments in the 'all' data, with the posts we are interested in studying:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairDF=pairDF.join(data.set_index('name'), on='op_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4263"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_author</th>\n",
       "      <th>op_text</th>\n",
       "      <th>op_title</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>op_name</th>\n",
       "      <th>train</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>802</td>\n",
       "      <td>EpicPiDude</td>\n",
       "      <td>Take three people, Persons A, B, and C. They l...</td>\n",
       "      <td>CMV: You should have to pass the citizenship t...</td>\n",
       "      <td>{'ancestor': 't1_cr427yp', 'author': 'Raintee9...</td>\n",
       "      <td>{'ancestor': 't1_cr3xa7x', 'author': '[deleted...</td>\n",
       "      <td>t3_35fjb1</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'subreddit_id': 't5_2w2s8', 'banned_by': Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>803</td>\n",
       "      <td>EpicPiDude</td>\n",
       "      <td>Take three people, Persons A, B, and C. They l...</td>\n",
       "      <td>CMV: You should have to pass the citizenship t...</td>\n",
       "      <td>{'ancestor': 't1_cr49j5s', 'author': 'phcullen...</td>\n",
       "      <td>{'ancestor': 't1_cr3xa7x', 'author': '[deleted...</td>\n",
       "      <td>t3_35fjb1</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'subreddit_id': 't5_2w2s8', 'banned_by': Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>804</td>\n",
       "      <td>G01denW01f11</td>\n",
       "      <td>Artists, pedants, and pedantic artists like to...</td>\n",
       "      <td>CMV: Black and white are colors</td>\n",
       "      <td>{'ancestor': 't1_cr3mhui', 'author': 'woahmani...</td>\n",
       "      <td>{'ancestor': 't1_cr3n4yp', 'author': 'niczar',...</td>\n",
       "      <td>t3_35edub</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'subreddit_id': 't5_2w2s8', 'banned_by': Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>805</td>\n",
       "      <td>WumboWombo</td>\n",
       "      <td>I'm young, so of course my biggest concern at ...</td>\n",
       "      <td>CMV: America's economy is destined to fail</td>\n",
       "      <td>{'ancestor': 't1_cr2suj3', 'author': 'huadpe',...</td>\n",
       "      <td>{'ancestor': 't1_cr2s3nt', 'author': 'scottevi...</td>\n",
       "      <td>t3_35bc4b</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'subreddit_id': 't5_2w2s8', 'banned_by': Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>806</td>\n",
       "      <td>WumboWombo</td>\n",
       "      <td>I'm young, so of course my biggest concern at ...</td>\n",
       "      <td>CMV: America's economy is destined to fail</td>\n",
       "      <td>{'ancestor': 't1_cr2sadm', 'author': 'gunnervi...</td>\n",
       "      <td>{'ancestor': 't1_cr2soeg', 'author': 'celerita...</td>\n",
       "      <td>t3_35bc4b</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'subreddit_id': 't5_2w2s8', 'banned_by': Non...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        op_author                                            op_text  \\\n",
       "802    EpicPiDude  Take three people, Persons A, B, and C. They l...   \n",
       "803    EpicPiDude  Take three people, Persons A, B, and C. They l...   \n",
       "804  G01denW01f11  Artists, pedants, and pedantic artists like to...   \n",
       "805    WumboWombo  I'm young, so of course my biggest concern at ...   \n",
       "806    WumboWombo  I'm young, so of course my biggest concern at ...   \n",
       "\n",
       "                                              op_title  \\\n",
       "802  CMV: You should have to pass the citizenship t...   \n",
       "803  CMV: You should have to pass the citizenship t...   \n",
       "804                    CMV: Black and white are colors   \n",
       "805         CMV: America's economy is destined to fail   \n",
       "806         CMV: America's economy is destined to fail   \n",
       "\n",
       "                                              positive  \\\n",
       "802  {'ancestor': 't1_cr427yp', 'author': 'Raintee9...   \n",
       "803  {'ancestor': 't1_cr49j5s', 'author': 'phcullen...   \n",
       "804  {'ancestor': 't1_cr3mhui', 'author': 'woahmani...   \n",
       "805  {'ancestor': 't1_cr2suj3', 'author': 'huadpe',...   \n",
       "806  {'ancestor': 't1_cr2sadm', 'author': 'gunnervi...   \n",
       "\n",
       "                                              negative    op_name  train  \\\n",
       "802  {'ancestor': 't1_cr3xa7x', 'author': '[deleted...  t3_35fjb1      0   \n",
       "803  {'ancestor': 't1_cr3xa7x', 'author': '[deleted...  t3_35fjb1      0   \n",
       "804  {'ancestor': 't1_cr3n4yp', 'author': 'niczar',...  t3_35edub      0   \n",
       "805  {'ancestor': 't1_cr2s3nt', 'author': 'scottevi...  t3_35bc4b      0   \n",
       "806  {'ancestor': 't1_cr2soeg', 'author': 'celerita...  t3_35bc4b      0   \n",
       "\n",
       "                                              comments  \n",
       "802  [{'subreddit_id': 't5_2w2s8', 'banned_by': Non...  \n",
       "803  [{'subreddit_id': 't5_2w2s8', 'banned_by': Non...  \n",
       "804  [{'subreddit_id': 't5_2w2s8', 'banned_by': Non...  \n",
       "805  [{'subreddit_id': 't5_2w2s8', 'banned_by': Non...  \n",
       "806  [{'subreddit_id': 't5_2w2s8', 'banned_by': Non...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairDF.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all comments made within every CMV post in our dataset, we need to extract only the comments that correspond to a positive argument and negative argument (i.e. the ones recorded as either changing OP's mind or not)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, collect the identifiers for each comment made by the respondent attempting to change the OP's mind (there is a respondent in both the positive and negative columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectResponses(responseList):\n",
    "    iDs=[]\n",
    "    if len(responseList['comments'])>0:\n",
    "        for each in responseList['comments']:\n",
    "            iDs.append(each['id'])\n",
    "    return iDs\n",
    "pairDF['negIDs']=pairDF.negative.apply(lambda x: collectResponses(x))\n",
    "pairDF['posIDs']=pairDF.positive.apply(lambda x: collectResponses(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now collect each of the comment identifiers that signify a response to the challenger by OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectOPcommentIDs(op_auth, allComments, replyIDs):\n",
    "    opIds =[]\n",
    "    for comment in allComments:\n",
    "        if comment['parent_id'].split('_')[1] in replyIDs: \n",
    "            if 'author' in comment.keys():\n",
    "                if comment['author'] == op_auth:\n",
    "                    opIds.append(comment['id'])\n",
    "\n",
    "    return opIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairDF['opRepliesPos'] = pairDF[['op_author','comments','posIDs']].apply(lambda x: collectOPcommentIDs(x['op_author'],x['comments'],x['posIDs']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairDF['opRepliesNeg'] = pairDF[['op_author','comments','negIDs']].apply(lambda x: collectOPcommentIDs(x['op_author'],x['comments'],x['negIDs']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I collect and properly order each of the comment IDs made in the thread _only_ by either OP or the 2nd conversant studied for both succesful and unsuccesful arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orderThreadids(comments, replyIDs, opCommentIDs):\n",
    "    threadIDs=list(replyIDs)\n",
    "    for comment in comments:\n",
    "        if comment['id'] in opCommentIDs:\n",
    "            pID= comment['parent_id'].split('_')[1]\n",
    "            if pID in replyIDs:\n",
    "                threadIDs.insert(threadIDs.index(pID)+1,comment['id'])\n",
    "            \n",
    "    return threadIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairDF['posOrder']= pairDF[['comments','posIDs','opRepliesPos']].apply(lambda x: orderThreadids(x['comments'],x['posIDs'],x['opRepliesPos']) ,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairDF['negOrder']= pairDF[['comments','negIDs','opRepliesNeg']].apply(lambda x: orderThreadids(x['comments'],x['negIDs'],x['opRepliesNeg']) ,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes the ordered thread IDs for only the successful and unsuccesful arguments measured in the original paper (although, note: I have also collected the OP replies from the 'all' data, which wasn't included in the smaller pair_data).\n",
    "\n",
    "Note: I don't convert this section into convokit format, but instead I convert the full comment threads later in this notebook. If you are interested in looking at the successful and unsuccessful arguments in the convokit format, see the 'success' attribute in each utterance's metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectThread(comments, orderedThreadids):\n",
    "    threadComments=[]\n",
    "    for iD in orderedThreadids:\n",
    "        for comment in comments:\n",
    "            if iD==comment['id']:\n",
    "                threadComments.append(comment)\n",
    "    return threadComments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairDF['positiveThread'] = pairDF[['comments','posOrder']].apply(lambda x: collectThread(x['comments'],x['posOrder']),axis=1)\n",
    "pairDF['negativeThread'] = pairDF[['comments','negOrder']].apply(lambda x: collectThread(x['comments'],x['negOrder']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note above: I have just collected each individual thread (with OP comments). However, when studying this data, we may be interested in looking at the entire conversation. Therefore, instead of only converting the positive threads and negative threads into convokit format, here I simply add an attribute to the comments if they are part of either the positive or negative thread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I add the success attribute and the pair identification (see my readme file for a more detailed explanation of 'success' and 'pair_ids') :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an identification # for the paired unsuccessful/successful arguments,\n",
    "# Note: the pair # will be the same for successful-unsuccessful matched pairs with the prefix 'p_' for pair \n",
    "# if there is no paired argument for the comment (i.e. it was either the original post by OP or an uncategorized comment), \n",
    "# then pair_id = None\n",
    "c=0\n",
    "pairIDS={}\n",
    "for i, r in pairDF.iterrows():\n",
    "    \n",
    "    c=c+1\n",
    "    for comment in r.comments:\n",
    "        \n",
    "        if comment['id'] in r.posOrder:\n",
    "            comment['success']=1\n",
    "            if comment['name'] in pairIDS.keys():\n",
    "                pairIDS[comment['name']].append('p_'+str(c))\n",
    "                pairIDS[comment['name']]=list(set(pairIDS[comment['name']]))\n",
    "            else:\n",
    "                pairIDS[comment['name']]=['p_'+str(c)]\n",
    "                pairIDS[comment['name']]=list(set(pairIDS[comment['name']]))\n",
    "                \n",
    "                \n",
    "        elif comment['id'] in r.negOrder:\n",
    "            comment['success']=0\n",
    "\n",
    "            if comment['name'] in pairIDS.keys():\n",
    "                pairIDS[comment['name']].append('p_'+str(c))\n",
    "                pairIDS[comment['name']]=list(set(pairIDS[comment['name']]))\n",
    "            else:\n",
    "                pairIDS[comment['name']]=['p_'+str(c)]\n",
    "                pairIDS[comment['name']]=list(set(pairIDS[comment['name']]))\n",
    "                \n",
    "\n",
    "        \n",
    "        if comment['name'] not in pairIDS.keys():\n",
    "            pairIDS[comment['name']]=[]\n",
    "        if 'success' not in comment.keys():\n",
    "            comment['success']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a column for pair_ids collected at the op post level, note: this won't be unique at the observation level in our pairDF dataframe, but I'm just doing this for quick conversion and after converting it into convokit, I add the list in at the conversation-level metadata and it is unique per conversation\n",
    "threads = list(set(pairDF.op_name))\n",
    "pids =[]\n",
    "for thread in threads:\n",
    "    pid=[]\n",
    "    for i,r in pairDF[pairDF.op_name==thread].iterrows():\n",
    "        for comment in r.comments:\n",
    "            if len(pairIDS[comment['name']])>0:\n",
    "                for p in pairIDS[comment['name']]:\n",
    "                    pid.append(p)\n",
    "    pid=list(set(pid))\n",
    "    pids.append(pid)\n",
    "pairDF['pIDs']=pairDF.op_name.apply(lambda x: pids[threads.index(x)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is collected in a pandas dataframe with each thread's comments fully accounted for. Convert it into convokit format:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to create a list of all Redditors, or 'users' in convokit parlance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = list(set(pairDF.op_author))\n",
    "\n",
    "for i,r in pairDF.iterrows():\n",
    "    for comment in r.comments:\n",
    "        if 'author' in comment.keys():\n",
    "            if comment['author'] not in users:\n",
    "                users.append(comment['author'])\n",
    "        else: continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34910"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I don't have metadata on individual users. I briefly considered creating a unique identifier for each user and including the 'username' as metadata, but since each Reddit username is unique, it would be superfluousC:\\Users\\Andrew\\Desktop\\Cornell-Conversational-Analysis-Toolkit. I believe other relevant information (such as whether a Redditor is the original poster) is specific to individual conversations and utterances.\n",
    "\n",
    "2 metadata points of note: 'author_flair_css_class' and 'author_flair_text' both describe flags that appear next to an author in a subeddit. In the changemyview subreddit the moderators use this to illustrate whether the author has changed someone's mind and it can be seen as both an award and evidence of credibility in the subreddit. While I would include this as author metadata, I believe, instead, that it is actually 'conversation' metadata because this flag would be updated overtime if the author changes multiple people's minds over the course of many conversations. Since this data was collected overtime, the flag is likely to change per user across multiple conversations, possibly across utterances.\n",
    "\n",
    "I will include the user_meta dictionary, just in case, so data can be added to it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_meta={}\n",
    "for user in users:\n",
    "    user_meta[user]={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_users = {k: Speaker(name = k, meta = v) for k,v in user_meta.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users in the data = 34910\n"
     ]
    }
   ],
   "source": [
    "print(\"number of users in the data = {0}\".format(len(corpus_users)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next: create utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there were 530 comments that were missing common attributes\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "count=0\n",
    "errors=[]\n",
    "utterance_corpus = {}\n",
    "\n",
    "for i , r in pairDF.iterrows():\n",
    "    #this creates an Utterance using the metadata provided in the original file. Note: this is for the original post in each observation within the pandas dataframe\n",
    "    utterance_corpus[r.op_name]=Utterance(id=r.op_name ,\n",
    "                                          user=corpus_users[r.op_author],\n",
    "                                          root=r.op_name ,\n",
    "                                          reply_to=None,\n",
    "                                          timestamp=None,\n",
    "                                          text=r.op_text,\n",
    "                                          meta= {'pair_ids':[],\n",
    "                                                 'success':None,\n",
    "                                                 'approved_by': None,\n",
    "                                                 'author_flair_css_class': None,\n",
    "                                                 'author_flair_text': None,\n",
    "                                                 'banned_by': None,\n",
    "                                                 'controversiality': None,\n",
    "                                                 'distinguished': None,\n",
    "                                                 'downs': None,\n",
    "                                                 'edited': None,\n",
    "                                                 'gilded': None,\n",
    "                                                 'likes': None,\n",
    "                                                 'mod_reports':None,\n",
    "                                                 'num_reports': None,\n",
    "                                                 'replies': [com['id'] for com in r.comments if com['parent_id']==r.op_name],\n",
    "                                                 'report_reasons': None,\n",
    "                                                 'saved': None,\n",
    "                                                 'score': None,\n",
    "                                                 'score_hidden': None,\n",
    "                                                 'subreddit': None,\n",
    "                                                 'subreddit_id': None,\n",
    "                                                 'ups': None,\n",
    "                                                 'user_reports': None})\n",
    "    #note: now for every comment in the original thread, make an utterance\n",
    "    for comment in r.comments:\n",
    "        try:\n",
    "            utterance_corpus[comment['name']]=Utterance(id=comment['name'],\n",
    "                                                        user=corpus_users[comment['author']],\n",
    "                                                        root=r.op_name,\n",
    "                                                        reply_to=comment['parent_id'],\n",
    "                                                        timestamp=int(comment['created']),\n",
    "                                                        text=comment['body'] ,\n",
    "                                                        meta={\n",
    "                                                            'pair_ids':pairIDS[comment['name']],\n",
    "                                                            'success':comment['success'],\n",
    "                                                            'approved_by': comment['approved_by'],\n",
    "                                                            'author_flair_css_class': comment['author_flair_css_class'],\n",
    "                                                            'author_flair_text': comment['author_flair_text'],\n",
    "                                                            'banned_by': comment['banned_by'],\n",
    "                                                            'controversiality': comment['controversiality'],\n",
    "                                                            'distinguished': comment['distinguished'],\n",
    "                                                            'downs': comment['downs'],\n",
    "                                                            'edited': comment['edited'],\n",
    "                                                            'gilded': comment['gilded'],\n",
    "                                                            'likes': comment['likes'],\n",
    "                                                            'mod_reports':comment['mod_reports'],\n",
    "                                                            'num_reports': comment['num_reports'],\n",
    "                                                            'replies':comment['replies'],\n",
    "                                                            'report_reasons': comment['report_reasons'],\n",
    "                                                            'saved': comment['saved'],\n",
    "                                                            'score': comment['score'],\n",
    "                                                            'score_hidden': comment['score_hidden'],\n",
    "                                                            'subreddit': comment['subreddit'],\n",
    "                                                            'subreddit_id': comment['subreddit_id'],\n",
    "                                                            'ups': comment['ups'],\n",
    "                                                            'user_reports': comment['user_reports']\n",
    "                                                             })\n",
    "\n",
    "        #this except catches multiple comments that have no text body, see errors examples below\n",
    "        except:\n",
    "            c=c+1\n",
    "            errors.append(comment)\n",
    "            utterance_corpus[comment['name']]=Utterance(id=comment['name'],\n",
    "                                                        user=Speaker(name='[missing]'),\n",
    "                                                        root=r.op_name,\n",
    "                                                        reply_to=comment['parent_id'],\n",
    "                                                        timestamp=None,\n",
    "                                                        text=None ,\n",
    "                                                        meta={\n",
    "                                                            'pair_ids':pairIDS[comment['name']],\n",
    "                                                            'success':comment['success'],\n",
    "                                                            'approved_by': None,\n",
    "                                                            'author_flair_css_class':  None,\n",
    "                                                            'author_flair_text':  None,\n",
    "                                                            'banned_by':  None,\n",
    "                                                            'controversiality':  None,\n",
    "                                                            'distinguished': None,\n",
    "                                                            'downs':  None,\n",
    "                                                            'edited':  None,\n",
    "                                                            'gilded':  None,\n",
    "                                                            'likes':  None,\n",
    "                                                            'mod_reports': None,\n",
    "                                                            'num_reports':  None,\n",
    "                                                            'replies': None,\n",
    "                                                            'report_reasons':  None,\n",
    "                                                            'saved':  None,\n",
    "                                                            'score':  None,\n",
    "                                                            'score_hidden':  None,\n",
    "                                                            'subreddit': None,\n",
    "                                                            'subreddit_id': None,\n",
    "                                                            'ups':  None,\n",
    "                                                            'user_reports':  None\n",
    "                                                             })\n",
    "\n",
    "           \n",
    "print('there were '+str(c)+' comments that were missing common attributes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 530 comments missing common attributes (note that none of them have a text body or author) have been included in the corpus for completeness (note: each were caught by the exception in the above code, but still included), here are some examples of these comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'children': ['cm6tktt'],\n",
       " 'count': 0,\n",
       " 'id': 'cm6tktt',\n",
       " 'name': 't1_cm6tktt',\n",
       " 'parent_id': 't1_cm6tfr2',\n",
       " 'success': None}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'children': ['cj50shk'],\n",
       " 'count': 0,\n",
       " 'id': 'cj50shk',\n",
       " 'name': 't1_cj50shk',\n",
       " 'parent_id': 't1_cj4wzvs',\n",
       " 'success': None}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'children': ['cq9ci0g'],\n",
       " 'count': 1,\n",
       " 'id': 'cq9ci0g',\n",
       " 'name': 't1_cq9ci0g',\n",
       " 'parent_id': 't1_cq9465r',\n",
       " 'success': None}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors[395]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293297"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(utterance_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note above: the # of individual posts is less than each recorded comment in our dataset. This stands scrutiny when reviewing the dataset for two reasons:\n",
    "    1. each positive and negative thread correspond to the same original post.\n",
    "    2. original posts were re-used to compare different successful/non-successful arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a corpus from a list of utterances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterance_list = [utterance for k,utterance in utterance_corpus.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_my_view_corpus = Corpus(utterances=utterance_list, version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of conversations in the dataset = 3051\n"
     ]
    }
   ],
   "source": [
    "print(\"number of conversations in the dataset = {}\".format(len(change_my_view_corpus.get_conversation_ids())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: 3051 is the number of original posts recorded in the dataset (both train and hold out data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample conversation 0:\n",
      "['t3_2ro9ux', 't1_cnhplrm', 't1_cnhrvq7', 't1_cnhz66d', 't1_cniauhy', 't1_cnibfev', 't1_cnic0gj', 't1_cnhpsmr', 't1_cnhpvqs', 't1_cnhq7iw', 't1_cnhqrw1', 't1_cnhqzsf', 't1_cni8tcx', 't1_cnhpp4o', 't1_cnhqouu', 't1_cnhrd8u', 't1_cnhrwsq', 't1_cnhs6sc', 't1_cnhtr4t', 't1_cnhuopi', 't1_cnio1bg', 't1_cnhq330', 't1_cnhs7xb', 't1_cnhpnmr', 't1_cnhqhxa', 't1_cnhrkoc', 't1_cnhq7nv', 't1_cnhqcwz', 't1_cnhsyft', 't1_cnhww76', 't1_cnhz5wq', 't1_cni80dr', 't1_cni8e2y']\n",
      "sample conversation 1:\n",
      "['t3_2ro0ti', 't1_cnhpddf', 't1_cnhpqan', 't1_cnhuxye', 't1_cni1m79', 't1_cni24ug', 't1_cnhrcu4', 't1_cni06fr', 't1_cnhp0bu', 't1_cnhppsw', 't1_cnhwhma', 't1_cnho6mi', 't1_cnhot32', 't1_cnhp1pb', 't1_cnho7iy', 't1_cnhoqp4', 't1_cnhobzs', 't1_cnhop4t', 't1_cnhp1nq', 't1_cnhpgyd', 't1_cnhp5lp', 't1_cnhplmn', 't1_cni3tyd', 't1_cnhqck4', 't1_cnhpee3', 't1_cnhregg', 't1_cniogf7', 't1_cnhowj2', 't1_cnhxuu1', 't1_cniedbg', 't1_cnixgm0']\n"
     ]
    }
   ],
   "source": [
    "convo_ids = change_my_view_corpus.get_conversation_ids()\n",
    "for i, convo_idx in enumerate(convo_ids[0:2]):\n",
    "    print(\"sample conversation {}:\".format(i))\n",
    "    print(change_my_view_corpus.get_conversation(convo_idx).get_utterance_ids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add conversation-level metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "convos = change_my_view_corpus.iter_conversations()\n",
    "for convo in convos:\n",
    "    convo.add_meta('op-userID',pairDF[pairDF.op_name==convo._id].op_author[pairDF[pairDF.op_name==convo._id].index[0]])\n",
    "    convo.add_meta('op-text-body',pairDF[pairDF.op_name==convo._id].op_text[pairDF[pairDF.op_name==convo._id].index[0]])\n",
    "    convo.add_meta('op-title',pairDF[pairDF.op_name==convo._id].op_title[pairDF[pairDF.op_name==convo._id].index[0]])\n",
    "    convo.add_meta('pair_ids',pairDF[pairDF.op_name==convo._id].pIDs[pairDF[pairDF.op_name==convo._id].index[0]])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_ids= change_my_view_corpus.get_conversation_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cv in convo_ids:\n",
    "    change_my_view_corpus.get_conversation(cv).add_meta('train',int(pairDF[pairDF.op_name==cv].train[pairDF[pairDF.op_name==cv].index[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add corpus title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_my_view_corpus.meta['name'] = \"Change My View Corpus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Users: 34911\n",
      "Number of Utterances: 293297\n",
      "Number of Conversations: 3051\n"
     ]
    }
   ],
   "source": [
    "change_my_view_corpus.print_summary_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_my_view_corpus.dump('change-my-view-corpus', base_path='C:\\\\Users\\\\Andrew\\\\Desktop\\\\CMV data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- The original data compiled by the authors only included the challenger replies. To extract the full argument (i.e. a conversation between OP and the challenger), we selected the comments by OP for inclusion in a successful or unsuccessful argument (i.e. \"success\" = 1 or 0) by collecting all OP replies to any of the corresponding successful/unsuccessful comments by the challenger. This is a conservative measure of the overall \"argument.\" It does not include comments made in response to the challenger's posts by other individuals nor include comments made by OP if he replied to those outside individuals. All other comments in the thread (including separate comments made by OP) have the \"success\" field taking the value of None.\n",
    "- If you are interested in expanding the 'arguments' to ensure all conversants are included, then I would suggest the following method:\n",
    "\n",
    "\t\t1. Collect all originally provided successful and unsuccessful comments (collected at the Utterance-level conditioning on both \"success\" = 1 or 0 and user_id != the OP's user_id).\n",
    "\t\t2. Collect all comments made by the OP.\n",
    "\t\t3. Using the reply_to identifier, recur up the comments made in the full comment thread for each original post; collecting every comment thread that OP has made a comment in.\n",
    "\t\t4. Select any comment thread from step 3 for inclusion in a successful/unsuccessful argument if the challenger has also made a comment in that thread. \n",
    "- Overall, I believe the conservative measurement of 'argument' that I have used is better because the second method (above) would include argument threads where a challenger is only minimally relevant.\n",
    "\n",
    "- Details on the collection procedure:\n",
    "\n",
    "We started from the data collected by the Winning Arguments paper (cited above). The data was collected from their host at this blog:\n",
    "https://chenhaot.com/pages/changemyview.html (note: data used in this corpus is from the original data collection -- NOT the updated data on 11/11/16) \n",
    "\n",
    "Note: we originally intended to only convert their pair_data into Convokit format (i.e. the data they use in Section 4 of the paper, which looks at differences between arguments that were convincing/unconvincing to the OP in changing their mind). However, the pair_data only included the replies to the original post (not OP's other comments in the thread -- so there was no conversation, nor did they have all comments in the thread). Therefore, we matched the OP posts in the pair_data with the same observation in their 'all' data, from which we collected all comments for each thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}